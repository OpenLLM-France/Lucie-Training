+ CHECKPOINT_PATH=/gpfswork/rech/qgz/urc37ho/checkpoints10121/
+ LOGS_PATH=/gpfswork/rech/qgz/urc37ho/lucie-logs
+ MEGATRON_DEEPSPEED_REPO=/gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya
+ cd /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya
+ DATASET=/gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document
+ TOKENIZER_PATH=OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all
++ head -n 1
++ scontrol show hostnames 'jean-zay-iam[16-17,29-32,37,47]'
+ MASTER_ADDR=jean-zay-iam16
+ MASTER_PORT=6000
+ GPUS_PER_NODE=8
+ NNODES=8
+ TP=1
+ PP=2
+ MICRO_BATCH_SIZE=4
+ GLOBAL_BATCH_SIZE=512
+ HIDDEN_SIZE=4096
+ FFN_HIDDEN_SIZE=11008
+ NUM_LAYERS=32
+ NUM_HEADS=32
+ SEQ_LENGTH=2048
+ NUM_KV_HEADS=32
+ TRAIN_STEPS=250000
+ LR=3e-4
+ MIN_LR=3e-5
+ LR_WARMUP_STEPS=2000
+ WEIGHT_DECAY=0.1
+ GRAD_CLIP=1
+ SAVE_INTERVAL=100
+ ZERO_STAGE=0
+ DS_CONFIG=./ds_config.1603271.json
+ activation_checkpoint=false
+ cat
+ ds_args=
+ ds_args=' --deepspeed '
+ ds_args=' --deepspeed_config=./ds_config.1603271.json  --deepspeed '
+ ds_args=' --zero-stage=0  --deepspeed_config=./ds_config.1603271.json  --deepspeed '
+ '[' false = true ']'
+ export CUDA_LAUNCH_BLOCKING=1
+ CUDA_LAUNCH_BLOCKING=1
+ export TORCHELASTIC_ERROR_FILE=/tmp/torch-elastic-error.json
+ TORCHELASTIC_ERROR_FILE=/tmp/torch-elastic-error.json
+ module purge
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash purge
+ eval unset '_LMFILES__modshare;
unset' 'LOADEDMODULES_modshare;
unset' 'MODULES_LMCONFLICT_modshare;
unset' '_LMFILES_;
unset' 'LOADEDMODULES;
unset' 'MODULES_LMCONFLICT;
test' '0;'
++ unset _LMFILES__modshare
++ unset LOADEDMODULES_modshare
++ unset MODULES_LMCONFLICT_modshare
++ unset _LMFILES_
++ unset LOADEDMODULES
++ unset MODULES_LMCONFLICT
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ module load cpuarch/amd
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load cpuarch/amd
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
unset' 'MODULEPATH_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd;' export 'LOADEDMODULES;
MODULEPATH=/gpfslocalsup/pub/module-rh/modulefiles:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64;' export 'MODULEPATH;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ unset MODULEPATH_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd
++ export LOADEDMODULES
++ MODULEPATH=/gpfslocalsup/pub/module-rh/modulefiles:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64
++ export MODULEPATH
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ module load anaconda-py3/2023.09
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load anaconda-py3/2023.09
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=anaconda-py3/2023.09:1:cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
MODULES_LMCONFLICT_modshare=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2:1;' export 'MODULES_LMCONFLICT_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2;' export 'MODULES_LMCONFLICT;
.' '/gpfslocalsup/pub/anaconda-py3/2023.09/etc/profile.d/conda.sh;
conda' activate 'base;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=anaconda-py3/2023.09:1:cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ MODULES_LMCONFLICT_modshare='anaconda-py3/2023.09&anaconda-py3&anaconda-py2:1'
++ export MODULES_LMCONFLICT_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='anaconda-py3/2023.09&anaconda-py3&anaconda-py2'
++ export MODULES_LMCONFLICT
++ . /gpfslocalsup/pub/anaconda-py3/2023.09/etc/profile.d/conda.sh
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
+++ '[' -z x ']'
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda shell.posix activate base
++ ask_conda='. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/deactivate.d/libxml2_deactivate.sh"
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/deactivate.d/libblas_mkl_deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_1='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211'\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\'''
++ eval '. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/deactivate.d/libxml2_deactivate.sh"
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/deactivate.d/libblas_mkl_deactivate.sh"
PS1='\''(base) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_1='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211'\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\'''
+++ . /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/deactivate.d/libxml2_deactivate.sh
++++ test -n ''
++++ unset XML_CATALOG_FILES
++++ unset xml_catalog_files_libxml2
+++ . /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/deactivate.d/libblas_mkl_deactivate.sh
++++ '[' '' = '' ']'
++++ unset MKL_INTERFACE_LAYER
++++ unset CONDA_MKL_INTERFACE_LAYER_BACKUP
+++ PS1='(base) '
+++ export PATH=/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
+++ export CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2023.09
+++ CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2023.09
+++ export CONDA_SHLVL=2
+++ CONDA_SHLVL=2
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_1=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ CONDA_PREFIX_1=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ conda activate lucie-torch211
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate lucie-torch211
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate lucie-torch211
++ /gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda shell.posix activate lucie-torch211
+ ask_conda='PS1='\''(lucie-torch211) '\''
export PATH='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''lucie-torch211'\''
export CONDA_PROMPT_MODIFIER='\''(lucie-torch211) '\''
export CONDA_PREFIX_2='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\''
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libblas_mkl_activate.sh"
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libxml2_activate.sh"'
+ eval 'PS1='\''(lucie-torch211) '\''
export PATH='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''lucie-torch211'\''
export CONDA_PROMPT_MODIFIER='\''(lucie-torch211) '\''
export CONDA_PREFIX_2='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\''
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libblas_mkl_activate.sh"
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libxml2_activate.sh"'
++ PS1='(lucie-torch211) '
++ export PATH=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
++ PATH=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
++ export CONDA_PREFIX=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
++ CONDA_PREFIX=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
++ export CONDA_SHLVL=3
++ CONDA_SHLVL=3
++ export CONDA_DEFAULT_ENV=lucie-torch211
++ CONDA_DEFAULT_ENV=lucie-torch211
++ export 'CONDA_PROMPT_MODIFIER=(lucie-torch211) '
++ CONDA_PROMPT_MODIFIER='(lucie-torch211) '
++ export CONDA_PREFIX_2=/gpfslocalsup/pub/anaconda-py3/2023.09
++ CONDA_PREFIX_2=/gpfslocalsup/pub/anaconda-py3/2023.09
++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
++ . /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libblas_mkl_activate.sh
+++ export CONDA_MKL_INTERFACE_LAYER_BACKUP=
+++ CONDA_MKL_INTERFACE_LAYER_BACKUP=
+++ export MKL_INTERFACE_LAYER=LP64,GNU
+++ MKL_INTERFACE_LAYER=LP64,GNU
++ . /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libxml2_activate.sh
+++ test -n ''
+++ xml_catalog_files_libxml2=
+++ XML_CATALOG_FILES=
+++ conda_catalog_files=
+++ ifs_libxml2=' 	
'
+++ IFS=' '
+++ rem=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ for pre in ${rem}
+++ test '' = /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ conda_catalog_files=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ rem=
+++ IFS=' 	
'
+++ conda_catalog_files='file:///linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/xml/catalog file:///etc/xml/catalog'
+++ export 'XML_CATALOG_FILES=file:///linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/xml/catalog file:///etc/xml/catalog'
+++ XML_CATALOG_FILES='file:///linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/xml/catalog file:///etc/xml/catalog'
+++ unset conda_catalog_files ifs_libxml2 rem
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ module load cuda/12.1.0
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load cuda/12.1.0
+ eval 'LD_LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib;' export 'LD_LIBRARY_PATH;
MANPATH=/gpfslocalsys/cuda/12.1.0/doc/man::/opt/c3/man:/opt/clmgr/man:/opt/sgi/share/man:/opt/clmgr/share/man:/opt/clmgr/lib/cm-cli/man:/gpfslocalsys/slurm/current/share/man:/usr/share/catman:/usr/share/man:/usr/catman:/usr/man;' export 'MANPATH;
LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/lib64/stubs:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib;' export 'LIBRARY_PATH;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09:cuda/12.1.0;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2:cuda/12.1.0\&cuda;' export 'MODULES_LMCONFLICT;
MANPATH_modshare=:1:/opt/sgi/share/man:1:/gpfslocalsys/slurm/current/share/man:1:/opt/c3/man:1:/opt/clmgr/lib/cm-cli/man:1:/opt/clmgr/share/man:1:/usr/man:1:/usr/catman:1:/opt/clmgr/man:1:/gpfslocalsys/cuda/12.1.0/doc/man:1:/usr/share/man:1:/usr/share/catman:1;' export 'MANPATH_modshare;
NVHPC_CUDA_HOME=/gpfslocalsys/cuda/12.1.0;' export 'NVHPC_CUDA_HOME;
LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64/stubs:1:/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1;' export 'LIBRARY_PATH_modshare;
MODULES_LMCONFLICT_modshare=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2:1:cuda/12.1.0\&cuda:1;' export 'MODULES_LMCONFLICT_modshare;
CPLUS_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include;' export 'CPLUS_INCLUDE_PATH;
CUDA_INSTALL_PATH=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_INSTALL_PATH;
CUDA_ROOT=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_ROOT;
CUDA_PATH=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_PATH;
LD_LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1;' export 'LD_LIBRARY_PATH_modshare;
C_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include;' export 'C_INCLUDE_PATH;
_LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=cuda/12.1.0:1:cpuarch/amd:1:anaconda-py3/2023.09:1;' export 'LOADEDMODULES_modshare;
PATH=/gpfslocalsys/cuda/12.1.0/samples:/gpfslocalsys/cuda/12.1.0/nvvm/bin:/gpfslocalsys/cuda/12.1.0/bin:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin;' export 'PATH;
CUDA_HOME=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_HOME;
PATH_modshare=/usr/bin:1:/gpfslocalsup/bin:1:/usr/local/bin:1:/gpfslocalsys/cuda/12.1.0/bin:1:/opt/sgi/bin:1:/gpfslocalsys/slurm/current/bin:1:/opt/clmgr/bin:1:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:1:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:1:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:1:/opt/sgi/sbin:1:/gpfslocalsys/cuda/12.1.0/samples:1:/bin:1:/opt/clmgr/sbin:1:/gpfslocalsys/bin:1:/gpfslocalsys/cuda/12.1.0/nvvm/bin:1:/sbin:1:/usr/sbin:1:/usr/local/sbin:1:/usr/lpp/mmfs/bin:1:/opt/c3/bin:1;' export 'PATH_modshare;
test' '0;'
++ LD_LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
++ export LD_LIBRARY_PATH
++ MANPATH=/gpfslocalsys/cuda/12.1.0/doc/man::/opt/c3/man:/opt/clmgr/man:/opt/sgi/share/man:/opt/clmgr/share/man:/opt/clmgr/lib/cm-cli/man:/gpfslocalsys/slurm/current/share/man:/usr/share/catman:/usr/share/man:/usr/catman:/usr/man
++ export MANPATH
++ LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/lib64/stubs:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
++ export LIBRARY_PATH
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09:cuda/12.1.0
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='anaconda-py3/2023.09&anaconda-py3&anaconda-py2:cuda/12.1.0&cuda'
++ export MODULES_LMCONFLICT
++ MANPATH_modshare=:1:/opt/sgi/share/man:1:/gpfslocalsys/slurm/current/share/man:1:/opt/c3/man:1:/opt/clmgr/lib/cm-cli/man:1:/opt/clmgr/share/man:1:/usr/man:1:/usr/catman:1:/opt/clmgr/man:1:/gpfslocalsys/cuda/12.1.0/doc/man:1:/usr/share/man:1:/usr/share/catman:1
++ export MANPATH_modshare
++ NVHPC_CUDA_HOME=/gpfslocalsys/cuda/12.1.0
++ export NVHPC_CUDA_HOME
++ LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64/stubs:1:/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1
++ export LIBRARY_PATH_modshare
++ MODULES_LMCONFLICT_modshare='anaconda-py3/2023.09&anaconda-py3&anaconda-py2:1:cuda/12.1.0&cuda:1'
++ export MODULES_LMCONFLICT_modshare
++ CPLUS_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include
++ export CPLUS_INCLUDE_PATH
++ CUDA_INSTALL_PATH=/gpfslocalsys/cuda/12.1.0
++ export CUDA_INSTALL_PATH
++ CUDA_ROOT=/gpfslocalsys/cuda/12.1.0
++ export CUDA_ROOT
++ CUDA_PATH=/gpfslocalsys/cuda/12.1.0
++ export CUDA_PATH
++ LD_LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1
++ export LD_LIBRARY_PATH_modshare
++ C_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include
++ export C_INCLUDE_PATH
++ _LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=cuda/12.1.0:1:cpuarch/amd:1:anaconda-py3/2023.09:1
++ export LOADEDMODULES_modshare
++ PATH=/gpfslocalsys/cuda/12.1.0/samples:/gpfslocalsys/cuda/12.1.0/nvvm/bin:/gpfslocalsys/cuda/12.1.0/bin:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
++ export PATH
++ CUDA_HOME=/gpfslocalsys/cuda/12.1.0
++ export CUDA_HOME
++ PATH_modshare=/usr/bin:1:/gpfslocalsup/bin:1:/usr/local/bin:1:/gpfslocalsys/cuda/12.1.0/bin:1:/opt/sgi/bin:1:/gpfslocalsys/slurm/current/bin:1:/opt/clmgr/bin:1:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:1:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:1:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:1:/opt/sgi/sbin:1:/gpfslocalsys/cuda/12.1.0/samples:1:/bin:1:/opt/clmgr/sbin:1:/gpfslocalsys/bin:1:/gpfslocalsys/cuda/12.1.0/nvvm/bin:1:/sbin:1:/usr/sbin:1:/usr/local/sbin:1:/usr/lpp/mmfs/bin:1:/opt/c3/bin:1
++ export PATH_modshare
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ DISTRIBUTED_ARGS='--nproc_per_node 8 --nnodes 8 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam16:6000 --rdzv_backend c10d --max_restarts 0 --tee 3'
++ pwd
+ export 'RUN=torchrun --nproc_per_node 8 --nnodes 8 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam16:6000 --rdzv_backend c10d --max_restarts 0 --tee 3        /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/pretrain_gpt.py        --data-cache-path /linkhome/rech/genlor01/urc37ho/.cache        --tensor-model-parallel-size 1        --pipeline-model-parallel-size 2        --num-layers 32        --hidden-size 4096        --ffn-hidden-size 11008        --num-attention-heads 32        --micro-batch-size 4        --global-batch-size 512        --seq-length 2048        --max-position-embeddings 2048        --train-iters 250000        --save /gpfswork/rech/qgz/urc37ho/checkpoints10121/        --load /gpfswork/rech/qgz/urc37ho/checkpoints10121/        --data-path /gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document        --data-impl mmap        --tokenizer-type PretrainedFromHF         --tokenizer-name-or-path OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all        --distributed-backend nccl        --lr 3e-4        --lr-decay-style cosine        --min-lr 3e-5        --weight-decay 0.1        --clip-grad 1        --lr-warmup-iters 2000        --optimizer adam        --adam-beta1 0.9        --adam-beta2 0.95        --log-interval 1        --save-interval 100        --eval-interval 100        --eval-iters 1        --bf16        --use-flash-attn-v2        --no-query-key-layer-scaling        --attention-dropout 0        --hidden-dropout 0        --use-rotary-position-embeddings        --untie-embeddings-and-output-weights        --swiglu        --normalization rmsnorm        --disable-bias-linear        --num-key-value-heads 32         --zero-stage=0  --deepspeed_config=./ds_config.1603271.json  --deepspeed                 '
+ RUN='torchrun --nproc_per_node 8 --nnodes 8 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam16:6000 --rdzv_backend c10d --max_restarts 0 --tee 3        /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/pretrain_gpt.py        --data-cache-path /linkhome/rech/genlor01/urc37ho/.cache        --tensor-model-parallel-size 1        --pipeline-model-parallel-size 2        --num-layers 32        --hidden-size 4096        --ffn-hidden-size 11008        --num-attention-heads 32        --micro-batch-size 4        --global-batch-size 512        --seq-length 2048        --max-position-embeddings 2048        --train-iters 250000        --save /gpfswork/rech/qgz/urc37ho/checkpoints10121/        --load /gpfswork/rech/qgz/urc37ho/checkpoints10121/        --data-path /gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document        --data-impl mmap        --tokenizer-type PretrainedFromHF         --tokenizer-name-or-path OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all        --distributed-backend nccl        --lr 3e-4        --lr-decay-style cosine        --min-lr 3e-5        --weight-decay 0.1        --clip-grad 1        --lr-warmup-iters 2000        --optimizer adam        --adam-beta1 0.9        --adam-beta2 0.95        --log-interval 1        --save-interval 100        --eval-interval 100        --eval-iters 1        --bf16        --use-flash-attn-v2        --no-query-key-layer-scaling        --attention-dropout 0        --hidden-dropout 0        --use-rotary-position-embeddings        --untie-embeddings-and-output-weights        --swiglu        --normalization rmsnorm        --disable-bias-linear        --num-key-value-heads 32         --zero-stage=0  --deepspeed_config=./ds_config.1603271.json  --deepspeed                 '
+ srun --jobid 1603271 bash -c 'torchrun --nproc_per_node 8 --nnodes 8 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam16:6000 --rdzv_backend c10d --max_restarts 0 --tee 3        /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/pretrain_gpt.py        --data-cache-path /linkhome/rech/genlor01/urc37ho/.cache        --tensor-model-parallel-size 1        --pipeline-model-parallel-size 2        --num-layers 32        --hidden-size 4096        --ffn-hidden-size 11008        --num-attention-heads 32        --micro-batch-size 4        --global-batch-size 512        --seq-length 2048        --max-position-embeddings 2048        --train-iters 250000        --save /gpfswork/rech/qgz/urc37ho/checkpoints10121/        --load /gpfswork/rech/qgz/urc37ho/checkpoints10121/        --data-path /gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document        --data-impl mmap        --tokenizer-type PretrainedFromHF         --tokenizer-name-or-path OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all        --distributed-backend nccl        --lr 3e-4        --lr-decay-style cosine        --min-lr 3e-5        --weight-decay 0.1        --clip-grad 1        --lr-warmup-iters 2000        --optimizer adam        --adam-beta1 0.9        --adam-beta2 0.95        --log-interval 1        --save-interval 100        --eval-interval 100        --eval-iters 1        --bf16        --use-flash-attn-v2        --no-query-key-layer-scaling        --attention-dropout 0        --hidden-dropout 0        --use-rotary-position-embeddings        --untie-embeddings-and-output-weights        --swiglu        --normalization rmsnorm        --disable-bias-linear        --num-key-value-heads 32         --zero-stage=0  --deepspeed_config=./ds_config.1603271.json  --deepspeed                 '
+ tee -a /gpfswork/rech/qgz/urc37ho/lucie-logs/main_log.txt
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,848] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-23 16:03:25,849] torch.distributed.run: [WARNING] *****************************************
[default4]:[2024-04-23 16:03:33,525] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-23 16:03:33,508] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-23 16:03:33,614] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-23 16:03:33,595] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,613] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-23 16:03:33,596] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-23 16:03:33,616] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-23 16:03:33,607] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[2024-04-23 16:03:33,502] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-23 16:03:33,615] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-23 16:03:33,613] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-23 16:03:33,615] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-23 16:03:33,613] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,614] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-23 16:03:33,611] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-23 16:03:33,616] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[2024-04-23 16:03:33,541] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-23 16:03:33,531] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-23 16:03:33,510] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-23 16:03:33,615] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,616] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-23 16:03:33,616] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-23 16:03:33,617] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-23 16:03:33,614] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default1]:[2024-04-23 16:03:33,509] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-23 16:03:33,533] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-23 16:03:33,618] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-23 16:03:33,620] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-23 16:03:33,618] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-23 16:03:33,551] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,619] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default7]:[2024-04-23 16:03:33,615] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default3]:[2024-04-23 16:03:33,558] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-23 16:03:33,666] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-23 16:03:33,670] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-23 16:03:33,669] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,664] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-23 16:03:33,668] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-23 16:03:33,668] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:--------------------------------------------------
[default0]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default6]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:[2024-04-23 16:03:33,669] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default3]:--------------------------------------------------
[default6]:--------------------------------------------------
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[2024-04-23 16:03:33,551] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-23 16:03:33,559] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,562] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-23 16:03:33,557] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-23 16:03:33,623] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-23 16:03:33,625] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-23 16:03:33,626] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-23 16:03:33,626] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[2024-04-23 16:03:33,511] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-23 16:03:33,608] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-23 16:03:33,643] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-23 16:03:33,646] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-23 16:03:33,645] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,644] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-23 16:03:33,644] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-23 16:03:33,645] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[2024-04-23 16:03:33,517] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-23 16:03:33,525] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-23 16:03:33,621] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-23 16:03:33,619] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-23 16:03:33,617] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-23 16:03:33,618] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-23 16:03:33,619] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-23 16:03:33,620] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:/bin/sh: line 0: type: git: not found
[default0]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:/bin/sh: line 0: type: git: not found
[default5]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default0]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:/bin/sh: line 0: type: git: not found
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
                                                  [default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:using world size: 64, data-parallel-size: 32, sequence-parallel size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 2 
[default0]:accumulate and all-reduce gradients in fp32 for bfloat16 data type.
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:using torch.bfloat16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  accumulate_allreduce_grads_in_fp32 .............. True
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  add_bias_linear ................................. False
[default0]:  add_position_embedding .......................... False
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  aml_data_download_path .......................... None
[default0]:  apply_layernorm_1p .............................. False
[default0]:  apply_query_key_layer_scaling ................... False
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  async_tensor_model_parallel_allreduce ........... False
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:  attention_dropout ............................... 0.0
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  barrier_with_L1_time ............................ True
[default0]:  bert_binary_head ................................ True
[default0]:  bert_embedder_type .............................. megatron
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ True
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ False
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... False
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default2]:/bin/sh: line 0: type: git: not found
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:  classes_fraction ................................ 1.0
[default0]:  clip_grad ....................................... 1.0
[default0]:  compression_training ............................ False
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  create_moe_param_group .......................... False
[default0]:  curriculum_learning_legacy ...................... False
[default0]:  data_cache_path ................................. /linkhome/rech/genlor01/urc37ho/.cache
[default0]:  data_efficiency_curriculum_learning ............. False
[default0]:  data_impl ....................................... mmap
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:  data_parallel_random_init ....................... False
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:  data_parallel_size .............................. 32
[default0]:  data_path ....................................... ['/gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document']
[default0]:  data_per_class_fraction ......................... 1.0
[default0]:  data_sharding ................................... True
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_num_layers .............................. None
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. False
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:  deepspeed_config ................................ ./ds_config.1603271.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  dino_bottleneck_size ............................ 256
[default0]:  dino_freeze_last_layer .......................... 1
[default0]:  dino_head_hidden_size ........................... 2048
[default0]:  dino_local_crops_number ......................... 10
[default0]:  dino_local_img_size ............................. 96
[default0]:  dino_norm_last_layer ............................ False
[default0]:  dino_teacher_temp ............................... 0.07
[default0]:  dino_warmup_teacher_temp ........................ 0.04
[default0]:  dino_warmup_teacher_temp_epochs ................. 30
[default0]:  disable_mem_efficient_ln ........................ True
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distribute_saved_activations .................... False
[default0]:  distributed_backend ............................. nccl
[default0]:  distributed_timeout_minutes ..................... 10
[default0]:  ds_inference .................................... False
[default0]:  ds_pipeline_enabled ............................. True
[default0]:  ds_sequence_parallel_size ....................... 1
[default0]:  embedding_path .................................. None
[default0]:  embedding_weights_in_fp32 ....................... False
[default0]:  empty_unused_memory_level ....................... 0
[default0]:  enable_expert_tensor_parallelism ................ False
[default0]:  encoder_num_layers .............................. 32
[default0]:  encoder_seq_length .............................. 2048
[default0]:  end_weight_decay ................................ 0.1
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 100
[default0]:  eval_iters ...................................... 1
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... None
[default0]:  exit_on_missing_checkpoint ...................... False
[default0]:  exit_signal_handler ............................. False
[default0]:  expert_interval ................................. 2
[default0]:  ffn_hidden_size ................................. 11008
[default0]:  finetune ........................................ False
[default0]:  force_ds_sequence_parallel ...................... False
[default0]:  fp16 ............................................ False
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  fp8_amax_compute_algo ........................... most_recent
[default0]:  fp8_amax_history_len ............................ 1
[default0]:  fp8_e4m3 ........................................ False
[default0]:  fp8_hybrid ...................................... False
[default0]:  fp8_interval .................................... 1
[default0]:  fp8_margin ...................................... 0
[default0]:  fp8_wgrad ....................................... True
[default0]:  global_batch_size ............................... 512
[default0]:  gradient_accumulation_fusion .................... True
[default0]:  head_lr_mult .................................... 1.0
[default0]:  hidden_dropout .................................. 0.0
[default0]:  hidden_size ..................................... 4096
[default0]:  hidden_size_teacher ............................. None
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_h ........................................... 224
[default0]:  img_w ........................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  inference_batch_times_seqlen_threshold .......... 512
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  iter_per_epoch .................................. 1250
[default0]:  kd .............................................. False
[default0]:  kd_alpha_ce ..................................... 1
[default0]:  kd_beta_ce ...................................... 1
[default0]:  kd_temp ......................................... 1.0
[default0]:  kv_channels ..................................... 128
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ /gpfswork/rech/qgz/urc37ho/checkpoints10121/
[default0]:  load_iteration .................................. None
[default0]:  load_teacher .................................... None
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... False
[default0]:  log_interval .................................... 1
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_memory_to_tensorboard ....................... False
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_optimizer_states_to_tensorboard ............. False
[default0]:  log_params_norm ................................. False
[default0]:  log_timers_to_tensorboard ....................... False
[default0]:  log_validation_ppl_to_tensorboard ............... False
[default0]:  log_world_size_to_tensorboard ................... False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0003
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 2000
[default0]:  lr_warmup_samples ............................... 0
[default0]:  lr_warmup_tokens ................................ None
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_factor ..................................... 1.0
[default0]:  mask_prob ....................................... 0.15
[default0]:  mask_type ....................................... random
[default0]:  masked_softmax_fusion ........................... True
[default5]:/bin/sh: line 0: type: git: not found
[default0]:  max_position_embeddings ......................... 2048
[default0]:  max_tokens_to_oom ............................... 12000
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... None
[default0]:  micro_batch_size ................................ 4
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 3e-05
[default0]:  mlp_type ........................................ standard
[default0]:  mmap_warmup ..................................... False
[default0]:  moe_eval_capacity_factor ........................ 1.0
[default0]:  moe_expert_parallel_size ........................ 1
[default0]:  moe_loss_coeff .................................. 0.1
[default0]:  moe_min_capacity ................................ 4
[default0]:  moe_token_dropping .............................. True
[default0]:  moe_train_capacity_factor ....................... 1.0
[default7]:/bin/sh: line 0: type: git: not found
[default0]:  mos ............................................. False
[default0]:  multiple_valid_sets ............................. False
[default0]:  no_load_lr_state ................................ False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_persist_layer_norm ........................... False
[default0]:  no_pipeline_parallel ............................ False
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  normalization ................................... rmsnorm
[default0]:  num_attention_heads ............................. 32
[default0]:  num_attention_heads_teacher ..................... None
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_experts ..................................... [1]
[default0]:/bin/sh: line 0: type: git: not found
[default0]:  num_experts_switch .............................. None
[default0]:  num_experts_teacher ............................. [1]
[default0]:  num_key_value_heads ............................. 32
[default0]:  num_layers ...................................... 32
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_layers_teacher .............................. None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  output_bert_embeddings .......................... False
[default0]:  overlap_p2p_comm ................................ False
[default0]:  override_opt_param_scheduler .................... False
[default0]:  params_dtype .................................... torch.bfloat16
[default0]:  partition_activations ........................... False
[default0]:  patch_dim ....................................... 16
[default0]:  perform_initialization .......................... True
[default0]:  pipeline_model_parallel_size .................... 2
[default0]:  pipeline_model_parallel_split_rank .............. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  random_ltd ...................................... False
[default0]:  rank ............................................ 0
[default0]:  recompute_granularity ........................... None
[default0]:  recompute_method ................................ None
[default0]:  recompute_num_layers ............................ 1
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_iteration ................................. False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  retro_add_retriever ............................. False
[default0]:  retro_cyclic_train_iters ........................ None
[default0]:  retro_encoder_attention_dropout ................. 0.1
[default0]:  retro_encoder_hidden_dropout .................... 0.1
[default0]:  retro_encoder_layers ............................ 2
[default0]:  retro_num_neighbors ............................. 2
[default0]:  retro_num_retrieved_chunks ...................... 2
[default0]:  retro_return_doc_ids ............................ False
[default0]:  retro_workdir ................................... None
[default0]:  return_data_index ............................... False
[default0]:  rotary_percent .................................. 1.0
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ /gpfswork/rech/qgz/urc37ho/checkpoints10121/
[default0]:  save_interval ................................... 100
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 1234
[default0]:  seq_length ...................................... 2048
[default0]:  sequence_parallel ............................... False
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train ...................................... False
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  squared_relu .................................... False
[default0]:  standalone_embedding_stage ...................... False
[default0]:  start_weight_decay .............................. 0.1
[default0]:  swiglu .......................................... True
[default0]:  swin_backbone_type .............................. tiny
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 1
[default0]:  tensorboard_dir ................................. None
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 1000
[default0]:  test_data_path .................................. None
[default0]:  tile_factor ..................................... 1
[default0]:  timing_log_level ................................ 0
[default0]:  timing_log_option ............................... minmax
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_model ................................. None
[default0]:  tokenizer_name_or_path .......................... OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all
[default0]:  tokenizer_type .................................. PretrainedFromHF
[default0]:  topk ............................................ 1
[default0]:  train_data_exact_num_epochs ..................... None
[default0]:  train_data_path ................................. None
[default0]:  train_desc_path ................................. None
[default0]:  train_doc_idx_path .............................. None
[default0]:  train_idx_path .................................. None
[default0]:  train_iters ..................................... 250000
[default0]:  train_sample_idx_path ........................... None
[default0]:  train_samples ................................... None
[default0]:  train_shuffle_idx_path .......................... None
[default0]:  train_tokens .................................... None
[default0]:  transformer_impl ................................ local
[default0]:  transformer_pipeline_model_parallel_size ........ 2
[default0]:  universal_checkpoint ............................ False
[default0]:  untie_embeddings_and_output_weights ............. True
[default0]:  use_checkpoint_args ............................. False
[default0]:  use_checkpoint_opt_param_scheduler .............. False
[default0]:  use_contiguous_buffers_in_local_ddp ............. True
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_dataset_only ................................ False
[default0]:  use_distributed_optimizer ....................... False
[default0]:  use_flash_attn .................................. True
[default0]:  use_flash_attn_triton ........................... False
[default0]:  use_flash_attn_v1 ............................... False
[default0]:  use_flash_attn_v2 ............................... True
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  use_ring_exchange_p2p ........................... False
[default0]:  use_rotary_position_embeddings .................. True
[default0]:  use_tutel ....................................... False
[default0]:  valid_data_path ................................. None
[default0]:  variable_seq_lengths ............................ False
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vision_backbone_type ............................ vit
[default0]:  vision_pretraining .............................. False
[default0]:  vision_pretraining_type ......................... classify
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... None
[default0]:  vocab_size ...................................... None
[default0]:  wandb_api_key ................................... None
[default0]:  wandb_entity .................................... None
[default0]:  wandb_id ........................................ None
[default0]:  wandb_logger .................................... False
[default0]:  wandb_project ................................... megatron-ds-training
[default0]:  wandb_resume .................................... None
[default0]:  wandb_run_name .................................. None
[default0]:  weight_decay .................................... 0.1
[default0]:  weight_decay_incr_style ......................... constant
[default0]:  world_size ...................................... 64
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 0
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 4
[default0]:> building PretrainedFromHF tokenizer ...
[default0]: vocab file is un-used. loading tokenizer from pre-trained model
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default4]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default5]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default0]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:/bin/sh: line 0: type: git: not found
[default0]:/bin/sh: line 0: type: git: not found
[default5]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default5]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default0]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default5]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default0]:loading file tokenizer.model from cache at None
[default0]:loading file tokenizer.json from cache at /linkhome/rech/genlor01/urc37ho/.cache/huggingface/hub/models--OpenLLM-France--Lucie-tokenizer-v2.4-space_prefix_all/snapshots/edf1b3d40698a2eec64a63aa8731c510e5810ae6/tokenizer.json
[default0]:loading file added_tokens.json from cache at None
[default0]:loading file special_tokens_map.json from cache at /linkhome/rech/genlor01/urc37ho/.cache/huggingface/hub/models--OpenLLM-France--Lucie-tokenizer-v2.4-space_prefix_all/snapshots/edf1b3d40698a2eec64a63aa8731c510e5810ae6/special_tokens_map.json
[default0]:loading file tokenizer_config.json from cache at /linkhome/rech/genlor01/urc37ho/.cache/huggingface/hub/models--OpenLLM-France--Lucie-tokenizer-v2.4-space_prefix_all/snapshots/edf1b3d40698a2eec64a63aa8731c510e5810ae6/tokenizer_config.json
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:Loading extension module scaled_softmax_cuda...
[default7]:[rank15]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank49]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank48]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank50]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank52]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank53]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank47]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank8]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank6]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank32]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank39]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank38]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank10]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank11]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank13]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank7]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank40]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank46]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank42]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank41]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank34]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank4]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank45]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank44]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank51]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank35]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank33]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank36]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank55]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank5]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank37]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank27]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank31]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank29]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank28]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank26]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank30]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank57]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank56]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank18]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank54]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank20]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank16]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank43]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank23]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank24]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank21]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank59]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank60]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank62]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank61]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank22]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank58]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank63]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank17]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank19]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank12]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank14]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank9]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank25]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]: > padded vocab (size: 32000) with 0 dummy tokens (new size: 32000)
[default0]:> initializing torch distributed ...
[default0]:[2024-04-23 16:04:05,729] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]:[2024-04-23 16:04:05,729] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default2]:[2024-04-23 16:04:06,632] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,630] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,633] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,636] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,622] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,630] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,628] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]:> initialized tensor model parallel with size 1
[default0]:> initialized pipeline model parallel with size 2
[default0]:> setting random seeds to 1234 ...
[default0]:> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
[default0]:> compiling dataset index builder ...
[default0]:make: Entering directory '/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 0.091 seconds
[default0]:> compiling and loading fused kernels ...
[default0]:ninja: no work to do.
[default0]:ninja: no work to do.
[default0]:ninja: no work to do.
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 69.598 seconds
[default0]:time to initialize megatron (seconds): 85.950
[default0]:[after megatron is initialized] datetime: 2024-04-23 16:05:16 
[default0]:building GPT model ...
[default0]:[2024-04-23 16:05:17,020] [INFO] [utils.py:791:see_memory_usage] Before Building Model
[default0]:[2024-04-23 16:05:17,021] [INFO] [utils.py:792:see_memory_usage] MA 0.0 GB         Max_MA 2.86 GB         CA 0.0 GB         Max_CA 3 GB 
[default0]:[2024-04-23 16:05:17,021] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 30.53 GB, percent = 6.1%
[default0]:SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
..... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ /gpfswork/rech/qgz/urc37ho/checkpoints10121/
[default0]:  load_iteration .................................. None
[default0]:  load_teacher .................................... None
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... False
[default0]:  log_interval .................................... 1
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_memory_to_tensorboard ....................... False
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_optimizer_states_to_tensorboard ............. False
[default0]:  log_params_norm ................................. False
[default0]:  log_timers_to_tensorboard ....................... False
[default0]:  log_validation_ppl_to_tensorboard ............... False
[default0]:  log_world_size_to_tensorboard ................... False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0003
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 2000
[default0]:  lr_warmup_samples ............................... 0
[default0]:  lr_warmup_tokens ................................ None
[default0[default0]:Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=1, model=0): 1, ProcessCoord(pipe=0, data=2, model=0): 2, ProcessCoord(pipe=0, data=3, model=0): 3, ProcessCoord(pipe=0, data=4, model=0): 4, ProcessCoord(pipe=0, data=5, model=0): 5, ProcessCoord(pipe=0, data=6, model=0): 6, ProcessCoord(pipe=0, data=7, model=0): 7, ProcessCoord(pipe=0, data=8, model=0): 8, ProcessCoord(pipe=0, data=9, model=0): 9, ProcessCoord(pipe=0, data=10, model=0): 10, ProcessCoord(pipe=0, data=11, model=0): 11, ProcessCoord(pipe=0, data=12, model=0): 12, ProcessCoord(pipe=0, data=13, model=0): 13, ProcessCoord(pipe=0, data=14, model=0): 14, ProcessCoord(pipe=0, data=15, model=0): 15, ProcessCoord(pipe=0, data=16, model=0): 16, ProcessCoord(pipe=0, data=17, model=0): 17, ProcessCoord(pipe=0, data=18, model=0): 18, ProcessCoord(pipe=0, data=19, model=0): 19, ProcessCoord(pipe=0, data=20, model=0): 20, ProcessCoord(pipe=0, data=21, model=0): 21, ProcessCoord(pipe=0, data=22, model=0): 22, ProcessCoord(pipe=0, data=23, model=0): 23, ProcessCoord(pipe=0, data=24, model=0): 24, ProcessCoord(pipe=0, data=25, model=0): 25, ProcessCoord(pipe=0, data=26, model=0): 26, ProcessCoord(pipe=0, data=27, model=0): 27, ProcessCoord(pipe=0, data=28, model=0): 28, ProcessCoord(pipe=0, data=29, model=0): 29, ProcessCoord(pipe=0, data=30, model=0): 30, ProcessCoord(pipe=0, data=31, model=0): 31, ProcessCoord(pipe=1, data=0, model=0): 32, ProcessCoord(pipe=1, data=1, model=0): 33, ProcessCoord(pipe=1, data=2, model=0): 34, ProcessCoord(pipe=1, data=3, model=0): 35, ProcessCoord(pipe=1, data=4, model=0): 36, ProcessCoord(pipe=1, data=5, model=0): 37, ProcessCoord(pipe=1, data=6, model=0): 38, ProcessCoord(pipe=1, data=7, model=0): 39, ProcessCoord(pipe=1, data=8, model=0): 40, ProcessCoord(pipe=1, data=9, model=0): 41, ProcessCoord(pipe=1, data=10, model=0): 42, ProcessCoord(pipe=1, data=11, model=0): 43, ProcessCoord(pipe=1, data=12, model=0): 44, ProcessCoord(pipe=1, data=13, model=0): 45, ProcessCoord(pipe=1, data=14, model=0): 46, ProcessCoord(pipe=1, data=15, model=0): 47, ProcessCoord(pipe=1, data=16, model=0): 48, ProcessCoord(pipe=1, data=17, model=0): 49, ProcessCoord(pipe=1, data=18, model=0): 50, ProcessCoord(pipe=1, data=19, model=0): 51, ProcessCoord(pipe=1, data=20, model=0): 52, ProcessCoord(pipe=1, data=21, model=0): 53, ProcessCoord(pipe=1, data=22, model=0): 54, ProcessCoord(pipe=1, data=23, model=0): 55, ProcessCoord(pipe=1, data=24, model=0): 56, ProcessCoord(pipe=1, data=25, model=0): 57, ProcessCoord(pipe=1, data=26, model=0): 58, ProcessCoord(pipe=1, data=27, model=0): 59, ProcessCoord(pipe=1, data=28, model=0): 60, ProcessCoord(pipe=1, data=29, model=0): 61, ProcessCoord(pipe=1, data=30, model=0): 62, ProcessCoord(pipe=1, data=31, model=0): 63}
[default0]:[2024-04-23 16:05:17,027] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer
[default0]:stage=0 layers=18
[default0]:     0: _to_float16
[default0]:     1: EmbeddingPipe
[default0]:     2: ParallelTransformerLayerPipe
[default0]:     3: ParallelTransformerLayerPipe
[default0]:     4: ParallelTransformerLayerPipe
[default0]:     5: ParallelTransformerLayerPipe
[default0]:     6: ParallelTransformerLayerPipe
[default0]:     7: ParallelTransformerLayerPipe
[default0]:     8: ParallelTransformerLayerPipe
[default0]:     9: ParallelTransformerLayerPipe
[default0]:    10: ParallelTransformerLayerPipe
[default0]:    11: ParallelTransformerLayerPipe
[default0]:    12: ParallelTransformerLayerPipe
[default0]:    13: ParallelTransformerLayerPipe
[default0]:    14: ParallelTransformerLayerPipe
[default0]:    15: ParallelTransformerLayerPipe
[default0]:    16: ParallelTransformerLayerPipe
[default0]:    17: ParallelTransformerLayerPipe
[default0]:stage=1 layers=19
[default0]:    18: ParallelTransformerLayerPipe
[default0]:    19: ParallelTransformerLayerPipe
[default0]:    20: ParallelTransformerLayerPipe
[default0]:    21: ParallelTransformerLayerPipe
[default0]:    22: ParallelTransformerLayerPipe
[default0]:    23: ParallelTransformerLayerPipe
[default0]:    24: ParallelTransformerLayerPipe
[default0]:    25: ParallelTransformerLayerPipe
[default0]:    26: ParallelTransformerLayerPipe
[default0]:    27: ParallelTransformerLayerPipe
[default0]:    28: ParallelTransformerLayerPipe
[default0]:    29: ParallelTransformerLayerPipe
[default0]:    30: ParallelTransformerLayerPipe
[default0]:    31: ParallelTransformerLayerPipe
[default0]:    32: ParallelTransformerLayerPipe
[default0]:    33: ParallelTransformerLayerPipe
[default0]:    34: MixedFusedRMSNorm
[default0]:    35: LMHeadPipe
[default0]:    36: float16_to_fp32
[default0]:  loss: CrossEntropy
[default0]:[2024-04-23 16:05:17,271] [INFO] [utils.py:791:see_memory_usage] After Building Model
[default0]:[2024-04-23 16:05:17,271] [INFO] [utils.py:792:see_memory_usage] MA 6.29 GB         Max_MA 6.31 GB         CA 6.31 GB         Max_CA 6 GB 
[default0]:[2024-04-23 16:05:17,272] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 30.79 GB, percent = 6.1%
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 3369205760
[default0]: > total number of parameters in model: 3369205760
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2024-04-23 16:05:17,273] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown
[default0]:[2024-04-23 16:05:20,627] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2024-04-23 16:05:20,627] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2024-04-23 16:05:20,627] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[default0]:[2024-04-23 16:05:20,628] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2024-04-23 16:05:20,628] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[default1]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,707] [INFO] [utils.py:791:see_memory_usage] begin bf16_optimizer
[default0]:[2024-04-23 16:05:20,708] [INFO] [utils.py:792:see_memory_usage] MA 6.28 GB         Max_MA 6.29 GB         CA 6.31 GB         Max_CA 6 GB 
[default0]:[2024-04-23 16:05:20,708] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 31.35 GB, percent = 6.2%
[default0]:[2024-04-23 16:05:20,769] [INFO] [utils.py:791:see_memory_usage] before initializing group 0
[default0]:[2024-04-23 16:05:20,770] [INFO] [utils.py:792:see_memory_usage] MA 6.28 GB         Max_MA 6.28 GB         CA 6.31 GB         Max_CA 6 GB 
[default0]:[2024-04-23 16:05:20,770] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 31.35 GB, percent = 6.2%
[default6]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default2]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default3]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,913] [INFO] [utils.py:791:see_memory_usage] after initializing group 0
[default0]:[2024-04-23 16:05:20,913] [INFO] [utils.py:792:see_memory_usage] MA 19.22 GB         Max_MA 19.22 GB         CA 25.53 GB         Max_CA 26 GB 
[default0]:[2024-04-23 16:05:20,913] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 31.48 GB, percent = 6.3%
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-23 16:04:05,731] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,728] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,725] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,715] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,729] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,734] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:04:06,713] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,713] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 3369209856
[default0]: > total number of parameters in model: 3369209856
[default1]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default3]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default6]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default2]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
KAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[2024-04-23 16:05:20,982] [INFO] [utils.py:791:see_memory_usage] before initializing group 1
[default0]:[2024-04-23 16:05:20,982] [INFO] [utils.py:792:see_memory_usage] MA 19.22 GB         Max_MA 19.22 GB         CA 25.53 GB         Max_CA 26 GB 
[default0]:[2024-04-23 16:05:20,982] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.02 GB, percent = 6.4%
[default0]:[2024-04-23 16:05:21,052] [INFO] [utils.py:791:see_memory_usage] after initializing group 1
[default0]:[2024-04-23 16:05:21,053] [INFO] [utils.py:792:see_memory_usage] MA 19.22 GB         Max_MA 19.22 GB         CA 25.53 GB         Max_CA 26 GB 
[default0]:[2024-04-23 16:05:21,053] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.04 GB, percent = 6.4%
[default0]:[2024-04-23 16:05:21,112] [INFO] [utils.py:791:see_memory_usage] before initialize_optimizer
[default0]:[2024-04-23 16:05:21,112] [INFO] [utils.py:792:see_memory_usage] MA 19.22 GB         Max_MA 19.22 GB         CA 25.53 GB         Max_CA 26 GB 
[default0]:[2024-04-23 16:05:21,112] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.08 GB, percent = 6.4%
[default0]:[2024-04-23 16:05:21,222] [INFO] [utils.py:791:see_memory_usage] end initialize_optimizer
[default0]:[2024-04-23 16:05:21,222] [INFO] [utils.py:792:see_memory_usage] MA 20.01 GB         Max_MA 20.01 GB         CA 26.31 GB         Max_CA 26 GB 
[default0]:[2024-04-23 16:05:21,222] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.73 GB, percent = 6.5%
[default0]:[2024-04-23 16:05:21,282] [INFO] [utils.py:791:see_memory_usage] end bf16_optimizer
[default0]:[2024-04-23 16:05:21,283] [INFO] [utils.py:792:see_memory_usage] MA 20.01 GB         Max_MA 20.01 GB         CA 26.31 GB         Max_CA 26 GB 
[default0]:[2024-04-23 16:05:21,283] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.73 GB, percent = 6.5%
[default0]:[2024-04-23 16:05:21,283] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2024-04-23 16:05:21,283] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2024-04-23 16:05:21,283] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x15411f859300>
[default0]:[2024-04-23 16:05:21,283] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2024-04-23 16:05:21,283] [INFO] [config.py:984:print] DeepSpeedEngine configuration:
[default0]:[2024-04-23 16:05:21,283] [INFO] [config.py:988:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   amp_enabled .................. False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   amp_params ................... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   bfloat16_enabled ............. True
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15411f859b40>
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   communication_data_type ...... None
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   dataloader_drop_last ......... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   disable_allgather ............ False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   dump_state ................... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-23 16:04:05,728] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,732] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,750] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,732] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,743] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,755] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,733] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:04:06,750] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default1]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default2]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default6]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-23 16:04:05,728] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,714] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:04:06,728] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,715] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,733] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,721] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,720] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,721] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:05:20,691] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:[2024-04-23 16:05:20,691] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default1]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default2]:[2024-04-23 16:05:20,691] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default3]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default6]:[2024-04-23 16:05:20,691] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,691] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-23 16:04:05,728] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:04:06,727] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,732] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,723] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,723] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,734] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,708] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,733] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default2]:[2024-04-23 16:05:20,691] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default3]:[2024-04-23 16:05:20,689] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default6]:[2024-04-23 16:05:20,691] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default1]:[2024-04-23 16:05:20,688] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,690] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   elasticity_enabled ........... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "recompute_fwd_factor": 0.0, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   fp16_auto_cast ............... None
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   fp16_enabled ................. False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   global_rank .................. 0
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 4
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   gradient_clipping ............ 0.0
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   graph_harvesting ............. False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 1
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   load_universal_checkpoint .... False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   loss_scale ................... 1.0
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   memory_breakdown ............. False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False
[default0]:[2024-04-23 16:05:21,284] [INFO] [config.py:988:print]   mics_shard_size .............. -1
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   optimizer_name ............... None
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   optimizer_params ............. None
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   pld_enabled .................. False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   pld_params ................... False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   prescale_gradients ........... False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   scheduler_name ............... None
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   scheduler_params ............. None
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   sparse_attention ............. None
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   steps_per_print .............. 1
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   train_batch_size ............. 512
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  4
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   use_node_local_storage ....... False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   weight_quantization_config ... None
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   world_size ................... 32
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   zero_enabled ................. False
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:988:print]   zero_optimization_stage ...... 0
[default0]:[2024-04-23 16:05:21,285] [INFO] [config.py:974:print_user_config]   json = {
[default0]:    "train_batch_size": 512, 
[default0]:    "train_micro_batch_size_per_gpu": 4, 
[default0]:    "steps_per_print": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 0
[default0]:    }, 
[default0]:    "bf16": {
[default0]:        "enabled": true
[default0]:    }
[default0]:}
[default0]:[2024-04-23 16:05:21,285] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=4 micro_batch_size=4
[default0]:[2024-04-23 16:05:21,285] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:21,343] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=18 [0, 18) STAGE_PARAMS=3369205760 (3369.206M) TOTAL_PARAMS=6738415616 (6738.416M) UNIQUE_PARAMS=6738415616 (6738.416M)
[default1]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-23 16:04:05,729] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:04:06,750] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,744] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,750] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,749] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,749] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,714] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,717] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:05:20,754] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[2024-04-23 16:05:20,754] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default6]:[2024-04-23 16:05:20,753] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:[2024-04-23 16:05:20,754] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default1]:[2024-04-23 16:05:20,753] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,754] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,755] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default3]:[2024-04-23 16:05:20,753] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default2]:[2024-04-23 16:05:21,426] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-23 16:04:05,729] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,689] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,685] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:04:06,713] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,723] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,707] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,696] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,718] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:05:20,714] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default6]:[2024-04-23 16:05:20,713] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,714] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default1]:[2024-04-23 16:05:20,713] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default3]:[2024-04-23 16:05:20,715] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:[2024-04-23 16:05:20,714] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default0]:[2024-04-23 16:05:20,714] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[2024-04-23 16:05:20,714] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-23 16:04:05,725] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-23 16:04:06,730] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-23 16:04:06,726] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-23 16:04:06,734] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-23 16:04:06,716] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-23 16:04:06,734] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-23 16:04:06,718] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-23 16:04:06,726] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default1]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default3]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default2]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default7]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default5]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default6]:[2024-04-23 16:05:20,745] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file /gpfswork/rech/qgz/urc37ho/checkpoints10121/ 
[default0]:    will not load any checkpoints and will start from random
[default2]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-23 16:05:21,416] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2024-04-23 16:05:21 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      128000000
[default0]:    validation: 1280512
[default0]:    test:       512
[default0]:> building train, validation, and test datasets for GPT ...
[default0]:Single data path provided for train, valid & test
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.010945 seconds
[default0]:    number of documents: 32615
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 31604) total of 31604 documents
[default0]:    validation:
[default0]:     document indices in [31604, 32582) total of 978 documents
[default0]:    test:
[default0]:     document indices in [32582, 32615) total of 33 documents
[default0]: > loading doc-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/e7aa0c922fff9c4424379934e7fe7de2_doc_idx.npy
[default0]: > loading sample-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/e7aa0c922fff9c4424379934e7fe7de2_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/e7aa0c922fff9c4424379934e7fe7de2_shuffle_idx.npy
[default0]:    loaded indexed file in 0.182 seconds
[default0]:    total number of samples: 128006360
[default0]:    total number of epochs: 14270
[default0]: > loading doc-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/c275a0f72fbd513748353ed84e20145e_doc_idx.npy
[default0]: > loading sample-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/c275a0f72fbd513748353ed84e20145e_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/c275a0f72fbd513748353ed84e20145e_shuffle_idx.npy
[default0]:    loaded indexed file in 0.152 seconds
[default0]:    total number of samples: 1280576
[default0]:    total number of epochs: 4875
[default0]: > loading doc-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/872083804bb1649e5fba30131cbda76c_doc_idx.npy
[default0]: > loading sample-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/872083804bb1649e5fba30131cbda76c_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/872083804bb1649e5fba30131cbda76c_shuffle_idx.npy
[default0]:    loaded indexed file in 0.021 seconds
[default0]:    total number of samples: 517
[default0]:    total number of epochs: 72
[default0]:> finished creating GPT datasets ...
[default0]:[after dataloaders are built] datetime: 2024-04-23 16:05:27 
[default0]:done with setup ...
[default0]:training ...
[default0]:[before the start of training step] datetime: 2024-04-23 16:05:27 
[default0]:[2024-04-23 16:05:37,059] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[1.5e-07, 1.5e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 1 loss: 11.2002 iter time (s): 10.036 samples/sec: 51.018
[default0]:[Rank 0] (after 1 iterations) memory (MB) | allocated: 27004.55078125 | max allocated: 70038.7060546875 | reserved: 77998.0 | max reserved: 77998.0
[default0]:[2024-04-23 16:05:45,562] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[3e-07, 3e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 2 loss: 11.1971 iter time (s): 8.132 samples/sec: 62.963
[default0]:[2024-04-23 16:05:53,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=0, lr=[4.5e-07, 4.5e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 3 loss: 11.1975 iter time (s): 8.195 samples/sec: 62.475
[default0]:[2024-04-23 16:06:02,057] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=0, lr=[6e-07, 6e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 4 loss: 11.1956 iter time (s): 8.284 samples/sec: 61.804
[default0]:[2024-04-23 16:06:10,255] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[7.499999999999999e-07, 7.499999999999999e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 5 loss: 11.1818 iter time (s): 8.200 samples/sec: 62.440
[default0]:[2024-04-23 16:06:18,485] [INFO] [logging.py:96:log_dist] [Rank 0] step=6, skipped=0, lr=[9e-07, 9e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 6 loss: 11.1264 iter time (s): 8.213 samples/sec: 62.343
[default0]:[2024-04-23 16:06:26,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=7, skipped=0, lr=[1.05e-06, 1.05e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 7 loss: 10.9664 iter time (s): 8.293 samples/sec: 61.739
[default0]:[2024-04-23 16:06:35,035] [INFO] [logging.py:96:log_dist] [Rank 0] step=8, skipped=0, lr=[1.2e-06, 1.2e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 8 loss: 10.8469 iter time (s): 8.248 samples/sec: 62.077
[default0]:[2024-04-23 16:06:43,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=9, skipped=0, lr=[1.3499999999999998e-06, 1.3499999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 9 loss: 10.4751 iter time (s): 8.435 samples/sec: 60.700
[default0]:[2024-04-23 16:06:51,656] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.4999999999999998e-06, 1.4999999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 10 loss: 10.3625 iter time (s): 8.172 samples/sec: 62.656
[default0]:[2024-04-23 16:06:59,981] [INFO] [logging.py:96:log_dist] [Rank 0] step=11, skipped=0, lr=[1.6499999999999999e-06, 1.6499999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 11 loss: 10.2015 iter time (s): 8.308 samples/sec: 61.630
[default0]:[2024-04-23 16:07:08,361] [INFO] [logging.py:96:log_dist] [Rank 0] step=12, skipped=0, lr=[1.8e-06, 1.8e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default2]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:(min, max) time across ranks (ms):
[default7]:    load-checkpoint ................................: (10.19, 10.35)
[default7]:(min, max) time across ranks (ms):
[default7]:    model-and-optimizer-setup ......................: (4686.67, 4710.03)
[default7]:    train/valid/test-data-iterators-setup ..........: (3857.43, 5607.20)
[default7]: iteration        1/  250000 | consumed samples:          512 | consumed tokens:      1048576 | elapsed time per iteration (ms): 10114.5 | learning rate: 1.500E-07 | global batch size:   512 | lm loss: 1.120017E+01 | grad norm: 17.951 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 50.620 | TFLOPs: 68.79 |
[default7]: iteration        2/  250000 | consumed samples:         1024 | consumed tokens:      2097152 | elapsed time per iteration (ms): 8142.3 | learning rate: 3.000E-07 | global batch size:   512 | lm loss: 1.119708E+01 | grad norm: 18.221 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.882 | TFLOPs: 85.45 |
[default7]: iteration        3/  250000 | consumed samples:         1536 | consumed tokens:      3145728 | elapsed time per iteration (ms): 8200.0 | learning rate: 4.500E-07 | global batch size:   512 | lm loss: 1.119752E+01 | grad norm: 17.614 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.439 | TFLOPs: 84.85 |
[default7]: iteration        4/  250000 | consumed samples:         2048 | consumed tokens:      4194304 | elapsed time per iteration (ms): 8296.9 | learning rate: 6.000E-07 | global batch size:   512 | lm loss: 1.119564E+01 | grad norm: 17.917 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.710 | TFLOPs: 83.86 |
[default7]: iteration        5/  250000 | consumed samples:         2560 | consumed tokens:      5242880 | elapsed time per iteration (ms): 8204.2 | learning rate: 7.500E-07 | global batch size:   512 | lm loss: 1.118181E+01 | grad norm: 18.297 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.407 | TFLOPs: 84.80 |
[default7]: iteration        6/  250000 | consumed samples:         3072 | consumed tokens:      6291456 | elapsed time per iteration (ms): 8218.8 | learning rate: 9.000E-07 | global batch size:   512 | lm loss: 1.112641E+01 | grad norm: 18.559 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.296 | TFLOPs: 84.65 |
[default7]: iteration        7/  250000 | consumed samples:         3584 | consumed tokens:      7340032 | elapsed time per iteration (ms): 8308.0 | learning rate: 1.050E-06 | global batch size:   512 | lm loss: 1.096636E+01 | grad norm: 17.213 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.627 | TFLOPs: 83.75 |
[default7]: iteration        8/  250000 | consumed samples:         4096 | consumed tokens:      8388608 | elapsed time per iteration (ms): 8252.2 | learning rate: 1.200E-06 | global batch size:   512 | lm loss: 1.084686E+01 | grad norm: 20.751 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.044 | TFLOPs: 84.31 |
[default7]: iteration        9/  250000 | consumed samples:         4608 | consumed tokens:      9437184 | elapsed time per iteration (ms): 8439.4 | learning rate: 1.350E-06 | global batch size:   512 | lm loss: 1.047510E+01 | grad norm: 16.208 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.667 | TFLOPs: 82.44 |
[default7]: iteration       10/  250000 | consumed samples:         5120 | consumed tokens:     10485760 | elapsed time per iteration (ms): 8185.3 | learning rate: 1.500E-06 | global batch size:   512 | lm loss: 1.036245E+01 | grad norm: 17.039 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.551 | TFLOPs: 85.00 |
[default7]: iteration       11/  250000 | consumed samples:         5632 | consumed tokens:     11534336 | elapsed time per iteration (ms): 8312.8 | learning rate: 1.650E-06 | global batch size:   512 | lm loss: 1.020150E+01 | grad norm: 17.432 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.591 | TFLOPs: 83.70 |
[default7]: iteration       12/  250000 | consumed samples:         6144 | consumed tokens:     12582912 | elapsed time per iteration (ms): 8384.7 | learning rate: 1.800E-06 | global batch size:   512 | lm loss: 9.843719E+00 | grad norm: 33.056 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.064 | TFLOPs: 82.98 |
[default7]: iteration       13/  250000 | consumed samples:         6656 | consumed tokens:     13631488 | elapsed time per iteration (ms): 8358.7 | learning rate: 1.950E-06 | global batch size:   512 | lm loss: 9.522295E+00 | grad norm: 24.646 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.253 | TFLOPs: 83.24 |
[default7]: iteration       14/  250000 | consumed samples:         7168 | consumed tokens:     14680064 | elapsed time per iteration (ms): 8210.7 | learning rate: 2.100E-06 | global batch size:   512 | lm loss: 9.310585E+00 | grad norm: 17.532 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.357 | TFLOPs: 84.74 |
[default7]: iteration       15/  250000 | consumed samples:         7680 | consumed tokens:     15728640 | elapsed time per iteration (ms): 8263.3 | learning rate: 2.250E-06 | global batch size:   512 | lm loss: 9.105361E+00 | grad norm: 25.006 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.960 | TFLOPs: 84.20 |
[default7]: iteration       16/  250000 | consumed samples:         8192 | consumed tokens:     16777216 | elapsed time per iteration (ms): 8298.7 | learning rate: 2.400E-06 | global batch size:   512 | lm loss: 8.899970E+00 | grad norm: 20.918 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.696 | TFLOPs: 83.84 |
[default7]: iteration       17/  250000 | consumed samples:         8704 | consumed tokens:     17825792 | elapsed time per iteration (ms): 8311.9 | learning rate: 2.550E-06 | global batch size:   512 | lm loss: 8.780151E+00 | grad norm: 17.954 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.598 | TFLOPs: 83.71 |
[default7]: iteration       18/  250000 | consumed samples:         9216 | consumed tokens:     18874368 | elapsed time per iteration (ms): 8338.8 | learning rate: 2.700E-06 | global batch size:   512 | lm loss: 8.558410E+00 | grad norm: 17.705 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.400 | TFLOPs: 83.44 |
[default7]: iteration       19/  250000 | consumed samples:         9728 | consumed tokens:     19922944 | elapsed time per iteration (ms): 8156.4 | learning rate: 2.850E-06 | global batch size:   512 | lm loss: 8.488734E+00 | grad norm: 21.324 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.773 | TFLOPs: 85.30 |
[default7]: iteration       20/  250000 | consumed samples:        10240 | consumed tokens:     20971520 | elapsed time per iteration (ms): 8353.3 | learning rate: 3.000E-06 | global batch size:   512 | lm loss: 8.432878E+00 | grad norm: 16.351 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.293 | TFLOPs: 83.29 |
[default7]: iteration       21/  250000 | consumed samples:        10752 | consumed tokens:     22020096 | elapsed time per iteration (ms): 8338.6 | learning rate: 3.150E-06 | global batch size:   512 | lm loss: 8.194088E+00 | grad norm: 17.601 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.401 | TFLOPs: 83.44 |
[default7]: iteration       22/  250000 | consumed samples:        11264 | consumed tokens:     23068672 | elapsed time per iteration (ms): 8372.6 | learning rate: 3.300E-06 | global batch size:   512 | lm loss: 8.134376E+00 | grad norm: 17.991 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.152 | TFLOPs: 83.10 |
[default7]: iteration       23/  250000 | consumed samples:        11776 | consumed tokens:     24117248 | elapsed time per iteration (ms): 8161.4 | learning rate: 3.450E-06 | global batch size:   512 | lm loss: 8.087173E+00 | grad norm: 16.037 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.735 | TFLOPs: 85.25 |
[default7]: iteration       24/  250000 | consumed samples:        12288 | consumed tokens:     25165824 | elapsed time per iteration (ms): 8305.1 | learning rate: 3.600E-06 | global batch size:   512 | lm loss: 7.973110E+00 | grad norm: 14.315 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.649 | TFLOPs: 83.77 |
[default7]: iteration       25/  250000 | consumed samples:        12800 | consumed tokens:     26214400 | elapsed time per iteration (ms): 8212.6 | learning rate: 3.750E-06 | global batch size:   512 | lm loss: 7.944541E+00 | grad norm: 16.512 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.343 | TFLOPs: 84.72 |
[default7]: iteration       26/  250000 | consumed samples:        13312 | consumed tokens:     27262976 | elapsed time per iteration (ms): 8164.4 | learning rate: 3.900E-06 | global batch size:   512 | lm loss: 7.795149E+00 | grad norm: 11.538 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.711 | TFLOPs: 85.22 |
[default7]: iteration       27/  250000 | consumed samples:        13824 | consumed tokens:     28311552 | elapsed time per iteration (ms): 8345.6 | learning rate: 4.050E-06 | global batch size:   512 | lm loss: 7.708087E+00 | grad norm: 10.840 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.350 | TFLOPs: 83.37 |
[default7]: iteration       28/  250000 | consumed samples:        14336 | consumed tokens:     29360128 | elapsed time per iteration (ms): 8389.6 | learning rate: 4.200E-06 | global batch size:   512 | lm loss: 7.650069E+00 | grad norm: 9.727 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.028 | TFLOPs: 82.93 |
[default7]: iteration       29/  250000 | consumed samples:        14848 | consumed tokens:     30408704 | elapsed time per iteration (ms): 8170.4 | learning rate: 4.350E-06 | global batch size:   512 | lm loss: 7.665982E+00 | grad norm: 8.622 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.665 | TFLOPs: 85.16 |
[default7]: iteration       30/  250000 | consumed samples:        15360 | consumed tokens:     31457280 | elapsed time per iteration (ms): 8408.6 | learning rate: 4.500E-06 | global batch size:   512 | lm loss: 7.570687E+00 | grad norm: 9.591 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.890 | TFLOPs: 82.74 |
[default7]: iteration       31/  250000 | consumed samples:        15872 | consumed tokens:     32505856 | elapsed time per iteration (ms): 8211.7 | learning rate: 4.650E-06 | global batch size:   512 | lm loss: 7.470266E+00 | grad norm: 7.849 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.350 | TFLOPs: 84.73 |
[default7]: iteration       32/  250000 | consumed samples:        16384 | consumed tokens:     33554432 | elapsed time per iteration (ms): 8349.2 | learning rate: 4.800E-06 | global batch size:   512 | lm loss: 7.410705E+00 | grad norm: 9.104 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.323 | TFLOPs: 83.33 |
[default7]: iteration       33/  250000 | consumed samples:        16896 | consumed tokens:     34603008 | elapsed time per iteration (ms): 8390.9 | learning rate: 4.950E-06 | global batch size:   512 | lm loss: 7.445461E+00 | grad norm: 6.713 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.018 | TFLOPs: 82.92 |
[default0]:steps: 12 loss: 9.8437 iter time (s): 8.379 samples/sec: 61.108
[default0]:[2024-04-23 16:07:16,720] [INFO] [logging.py:96:log_dist] [Rank 0] step=13, skipped=0, lr=[1.95e-06, 1.95e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 13 loss: 9.5223 iter time (s): 8.352 samples/sec: 61.302
[default0]:[2024-04-23 16:07:24,920] [INFO] [logging.py:96:log_dist] [Rank 0] step=14, skipped=0, lr=[2.1e-06, 2.1e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 14 loss: 9.3106 iter time (s): 8.196 samples/sec: 62.471
[default0]:[2024-04-23 16:07:33,185] [INFO] [logging.py:96:log_dist] [Rank 0] step=15, skipped=0, lr=[2.2499999999999996e-06, 2.2499999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 15 loss: 9.1054 iter time (s): 8.258 samples/sec: 62.000
[default0]:[2024-04-23 16:07:41,512] [INFO] [logging.py:96:log_dist] [Rank 0] step=16, skipped=0, lr=[2.4e-06, 2.4e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 16 loss: 8.9000 iter time (s): 8.289 samples/sec: 61.768
[default0]:[2024-04-23 16:07:49,798] [INFO] [logging.py:96:log_dist] [Rank 0] step=17, skipped=0, lr=[2.5499999999999997e-06, 2.5499999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 17 loss: 8.7802 iter time (s): 8.307 samples/sec: 61.635
[default0]:[2024-04-23 16:07:58,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=18, skipped=0, lr=[2.6999999999999996e-06, 2.6999999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 18 loss: 8.5584 iter time (s): 8.333 samples/sec: 61.445
[default0]:[2024-04-23 16:08:06,314] [INFO] [logging.py:96:log_dist] [Rank 0] step=19, skipped=0, lr=[2.85e-06, 2.85e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 19 loss: 8.4887 iter time (s): 8.152 samples/sec: 62.808
[default0]:[2024-04-23 16:08:14,669] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[2.9999999999999997e-06, 2.9999999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 20 loss: 8.4329 iter time (s): 8.348 samples/sec: 61.329
[default0]:[2024-04-23 16:08:23,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=21, skipped=0, lr=[3.1499999999999995e-06, 3.1499999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 21 loss: 8.1941 iter time (s): 8.334 samples/sec: 61.433
[default0]:[2024-04-23 16:08:31,393] [INFO] [logging.py:96:log_dist] [Rank 0] step=22, skipped=0, lr=[3.2999999999999997e-06, 3.2999999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 22 loss: 8.1344 iter time (s): 8.367 samples/sec: 61.195
[default0]:[2024-04-23 16:08:39,555] [INFO] [logging.py:96:log_dist] [Rank 0] step=23, skipped=0, lr=[3.4499999999999996e-06, 3.4499999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 23 loss: 8.0872 iter time (s): 8.157 samples/sec: 62.769
[default0]:[2024-04-23 16:08:47,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=24, skipped=0, lr=[3.6e-06, 3.6e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 24 loss: 7.9731 iter time (s): 8.301 samples/sec: 61.683
[default0]:[2024-04-23 16:08:56,071] [INFO] [logging.py:96:log_dist] [Rank 0] step=25, skipped=0, lr=[3.7499999999999997e-06, 3.7499999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 25 loss: 7.9445 iter time (s): 8.200 samples/sec: 62.436
[default0]:[2024-04-23 16:09:04,230] [INFO] [logging.py:96:log_dist] [Rank 0] step=26, skipped=0, lr=[3.9e-06, 3.9e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 26 loss: 7.7951 iter time (s): 8.160 samples/sec: 62.744
[default0]:[2024-04-23 16:09:12,583] [INFO] [logging.py:96:log_dist] [Rank 0] step=27, skipped=0, lr=[4.05e-06, 4.05e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 27 loss: 7.7081 iter time (s): 8.341 samples/sec: 61.386
[default0]:[2024-04-23 16:09:20,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=28, skipped=0, lr=[4.2e-06, 4.2e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 28 loss: 7.6501 iter time (s): 8.383 samples/sec: 61.075
[default0]:[2024-04-23 16:09:29,150] [INFO] [logging.py:96:log_dist] [Rank 0] step=29, skipped=0, lr=[4.35e-06, 4.35e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 29 loss: 7.6660 iter time (s): 8.166 samples/sec: 62.699
[default0]:[2024-04-23 16:09:37,549] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[4.499999999999999e-06, 4.499999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 30 loss: 7.5707 iter time (s): 8.403 samples/sec: 60.931
[default0]:[2024-04-23 16:09:45,772] [INFO] [logging.py:96:log_dist] [Rank 0] step=31, skipped=0, lr=[4.6499999999999995e-06, 4.6499999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 31 loss: 7.4703 iter time (s): 8.207 samples/sec: 62.384
[default0]:[2024-04-23 16:09:54,110] [INFO] [logging.py:96:log_dist] [Rank 0] step=32, skipped=0, lr=[4.8e-06, 4.8e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 32 loss: 7.4107 iter time (s): 8.345 samples/sec: 61.356
[default0]:[2024-04-23 16:10:02,504] [INFO] [logging.py:96:log_dist] [Rank 0] step=33, skipped=0, lr=[4.949999999999999e-06, 4.949999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 33 loss: 7.4455 iter time (s): 8.386 samples/sec: 61.053
[default0]:[2024-04-23 16:10:10,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=34, skipped=0, lr=[5.0999999999999995e-06, 5.0999999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 34 loss: 7.3658 iter time (s): 8.391 samples/sec: 61.021
[default0]:[2024-04-23 16:10:19,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=35, skipped=0, lr=[5.25e-06, 5.25e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 35 loss: 7.3470 iter time (s): 8.280 samples/sec: 61.839
[default0]:[2024-04-23 16:10:27,618] [INFO] [logging.py:96:log_dist] [Rank 0] step=36, skipped=0, lr=[5.399999999999999e-06, 5.399999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 36 loss: 7.2578 iter time (s): 8.420 samples/sec: 60.807
[default0]:[2024-04-23 16:10:35,839] [INFO] [logging.py:96:log_dist] [Rank 0] step=37, skipped=0, lr=[5.549999999999999e-06, 5.549999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 37 loss: 7.2027 iter time (s): 8.221 samples/sec: 62.281
[default0]:[2024-04-23 16:10:44,089] [INFO] [logging.py:96:log_dist] [Rank 0] step=38, skipped=0, lr=[5.7e-06, 5.7e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 38 loss: 7.2587 iter time (s): 8.226 samples/sec: 62.243
[default0]:[2024-04-23 16:10:52,302] [INFO] [logging.py:96:log_dist] [Rank 0] step=39, skipped=0, lr=[5.849999999999999e-06, 5.849999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 39 loss: 7.1945 iter time (s): 8.212 samples/sec: 62.349
[default0]:[2024-04-23 16:11:00,448] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[5.999999999999999e-06, 5.999999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 40 loss: 7.2798 iter time (s): 8.140 samples/sec: 62.901
[default0]:[2024-04-23 16:11:08,787] [INFO] [logging.py:96:log_dist] [Rank 0] step=41, skipped=0, lr=[6.1499999999999996e-06, 6.1499999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 41 loss: 7.1082 iter time (s): 8.337 samples/sec: 61.414
[default0]:[2024-04-23 16:11:17,126] [INFO] [logging.py:96:log_dist] [Rank 0] step=42, skipped=0, lr=[6.299999999999999e-06, 6.299999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 42 loss: 7.1222 iter time (s): 8.326 samples/sec: 61.493
[default0]:[2024-04-23 16:11:25,432] [INFO] [logging.py:96:log_dist] [Rank 0] step=43, skipped=0, lr=[6.449999999999999e-06, 6.449999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 43 loss: 7.0640 iter time (s): 8.303 samples/sec: 61.664
[default0]:[2024-04-23 16:11:33,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=44, skipped=0, lr=[6.5999999999999995e-06, 6.5999999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 44 loss: 6.9910 iter time (s): 8.295 samples/sec: 61.721
[default0]:[2024-04-23 16:11:42,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=45, skipped=0, lr=[6.749999999999999e-06, 6.749999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 45 loss: 7.0516 iter time (s): 8.262 samples/sec: 61.968
[default7]: iteration       34/  250000 | consumed samples:        17408 | consumed tokens:     35651584 | elapsed time per iteration (ms): 8396.6 | learning rate: 5.100E-06 | global batch size:   512 | lm loss: 7.365846E+00 | grad norm: 7.520 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.977 | TFLOPs: 82.86 |
[default7]: iteration       35/  250000 | consumed samples:        17920 | consumed tokens:     36700160 | elapsed time per iteration (ms): 8285.3 | learning rate: 5.250E-06 | global batch size:   512 | lm loss: 7.346951E+00 | grad norm: 6.750 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.797 | TFLOPs: 83.98 |
[default7]: iteration       36/  250000 | consumed samples:        18432 | consumed tokens:     37748736 | elapsed time per iteration (ms): 8431.6 | learning rate: 5.400E-06 | global batch size:   512 | lm loss: 7.257849E+00 | grad norm: 6.618 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.724 | TFLOPs: 82.52 |
[default7]: iteration       37/  250000 | consumed samples:        18944 | consumed tokens:     38797312 | elapsed time per iteration (ms): 8226.3 | learning rate: 5.550E-06 | global batch size:   512 | lm loss: 7.202679E+00 | grad norm: 5.867 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.239 | TFLOPs: 84.58 |
[default7]: iteration       38/  250000 | consumed samples:        19456 | consumed tokens:     39845888 | elapsed time per iteration (ms): 8230.2 | learning rate: 5.700E-06 | global batch size:   512 | lm loss: 7.258695E+00 | grad norm: 5.313 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.210 | TFLOPs: 84.54 |
[default7]: iteration       39/  250000 | consumed samples:        19968 | consumed tokens:     40894464 | elapsed time per iteration (ms): 8218.5 | learning rate: 5.850E-06 | global batch size:   512 | lm loss: 7.194516E+00 | grad norm: 5.156 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.298 | TFLOPs: 84.66 |
[default7]: iteration       40/  250000 | consumed samples:        20480 | consumed tokens:     41943040 | elapsed time per iteration (ms): 8144.7 | learning rate: 6.000E-06 | global batch size:   512 | lm loss: 7.279777E+00 | grad norm: 5.204 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.863 | TFLOPs: 85.42 |
[default7]: iteration       41/  250000 | consumed samples:        20992 | consumed tokens:     42991616 | elapsed time per iteration (ms): 8341.9 | learning rate: 6.150E-06 | global batch size:   512 | lm loss: 7.108162E+00 | grad norm: 5.724 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.377 | TFLOPs: 83.41 |
[default7]: iteration       42/  250000 | consumed samples:        21504 | consumed tokens:     44040192 | elapsed time per iteration (ms): 8333.7 | learning rate: 6.300E-06 | global batch size:   512 | lm loss: 7.122227E+00 | grad norm: 4.398 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.437 | TFLOPs: 83.49 |
[default7]: iteration       43/  250000 | consumed samples:        22016 | consumed tokens:     45088768 | elapsed time per iteration (ms): 8309.2 | learning rate: 6.450E-06 | global batch size:   512 | lm loss: 7.063976E+00 | grad norm: 4.685 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.619 | TFLOPs: 83.73 |
[default7]: iteration       44/  250000 | consumed samples:        22528 | consumed tokens:     46137344 | elapsed time per iteration (ms): 8301.4 | learning rate: 6.600E-06 | global batch size:   512 | lm loss: 6.990968E+00 | grad norm: 5.801 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.677 | TFLOPs: 83.81 |
[default7]: iteration       45/  250000 | consumed samples:        23040 | consumed tokens:     47185920 | elapsed time per iteration (ms): 8277.0 | learning rate: 6.750E-06 | global batch size:   512 | lm loss: 7.051630E+00 | grad norm: 5.083 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.858 | TFLOPs: 84.06 |
[default7]: iteration       46/  250000 | consumed samples:        23552 | consumed tokens:     48234496 | elapsed time per iteration (ms): 8407.0 | learning rate: 6.900E-06 | global batch size:   512 | lm loss: 6.915473E+00 | grad norm: 4.180 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.902 | TFLOPs: 82.76 |
[default7]: iteration       47/  250000 | consumed samples:        24064 | consumed tokens:     49283072 | elapsed time per iteration (ms): 8260.2 | learning rate: 7.050E-06 | global batch size:   512 | lm loss: 7.114137E+00 | grad norm: 4.007 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.984 | TFLOPs: 84.23 |
[default7]: iteration       48/  250000 | consumed samples:        24576 | consumed tokens:     50331648 | elapsed time per iteration (ms): 8436.9 | learning rate: 7.200E-06 | global batch size:   512 | lm loss: 6.898245E+00 | grad norm: 3.995 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.686 | TFLOPs: 82.47 |
[default7]: iteration       49/  250000 | consumed samples:        25088 | consumed tokens:     51380224 | elapsed time per iteration (ms): 8272.1 | learning rate: 7.350E-06 | global batch size:   512 | lm loss: 6.992914E+00 | grad norm: 2.989 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.895 | TFLOPs: 84.11 |
[default7]: iteration       50/  250000 | consumed samples:        25600 | consumed tokens:     52428800 | elapsed time per iteration (ms): 8279.3 | learning rate: 7.500E-06 | global batch size:   512 | lm loss: 6.920588E+00 | grad norm: 4.311 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.841 | TFLOPs: 84.04 |
[default7]: iteration       51/  250000 | consumed samples:        26112 | consumed tokens:     53477376 | elapsed time per iteration (ms): 8362.4 | learning rate: 7.650E-06 | global batch size:   512 | lm loss: 6.799279E+00 | grad norm: 4.116 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.226 | TFLOPs: 83.20 |
[default7]: iteration       52/  250000 | consumed samples:        26624 | consumed tokens:     54525952 | elapsed time per iteration (ms): 8198.7 | learning rate: 7.800E-06 | global batch size:   512 | lm loss: 6.823242E+00 | grad norm: 3.902 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.449 | TFLOPs: 84.86 |
[default7]: iteration       53/  250000 | consumed samples:        27136 | consumed tokens:     55574528 | elapsed time per iteration (ms): 8413.4 | learning rate: 7.950E-06 | global batch size:   512 | lm loss: 6.800851E+00 | grad norm: 8.696 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.856 | TFLOPs: 82.70 |
[default7]: iteration       54/  250000 | consumed samples:        27648 | consumed tokens:     56623104 | elapsed time per iteration (ms): 8351.2 | learning rate: 8.100E-06 | global batch size:   512 | lm loss: 6.791966E+00 | grad norm: 13.446 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.308 | TFLOPs: 83.31 |
[default7]: iteration       55/  250000 | consumed samples:        28160 | consumed tokens:     57671680 | elapsed time per iteration (ms): 8184.7 | learning rate: 8.250E-06 | global batch size:   512 | lm loss: 6.778274E+00 | grad norm: 10.509 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.556 | TFLOPs: 85.01 |
[default7]: iteration       56/  250000 | consumed samples:        28672 | consumed tokens:     58720256 | elapsed time per iteration (ms): 8291.9 | learning rate: 8.400E-06 | global batch size:   512 | lm loss: 6.770942E+00 | grad norm: 10.134 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.747 | TFLOPs: 83.91 |
[default7]: iteration       57/  250000 | consumed samples:        29184 | consumed tokens:     59768832 | elapsed time per iteration (ms): 8359.8 | learning rate: 8.550E-06 | global batch size:   512 | lm loss: 7.034775E+00 | grad norm: 22.896 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.245 | TFLOPs: 83.23 |
[default7]: iteration       58/  250000 | consumed samples:        29696 | consumed tokens:     60817408 | elapsed time per iteration (ms): 8272.8 | learning rate: 8.700E-06 | global batch size:   512 | lm loss: 6.902672E+00 | grad norm: 11.221 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.889 | TFLOPs: 84.10 |
[default7]: iteration       59/  250000 | consumed samples:        30208 | consumed tokens:     61865984 | elapsed time per iteration (ms): 8190.2 | learning rate: 8.850E-06 | global batch size:   512 | lm loss: 6.901595E+00 | grad norm: 16.901 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.514 | TFLOPs: 84.95 |
[default7]: iteration       60/  250000 | consumed samples:        30720 | consumed tokens:     62914560 | elapsed time per iteration (ms): 8123.3 | learning rate: 9.000E-06 | global batch size:   512 | lm loss: 7.068559E+00 | grad norm: 35.844 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 63.028 | TFLOPs: 85.65 |
[default7]: iteration       61/  250000 | consumed samples:        31232 | consumed tokens:     63963136 | elapsed time per iteration (ms): 8259.9 | learning rate: 9.150E-06 | global batch size:   512 | lm loss: 6.911744E+00 | grad norm: 11.307 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.986 | TFLOPs: 84.23 |
[default7]: iteration       62/  250000 | consumed samples:        31744 | consumed tokens:     65011712 | elapsed time per iteration (ms): 8278.4 | learning rate: 9.300E-06 | global batch size:   512 | lm loss: 7.048892E+00 | grad norm: 15.258 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.847 | TFLOPs: 84.04 |
[default7]: iteration       63/  250000 | consumed samples:        32256 | consumed tokens:     66060288 | elapsed time per iteration (ms): 8405.0 | learning rate: 9.450E-06 | global batch size:   512 | lm loss: 7.167840E+00 | grad norm: 13.292 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.916 | TFLOPs: 82.78 |
[default7]: iteration       64/  250000 | consumed samples:        32768 | consumed tokens:     67108864 | elapsed time per iteration (ms): 8398.5 | learning rate: 9.600E-06 | global batch size:   512 | lm loss: 7.023433E+00 | grad norm: 8.755 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.963 | TFLOPs: 82.84 |
[default7]: iteration       65/  250000 | consumed samples:        33280 | consumed tokens:     68157440 | elapsed time per iteration (ms): 8422.2 | learning rate: 9.750E-06 | global batch size:   512 | lm loss: 6.976049E+00 | grad norm: 9.124 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.792 | TFLOPs: 82.61 |
[default7]: iteration       66/  250000 | consumed samples:        33792 | consumed tokens:     69206016 | elapsed time per iteration (ms): 8368.7 | learning rate: 9.900E-06 | global batch size:   512 | lm loss: 6.882112E+00 | grad norm: 6.618 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.180 | TFLOPs: 83.14 |
[default7]: iteration       67/  250000 | consumed samples:        34304 | consumed tokens:     70254592 | elapsed time per iteration (ms): 8185.2 | learning rate: 1.005E-05 | global batch size:   512 | lm loss: 6.899350E+00 | grad norm: 9.830 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.552 | TFLOPs: 85.00 |
[default7]: iteration       68/  250000 | consumed samples:        34816 | consumed tokens:     71303168 | elapsed time per iteration (ms): 8285.1 | learning rate: 1.020E-05 | global batch size:   512 | lm loss: 6.764022E+00 | grad norm: 10.475 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.798 | TFLOPs: 83.98 |
[default7]: iteration       69/  250000 | consumed samples:        35328 | consumed tokens:     72351744 | elapsed time per iteration (ms): 8454.0 | learning rate: 1.035E-05 | global batch size:   512 | lm loss: 6.648516E+00 | grad norm: 4.644 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.563 | TFLOPs: 82.30 |
[default7]: iteration       70/  250000 | consumed samples:        35840 | consumed tokens:     73400320 | elapsed time per iteration (ms): 8270.9 | learning rate: 1.050E-05 | global batch size:   512 | lm loss: 6.738193E+00 | grad norm: 18.773 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.904 | TFLOPs: 84.12 |
[default7]: iteration       71/  250000 | consumed samples:        36352 | consumed tokens:     74448896 | elapsed time per iteration (ms): 8433.7 | learning rate: 1.065E-05 | global batch size:   512 | lm loss: 6.678116E+00 | grad norm: 5.299 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.709 | TFLOPs: 82.50 |
[default7]: iteration       72/  250000 | consumed samples:        36864 | consumed tokens:     75497472 | elapsed time per iteration (ms): 8324.5 | learning rate: 1.080E-05 | global batch size:   512 | lm loss: 6.581970E+00 | grad norm: 4.930 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.505 | TFLOPs: 83.58 |
[default7]: iteration       73/  250000 | consumed samples:        37376 | consumed tokens:     76546048 | elapsed time per iteration (ms): 8241.3 | learning rate: 1.095E-05 | global batch size:   512 | lm loss: 6.581159E+00 | grad norm: 4.756 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.126 | TFLOPs: 84.42 |
[default0]:[2024-04-23 16:11:50,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=46, skipped=0, lr=[6.899999999999999e-06, 6.899999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 46 loss: 6.9155 iter time (s): 8.403 samples/sec: 60.934
[default0]:[2024-04-23 16:11:58,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=47, skipped=0, lr=[7.0499999999999986e-06, 7.0499999999999986e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 47 loss: 7.1141 iter time (s): 8.254 samples/sec: 62.029
[default0]:[2024-04-23 16:12:07,123] [INFO] [logging.py:96:log_dist] [Rank 0] step=48, skipped=0, lr=[7.2e-06, 7.2e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 48 loss: 6.8982 iter time (s): 8.432 samples/sec: 60.719
[default0]:[2024-04-23 16:12:15,395] [INFO] [logging.py:96:log_dist] [Rank 0] step=49, skipped=0, lr=[7.35e-06, 7.35e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 49 loss: 6.9929 iter time (s): 8.266 samples/sec: 61.940
[default0]:[2024-04-23 16:12:23,673] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[7.499999999999999e-06, 7.499999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 50 loss: 6.9206 iter time (s): 8.275 samples/sec: 61.875
[default0]:[2024-04-23 16:12:32,043] [INFO] [logging.py:96:log_dist] [Rank 0] step=51, skipped=0, lr=[7.65e-06, 7.65e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 51 loss: 6.7993 iter time (s): 8.358 samples/sec: 61.261
[default0]:[2024-04-23 16:12:40,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=52, skipped=0, lr=[7.8e-06, 7.8e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 52 loss: 6.8232 iter time (s): 8.194 samples/sec: 62.487
[default0]:[2024-04-23 16:12:48,641] [INFO] [logging.py:96:log_dist] [Rank 0] step=53, skipped=0, lr=[7.949999999999998e-06, 7.949999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 53 loss: 6.8009 iter time (s): 8.409 samples/sec: 60.890
[default0]:[2024-04-23 16:12:57,000] [INFO] [logging.py:96:log_dist] [Rank 0] step=54, skipped=0, lr=[8.1e-06, 8.1e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 54 loss: 6.7920 iter time (s): 8.344 samples/sec: 61.358
[default0]:[2024-04-23 16:13:05,187] [INFO] [logging.py:96:log_dist] [Rank 0] step=55, skipped=0, lr=[8.249999999999999e-06, 8.249999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 55 loss: 6.7783 iter time (s): 8.180 samples/sec: 62.591
[default0]:[2024-04-23 16:13:13,476] [INFO] [logging.py:96:log_dist] [Rank 0] step=56, skipped=0, lr=[8.4e-06, 8.4e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 56 loss: 6.7709 iter time (s): 8.279 samples/sec: 61.842
[default0]:[2024-04-23 16:13:21,840] [INFO] [logging.py:96:log_dist] [Rank 0] step=57, skipped=0, lr=[8.549999999999998e-06, 8.549999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 57 loss: 7.0348 iter time (s): 8.355 samples/sec: 61.281
[default0]:[2024-04-23 16:13:30,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=58, skipped=0, lr=[8.7e-06, 8.7e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 58 loss: 6.9027 iter time (s): 8.266 samples/sec: 61.942
[default0]:[2024-04-23 16:13:38,300] [INFO] [logging.py:96:log_dist] [Rank 0] step=59, skipped=0, lr=[8.849999999999998e-06, 8.849999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 59 loss: 6.9016 iter time (s): 8.186 samples/sec: 62.548
[default0]:[2024-04-23 16:13:46,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[8.999999999999999e-06, 8.999999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 60 loss: 7.0686 iter time (s): 8.119 samples/sec: 63.062
[default0]:[2024-04-23 16:13:54,684] [INFO] [logging.py:96:log_dist] [Rank 0] step=61, skipped=0, lr=[9.149999999999999e-06, 9.149999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 61 loss: 6.9117 iter time (s): 8.254 samples/sec: 62.034
[default0]:[2024-04-23 16:14:02,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=62, skipped=0, lr=[9.299999999999999e-06, 9.299999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 62 loss: 7.0489 iter time (s): 8.274 samples/sec: 61.880
[default0]:[2024-04-23 16:14:11,366] [INFO] [logging.py:96:log_dist] [Rank 0] step=63, skipped=0, lr=[9.449999999999998e-06, 9.449999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 63 loss: 7.1678 iter time (s): 8.399 samples/sec: 60.960
[default0]:[2024-04-23 16:14:19,769] [INFO] [logging.py:96:log_dist] [Rank 0] step=64, skipped=0, lr=[9.6e-06, 9.6e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 64 loss: 7.0234 iter time (s): 8.383 samples/sec: 61.077
[default0]:[2024-04-23 16:14:28,182] [INFO] [logging.py:96:log_dist] [Rank 0] step=65, skipped=0, lr=[9.75e-06, 9.75e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 65 loss: 6.9760 iter time (s): 8.416 samples/sec: 60.837
[default0]:[2024-04-23 16:14:36,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=66, skipped=0, lr=[9.899999999999998e-06, 9.899999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 66 loss: 6.8821 iter time (s): 8.348 samples/sec: 61.329
[default0]:[2024-04-23 16:14:44,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=67, skipped=0, lr=[1.005e-05, 1.005e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 67 loss: 6.8993 iter time (s): 8.181 samples/sec: 62.586
[default0]:[2024-04-23 16:14:53,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=68, skipped=0, lr=[1.0199999999999999e-05, 1.0199999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 68 loss: 6.7640 iter time (s): 8.279 samples/sec: 61.841
[default0]:[2024-04-23 16:15:01,489] [INFO] [logging.py:96:log_dist] [Rank 0] step=69, skipped=0, lr=[1.035e-05, 1.035e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 69 loss: 6.6485 iter time (s): 8.449 samples/sec: 60.602
[default0]:[2024-04-23 16:15:09,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[1.05e-05, 1.05e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 70 loss: 6.7382 iter time (s): 8.264 samples/sec: 61.954
[default0]:[2024-04-23 16:15:18,171] [INFO] [logging.py:96:log_dist] [Rank 0] step=71, skipped=0, lr=[1.065e-05, 1.065e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 71 loss: 6.6781 iter time (s): 8.429 samples/sec: 60.745
[default0]:[2024-04-23 16:15:26,486] [INFO] [logging.py:96:log_dist] [Rank 0] step=72, skipped=0, lr=[1.0799999999999998e-05, 1.0799999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 72 loss: 6.5820 iter time (s): 8.320 samples/sec: 61.538
[default0]:[2024-04-23 16:15:34,738] [INFO] [logging.py:96:log_dist] [Rank 0] step=73, skipped=0, lr=[1.095e-05, 1.095e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 73 loss: 6.5812 iter time (s): 8.235 samples/sec: 62.173
[default0]:[2024-04-23 16:15:43,077] [INFO] [logging.py:96:log_dist] [Rank 0] step=74, skipped=0, lr=[1.1099999999999999e-05, 1.1099999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 74 loss: 6.5651 iter time (s): 8.318 samples/sec: 61.550
[default0]:[2024-04-23 16:15:51,431] [INFO] [logging.py:96:log_dist] [Rank 0] step=75, skipped=0, lr=[1.1249999999999999e-05, 1.1249999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 75 loss: 6.4622 iter time (s): 8.354 samples/sec: 61.287
[default0]:[2024-04-23 16:15:59,650] [INFO] [logging.py:96:log_dist] [Rank 0] step=76, skipped=0, lr=[1.14e-05, 1.14e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 76 loss: 6.5126 iter time (s): 8.202 samples/sec: 62.426
[default0]:[2024-04-23 16:16:08,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=77, skipped=0, lr=[1.155e-05, 1.155e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 77 loss: 6.5138 iter time (s): 8.513 samples/sec: 60.140
[default0]:[2024-04-23 16:16:16,640] [INFO] [logging.py:96:log_dist] [Rank 0] step=78, skipped=0, lr=[1.1699999999999998e-05, 1.1699999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 78 loss: 6.4184 iter time (s): 8.478 samples/sec: 60.390
[default0]:[2024-04-23 16:16:25,060] [INFO] [logging.py:96:log_dist] [Rank 0] step=79, skipped=0, lr=[1.185e-05, 1.185e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default7]: iteration       74/  250000 | consumed samples:        37888 | consumed tokens:     77594624 | elapsed time per iteration (ms): 8323.1 | learning rate: 1.110E-05 | global batch size:   512 | lm loss: 6.565077E+00 | grad norm: 4.721 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.516 | TFLOPs: 83.59 |
[default7]: iteration       75/  250000 | consumed samples:        38400 | consumed tokens:     78643200 | elapsed time per iteration (ms): 8358.6 | learning rate: 1.125E-05 | global batch size:   512 | lm loss: 6.462214E+00 | grad norm: 4.270 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.255 | TFLOPs: 83.24 |
[default7]: iteration       76/  250000 | consumed samples:        38912 | consumed tokens:     79691776 | elapsed time per iteration (ms): 8206.1 | learning rate: 1.140E-05 | global batch size:   512 | lm loss: 6.512607E+00 | grad norm: 4.179 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.393 | TFLOPs: 84.79 |
[default7]: iteration       77/  250000 | consumed samples:        39424 | consumed tokens:     80740352 | elapsed time per iteration (ms): 8519.3 | learning rate: 1.155E-05 | global batch size:   512 | lm loss: 6.513789E+00 | grad norm: 3.353 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.099 | TFLOPs: 81.67 |
[default7]: iteration       78/  250000 | consumed samples:        39936 | consumed tokens:     81788928 | elapsed time per iteration (ms): 8484.6 | learning rate: 1.170E-05 | global batch size:   512 | lm loss: 6.418403E+00 | grad norm: 6.386 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.345 | TFLOPs: 82.00 |
[default7]: iteration       79/  250000 | consumed samples:        40448 | consumed tokens:     82837504 | elapsed time per iteration (ms): 8406.6 | learning rate: 1.185E-05 | global batch size:   512 | lm loss: 6.418070E+00 | grad norm: 3.321 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.904 | TFLOPs: 82.76 |
[default7]: iteration       80/  250000 | consumed samples:        40960 | consumed tokens:     83886080 | elapsed time per iteration (ms): 8321.3 | learning rate: 1.200E-05 | global batch size:   512 | lm loss: 6.390677E+00 | grad norm: 3.333 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.529 | TFLOPs: 83.61 |
[default7]: iteration       81/  250000 | consumed samples:        41472 | consumed tokens:     84934656 | elapsed time per iteration (ms): 8296.8 | learning rate: 1.215E-05 | global batch size:   512 | lm loss: 6.423116E+00 | grad norm: 3.363 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.710 | TFLOPs: 83.86 |
[default7]: iteration       82/  250000 | consumed samples:        41984 | consumed tokens:     85983232 | elapsed time per iteration (ms): 8212.9 | learning rate: 1.230E-05 | global batch size:   512 | lm loss: 6.491029E+00 | grad norm: 3.350 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.341 | TFLOPs: 84.72 |
[default7]: iteration       83/  250000 | consumed samples:        42496 | consumed tokens:     87031808 | elapsed time per iteration (ms): 8397.4 | learning rate: 1.245E-05 | global batch size:   512 | lm loss: 6.402981E+00 | grad norm: 3.228 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.971 | TFLOPs: 82.85 |
[default7]: iteration       84/  250000 | consumed samples:        43008 | consumed tokens:     88080384 | elapsed time per iteration (ms): 8341.0 | learning rate: 1.260E-05 | global batch size:   512 | lm loss: 6.403211E+00 | grad norm: 2.839 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.383 | TFLOPs: 83.41 |
[default7]: iteration       85/  250000 | consumed samples:        43520 | consumed tokens:     89128960 | elapsed time per iteration (ms): 8231.6 | learning rate: 1.275E-05 | global batch size:   512 | lm loss: 6.368530E+00 | grad norm: 3.065 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.199 | TFLOPs: 84.52 |
[default7]: iteration       86/  250000 | consumed samples:        44032 | consumed tokens:     90177536 | elapsed time per iteration (ms): 8427.9 | learning rate: 1.290E-05 | global batch size:   512 | lm loss: 6.375267E+00 | grad norm: 3.679 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.750 | TFLOPs: 82.55 |
[default7]: iteration       87/  250000 | consumed samples:        44544 | consumed tokens:     91226112 | elapsed time per iteration (ms): 8322.3 | learning rate: 1.305E-05 | global batch size:   512 | lm loss: 6.228669E+00 | grad norm: 2.230 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.522 | TFLOPs: 83.60 |
[default7]: iteration       88/  250000 | consumed samples:        45056 | consumed tokens:     92274688 | elapsed time per iteration (ms): 8283.3 | learning rate: 1.320E-05 | global batch size:   512 | lm loss: 6.300038E+00 | grad norm: 2.781 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.811 | TFLOPs: 84.00 |
[default7]: iteration       89/  250000 | consumed samples:        45568 | consumed tokens:     93323264 | elapsed time per iteration (ms): 8242.6 | learning rate: 1.335E-05 | global batch size:   512 | lm loss: 6.265749E+00 | grad norm: 3.140 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.116 | TFLOPs: 84.41 |
[default7]: iteration       90/  250000 | consumed samples:        46080 | consumed tokens:     94371840 | elapsed time per iteration (ms): 8203.4 | learning rate: 1.350E-05 | global batch size:   512 | lm loss: 6.257465E+00 | grad norm: 2.967 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.413 | TFLOPs: 84.81 |
[default7]: iteration       91/  250000 | consumed samples:        46592 | consumed tokens:     95420416 | elapsed time per iteration (ms): 8391.5 | learning rate: 1.365E-05 | global batch size:   512 | lm loss: 6.245782E+00 | grad norm: 2.407 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.014 | TFLOPs: 82.91 |
[default7]: iteration       92/  250000 | consumed samples:        47104 | consumed tokens:     96468992 | elapsed time per iteration (ms): 8259.9 | learning rate: 1.380E-05 | global batch size:   512 | lm loss: 6.254858E+00 | grad norm: 2.432 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.986 | TFLOPs: 84.23 |
[default7]: iteration       93/  250000 | consumed samples:        47616 | consumed tokens:     97517568 | elapsed time per iteration (ms): 8307.1 | learning rate: 1.395E-05 | global batch size:   512 | lm loss: 6.303369E+00 | grad norm: 2.687 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.634 | TFLOPs: 83.76 |
[default0]:steps: 79 loss: 6.4181 iter time (s): 8.401 samples/sec: 60.946
[default0]:[2024-04-23 16:16:33,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[1.1999999999999999e-05, 1.1999999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 80 loss: 6.3907 iter time (s): 8.315 samples/sec: 61.575
[default0]:[2024-04-23 16:16:41,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=81, skipped=0, lr=[1.2149999999999999e-05, 1.2149999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 81 loss: 6.4231 iter time (s): 8.292 samples/sec: 61.743
[default0]:[2024-04-23 16:16:49,888] [INFO] [logging.py:96:log_dist] [Rank 0] step=82, skipped=0, lr=[1.2299999999999999e-05, 1.2299999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 82 loss: 6.4910 iter time (s): 8.208 samples/sec: 62.381
[default0]:[2024-04-23 16:16:58,291] [INFO] [logging.py:96:log_dist] [Rank 0] step=83, skipped=0, lr=[1.245e-05, 1.245e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 83 loss: 6.4030 iter time (s): 8.384 samples/sec: 61.070
[default0]:[2024-04-23 16:17:06,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=84, skipped=0, lr=[1.2599999999999998e-05, 1.2599999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 84 loss: 6.4032 iter time (s): 8.337 samples/sec: 61.416
[default0]:[2024-04-23 16:17:14,844] [INFO] [logging.py:96:log_dist] [Rank 0] step=85, skipped=0, lr=[1.275e-05, 1.275e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 85 loss: 6.3685 iter time (s): 8.214 samples/sec: 62.332
[default0]:[2024-04-23 16:17:23,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=86, skipped=0, lr=[1.2899999999999998e-05, 1.2899999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 86 loss: 6.3753 iter time (s): 8.423 samples/sec: 60.783
[default0]:[2024-04-23 16:17:31,618] [INFO] [logging.py:96:log_dist] [Rank 0] step=87, skipped=0, lr=[1.3049999999999999e-05, 1.3049999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 87 loss: 6.2287 iter time (s): 8.318 samples/sec: 61.556
[default0]:[2024-04-23 16:17:39,873] [INFO] [logging.py:96:log_dist] [Rank 0] step=88, skipped=0, lr=[1.3199999999999999e-05, 1.3199999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 88 loss: 6.3000 iter time (s): 8.267 samples/sec: 61.935
[default0]:[2024-04-23 16:17:48,141] [INFO] [logging.py:96:log_dist] [Rank 0] step=89, skipped=0, lr=[1.335e-05, 1.335e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 89 loss: 6.2657 iter time (s): 8.238 samples/sec: 62.150
[default0]:[2024-04-23 16:17:56,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[1.3499999999999998e-05, 1.3499999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 90 loss: 6.2575 iter time (s): 8.199 samples/sec: 62.448
[default0]:[2024-04-23 16:18:04,740] [INFO] [logging.py:96:log_dist] [Rank 0] step=91, skipped=0, lr=[1.365e-05, 1.365e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 91 loss: 6.2458 iter time (s): 8.385 samples/sec: 61.058
[default0]:[2024-04-23 16:18:12,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=92, skipped=0, lr=[1.3799999999999998e-05, 1.3799999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 92 loss: 6.2549 iter time (s): 8.254 samples/sec: 62.031
[default0]:[2024-04-23 16:18:21,313] [INFO] [logging.py:96:log_dist] [Rank 0] step=93, skipped=0, lr=[1.3949999999999999e-05, 1.3949999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 93 loss: 6.3034 iter time (s): 8.303 samples/sec: 61.667
[default0]:[2024-04-23 16:18:29,563] [INFO] [logging.py:96:log_dist] [Rank 0] step=94, skipped=0, lr=[1.4099999999999997e-05, 1.4099999999999997e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 94 loss: 6.1725 iter time (s): 8.254 samples/sec: 62.030
[default0]:[2024-04-23 16:18:37,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=95, skipped=0, lr=[1.4249999999999999e-05, 1.4249999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 95 loss: 6.1619 iter time (s): 8.337 samples/sec: 61.414
[default0]:[2024-04-23 16:18:46,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=96, skipped=0, lr=[1.44e-05, 1.44e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 96 loss: 6.0695 iter time (s): 8.200 samples/sec: 62.442
[default0]:[2024-04-23 16:18:54,368] [INFO] [logging.py:96:log_dist] [Rank 0] step=97, skipped=0, lr=[1.4549999999999998e-05, 1.4549999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 97 loss: 6.0873 iter time (s): 8.211 samples/sec: 62.358
[default0]:[2024-04-23 16:19:02,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=98, skipped=0, lr=[1.47e-05, 1.47e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 98 loss: 6.1365 iter time (s): 8.282 samples/sec: 61.822
[default0]:[2024-04-23 16:19:11,058] [INFO] [logging.py:96:log_dist] [Rank 0] step=99, skipped=0, lr=[1.4849999999999998e-05, 1.4849999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 99 loss: 6.1478 iter time (s): 8.409 samples/sec: 60.890
[default0]:[2024-04-23 16:19:19,354] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[1.4999999999999999e-05, 1.4999999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 100 loss: 6.1362 iter time (s): 8.281 samples/sec: 61.830
[default0]:saving checkpoint at iteration     100 to /gpfswork/rech/qgz/urc37ho/checkpoints10121/
[default0]:[2024-04-23 16:19:21,212] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
[default0]:[2024-04-23 16:19:21,296] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_01-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:21,422] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_01-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:21,480] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_02-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:21,713] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_02-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:21,765] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_03-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:22,037] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_03-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:22,093] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_04-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:22,373] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_04-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:22,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_05-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:22,675] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_05-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:22,729] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_06-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:22,937] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_06-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:22,994] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_07-model_00-model_states.pt...
                                                                         a                                                                                                                                                                                                                                                                                                                          !                                                                                                                                                                                                                                                                                                                                         [default0]:[2024-04-23 16:05:21,343] [INFO] [engine.py:158:__init__] RANK=32 STAGE=1 LAYERS=19 [18, 37) STAGE_PARAMS=3369209856 (3369.210M) TOTAL_PARAMS=6738415616 (6738.416M) UNIQUE_PARAMS=6738415616 (6738.416M)
[default1]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2024-04-23 16:05:21,425] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[Rank 32] (after 1 iterations) memory (MB) | allocated: 29252.52294921875 | max allocated: 52241.568359375 | reserved: 60498.0 | max reserved: 60498.0
[default0]:[2024-04-23 16:19:21,314] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_18-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:21,548] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_18-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:21,600] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_19-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:21,813] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_19-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:21,865] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_20-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:22,071] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_20-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:22,123] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_21-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:22,349] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_21-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:22,402] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_22-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:22,639] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_22-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:22,691] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_23-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:23,017] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_23-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:23,068] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_24-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:23,283] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_24-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:23,335] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_25-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:23,600] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_25-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:23,651] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_26-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:23,999] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_26-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:24,051] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_27-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:24,361] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_27-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:24,412] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_28-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:24,719] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_28-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:24,770] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_29-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:24,992] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_29-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:25,043] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_30-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:25,378] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_30-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:25,430] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_31-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:25,667] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_31-model_00-model_states.pt.
[default7]: iteration       94/  250000 | consumed samples:        48128 | consumed tokens:     98566144 | elapsed time per iteration (ms): 8272.1 | learning rate: 1.410E-05 | global batch size:   512 | lm loss: 6.172461E+00 | grad norm: 2.839 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.895 | TFLOPs: 84.11 |
[default7]: iteration       95/  250000 | consumed samples:        48640 | consumed tokens:     99614720 | elapsed time per iteration (ms): 8343.4 | learning rate: 1.425E-05 | global batch size:   512 | lm loss: 6.161944E+00 | grad norm: 2.562 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.366 | TFLOPs: 83.39 |
[default7]: iteration       96/  250000 | consumed samples:        49152 | consumed tokens:    100663296 | elapsed time per iteration (ms): 8213.6 | learning rate: 1.440E-05 | global batch size:   512 | lm loss: 6.069524E+00 | grad norm: 2.505 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.335 | TFLOPs: 84.71 |
[default7]: iteration       97/  250000 | consumed samples:        49664 | consumed tokens:    101711872 | elapsed time per iteration (ms): 8215.4 | learning rate: 1.455E-05 | global batch size:   512 | lm loss: 6.087322E+00 | grad norm: 3.332 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.322 | TFLOPs: 84.69 |
[default7]: iteration       98/  250000 | consumed samples:        50176 | consumed tokens:    102760448 | elapsed time per iteration (ms): 8286.4 | learning rate: 1.470E-05 | global batch size:   512 | lm loss: 6.136495E+00 | grad norm: 4.458 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.788 | TFLOPs: 83.96 |
[default7]: iteration       99/  250000 | consumed samples:        50688 | consumed tokens:    103809024 | elapsed time per iteration (ms): 8413.3 | learning rate: 1.485E-05 | global batch size:   512 | lm loss: 6.147757E+00 | grad norm: 4.424 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 60.856 | TFLOPs: 82.70 |
[default7]: iteration      100/  250000 | consumed samples:        51200 | consumed tokens:    104857600 | elapsed time per iteration (ms): 8293.0 | learning rate: 1.500E-05 | global batch size:   512 | lm loss: 6.136194E+00 | grad norm: 3.944 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.739 | TFLOPs: 83.90 |
[default7]:-----------------------------------------------------------------------------------------------
[default7]: validation loss at iteration 100 | lm loss value: 6.142506E+00 | lm loss PPL: 4.652178E+02 | 
[default7]:-----------------------------------------------------------------------------------------------
[default3]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_27_mp_rank_01_optim_states.pt...
[default6]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_30_mp_rank_01_optim_states.pt...
[default2]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_26_mp_rank_01_optim_states.pt...
[default1]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_25_mp_rank_01_optim_states.pt...
[default4]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_28_mp_rank_01_optim_states.pt...
[default5]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_29_mp_rank_01_optim_states.pt...
[default7]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_31_mp_rank_01_optim_states.pt...
[default0]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_24_mp_rank_01_optim_states.pt...
[default3]:[2024-04-23 16:19:27,966] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_27_mp_rank_01_optim_states.pt.
[default3]:[2024-04-23 16:19:27,966] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_27_mp_rank_01_optim_states.pt
[default3]:[2024-04-23 16:19:27,966] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default6]:[2024-04-23 16:19:28,066] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_30_mp_rank_01_optim_states.pt.
[default6]:[2024-04-23 16:19:28,066] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_30_mp_rank_01_optim_states.pt
[default6]:[2024-04-23 16:19:28,066] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default2]:[2024-04-23 16:19:28,304] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_26_mp_rank_01_optim_states.pt.
[default2]:[2024-04-23 16:19:28,304] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_26_mp_rank_01_optim_states.pt
[default2]:[2024-04-23 16:19:28,304] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default5]:[2024-04-23 16:19:28,272] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_29_mp_rank_01_optim_states.pt.
[default5]:[2024-04-23 16:19:28,272] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_29_mp_rank_01_optim_states.pt
[default5]:[2024-04-23 16:19:28,273] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default4]:[2024-04-23 16:19:28,397] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_28_mp_rank_01_optim_states.pt.
[default4]:[2024-04-23 16:19:28,397] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_28_mp_rank_01_optim_states.pt
[default4]:[2024-04-23 16:19:28,397] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default7]:[2024-04-23 16:19:28,357] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_31_mp_rank_01_optim_states.pt.
[default7]:[2024-04-23 16:19:28,357] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_31_mp_rank_01_optim_states.pt
[default7]:[2024-04-23 16:19:28,358] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2024-04-23 16:19:23,220] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_07-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:23,276] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_08-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:23,586] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_08-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:23,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_09-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:23,852] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_09-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:23,907] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_10-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:24,120] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_10-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:24,176] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_11-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:24,406] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_11-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:24,461] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_12-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:24,670] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_12-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:24,726] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_13-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:24,943] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_13-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:24,998] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_14-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:25,221] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_14-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:25,277] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_15-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:25,519] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_15-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:25,573] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_16-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:25,802] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_16-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:25,861] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_17-model_00-model_states.pt...
[default0]:[2024-04-23 16:19:26,095] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/layer_17-model_00-model_states.pt.
[default0]:[2024-04-23 16:19:26,097] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/mp_rank_00_model_states.pt
[default0]:[2024-04-23 16:19:26,097] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/mp_rank_00_model_states.pt...
[default1]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[default6]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt...
[default3]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default7]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt...
[default5]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt...
[default0]:[2024-04-23 16:19:26,239] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/mp_rank_00_model_states.pt.
[default0]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default4]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
[default2]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[default2]:[2024-04-23 16:19:28,739] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default2]:[2024-04-23 16:19:28,739] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[default2]:[2024-04-23 16:19:28,739] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2024-04-23 16:19:28,766] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default1]:[2024-04-23 16:19:28,767] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[default1]:[2024-04-23 16:19:28,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2024-04-23 16:19:28,818] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default3]:[2024-04-23 16:19:28,811] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default3]:[2024-04-23 16:19:28,812] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[default3]:[2024-04-23 16:19:28,813] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_9_mp_rank_01_optim_states.pt...
[default4]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_12_mp_rank_01_optim_states.pt...
[default5]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_13_mp_rank_01_optim_states.pt...
[default3]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_11_mp_rank_01_optim_states.pt...
[default7]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_15_mp_rank_01_optim_states.pt...
[default6]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_14_mp_rank_01_optim_states.pt...
[default2]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_10_mp_rank_01_optim_states.pt...
[default0]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_8_mp_rank_01_optim_states.pt...
[default0]:[2024-04-23 16:19:28,155] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_8_mp_rank_01_optim_states.pt.
[default0]:[2024-04-23 16:19:28,155] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_8_mp_rank_01_optim_states.pt
[default0]:[2024-04-23 16:19:28,155] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2024-04-23 16:19:28,176] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_9_mp_rank_01_optim_states.pt.
[default1]:[2024-04-23 16:19:28,176] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_9_mp_rank_01_optim_states.pt
[default1]:[2024-04-23 16:19:28,176] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default3]:[2024-04-23 16:19:28,729] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_11_mp_rank_01_optim_states.pt.
[default3]:[2024-04-23 16:19:28,729] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_11_mp_rank_01_optim_states.pt
[default3]:[2024-04-23 16:19:28,730] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default2]:[2024-04-23 16:19:28,761] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_10_mp_rank_01_optim_states.pt.
[default2]:[2024-04-23 16:19:28,761] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_10_mp_rank_01_optim_states.pt
[default2]:[2024-04-23 16:19:28,761] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default5]:[2024-04-23 16:19:29,051] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_13_mp_rank_01_optim_states.pt.
[default5]:[2024-04-23 16:19:29,051] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_13_mp_rank_01_optim_states.pt
[default5]:[2024-04-23 16:19:29,051] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default4]:[2024-04-23 16:19:29,187] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_12_mp_rank_01_optim_states.pt.
[default4]:[2024-04-23 16:19:29,187] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_12_mp_rank_01_optim_states.pt
[default4]:[2024-04-23 16:19:29,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default6]:[2024-04-23 16:19:29,348] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_14_mp_rank_01_optim_states.pt.
[default6]:[2024-04-23 16:19:29,348] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_14_mp_rank_01_optim_states.pt
[default6]:[2024-04-23 16:19:29,348] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default7]:[2024-04-23 16:19:29,441] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_15_mp_rank_01_optim_states.pt.
[default1]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_17_mp_rank_00_optim_states.pt...
[default0]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
[default5]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_21_mp_rank_00_optim_states.pt...
[default6]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_22_mp_rank_00_optim_states.pt...
[default7]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_23_mp_rank_00_optim_states.pt...
[default4]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
[default3]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_19_mp_rank_00_optim_states.pt...
[default2]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_18_mp_rank_00_optim_states.pt...
[default2]:[2024-04-23 16:19:28,985] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_18_mp_rank_00_optim_states.pt.
[default2]:[2024-04-23 16:19:28,985] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_18_mp_rank_00_optim_states.pt
[default2]:[2024-04-23 16:19:28,985] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default6]:[2024-04-23 16:19:29,123] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_22_mp_rank_00_optim_states.pt.
[default6]:[2024-04-23 16:19:29,124] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_22_mp_rank_00_optim_states.pt
[default6]:[2024-04-23 16:19:29,124] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default7]:[2024-04-23 16:19:29,214] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_23_mp_rank_00_optim_states.pt.
[default7]:[2024-04-23 16:19:29,215] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_23_mp_rank_00_optim_states.pt
[default7]:[2024-04-23 16:19:29,215] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default3]:[2024-04-23 16:19:29,239] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_19_mp_rank_00_optim_states.pt.
[default3]:[2024-04-23 16:19:29,240] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_19_mp_rank_00_optim_states.pt
[default3]:[2024-04-23 16:19:29,240] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2024-04-23 16:19:29,218] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
[default0]:[2024-04-23 16:19:29,218] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
[default0]:[2024-04-23 16:19:29,218] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2024-04-23 16:19:29,445] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_17_mp_rank_00_optim_states.pt.
[default1]:[2024-04-23 16:19:29,445] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_17_mp_rank_00_optim_states.pt
[default1]:[2024-04-23 16:19:29,445] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default4]:[2024-04-23 16:19:30,086] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
[default4]:[2024-04-23 16:19:30,086] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
[default4]:[2024-04-23 16:19:30,086] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default5]:[2024-04-23 16:19:30,109] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_21_mp_rank_00_optim_states.pt.
[default4]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
[default5]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_29_mp_rank_00_optim_states.pt...
[default0]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
[default2]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_26_mp_rank_00_optim_states.pt...
[default6]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_30_mp_rank_00_optim_states.pt...
[default1]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_25_mp_rank_00_optim_states.pt...
[default7]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_31_mp_rank_00_optim_states.pt...
[default3]:[2024-04-23 16:19:26,250] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_27_mp_rank_00_optim_states.pt...
[default0]:[2024-04-23 16:19:27,897] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
[default0]:[2024-04-23 16:19:27,897] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
[default0]:[2024-04-23 16:19:27,897] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2024-04-23 16:19:27,914] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_25_mp_rank_00_optim_states.pt.
[default1]:[2024-04-23 16:19:27,914] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_25_mp_rank_00_optim_states.pt
[default1]:[2024-04-23 16:19:27,914] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default3]:[2024-04-23 16:19:27,897] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_27_mp_rank_00_optim_states.pt.
[default3]:[2024-04-23 16:19:27,897] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_27_mp_rank_00_optim_states.pt
[default3]:[2024-04-23 16:19:27,897] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default2]:[2024-04-23 16:19:28,302] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_26_mp_rank_00_optim_states.pt.
[default2]:[2024-04-23 16:19:28,302] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_26_mp_rank_00_optim_states.pt
[default2]:[2024-04-23 16:19:28,302] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default6]:[2024-04-23 16:19:29,097] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_30_mp_rank_00_optim_states.pt.
[default6]:[2024-04-23 16:19:29,097] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_30_mp_rank_00_optim_states.pt
[default6]:[2024-04-23 16:19:29,097] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default7]:[2024-04-23 16:19:29,089] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_31_mp_rank_00_optim_states.pt.
[default7]:[2024-04-23 16:19:29,090] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_31_mp_rank_00_optim_states.pt
[default7]:[2024-04-23 16:19:29,090] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default4]:[2024-04-23 16:19:30,345] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
[default4]:[2024-04-23 16:19:30,345] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
[default4]:[2024-04-23 16:19:30,345] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default5]:[2024-04-23 16:19:30,317] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_29_mp_rank_00_optim_states.pt.
[default2]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-23 16:05:21,417] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints10121/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_22_mp_rank_01_optim_states.pt...
[default3]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_19_mp_rank_01_optim_states.pt...
[default7]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_23_mp_rank_01_optim_states.pt...
[default5]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_21_mp_rank_01_optim_states.pt...
[default0]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_16_mp_rank_01_optim_states.pt...
[default1]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_17_mp_rank_01_optim_states.pt...
[default2]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_18_mp_rank_01_optim_states.pt...
[default4]:[2024-04-23 16:19:26,475] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_20_mp_rank_01_optim_states.pt...
[default2]:[2024-04-23 16:19:28,387] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_18_mp_rank_01_optim_states.pt.
[default2]:[2024-04-23 16:19:28,389] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_18_mp_rank_01_optim_states.pt
[default2]:[2024-04-23 16:19:28,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default7]:[2024-04-23 16:19:28,682] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_23_mp_rank_01_optim_states.pt.
[default7]:[2024-04-23 16:19:28,683] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_23_mp_rank_01_optim_states.pt
[default7]:[2024-04-23 16:19:28,683] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default3]:[2024-04-23 16:19:28,803] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_19_mp_rank_01_optim_states.pt.
[default3]:[2024-04-23 16:19:28,803] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_19_mp_rank_01_optim_states.pt
[default3]:[2024-04-23 16:19:28,803] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2024-04-23 16:19:28,940] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_17_mp_rank_01_optim_states.pt.
[default1]:[2024-04-23 16:19:28,940] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_17_mp_rank_01_optim_states.pt
[default1]:[2024-04-23 16:19:28,940] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default6]:[2024-04-23 16:19:28,916] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_22_mp_rank_01_optim_states.pt.
[default6]:[2024-04-23 16:19:28,916] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_22_mp_rank_01_optim_states.pt
[default6]:[2024-04-23 16:19:28,916] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:[2024-04-23 16:19:28,947] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_16_mp_rank_01_optim_states.pt.
[default0]:[2024-04-23 16:19:28,947] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_16_mp_rank_01_optim_states.pt
[default0]:[2024-04-23 16:19:28,947] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default4]:[2024-04-23 16:19:30,301] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_20_mp_rank_01_optim_states.pt.
[default4]:[2024-04-23 16:19:30,302] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_20_mp_rank_01_optim_states.pt
[default4]:[2024-04-23 16:19:30,302] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default5]:[2024-04-23 16:19:30,357] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_21_mp_rank_01_optim_states.pt.
[default0]:[2024-04-23 16:19:28,436] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_24_mp_rank_01_optim_states.pt.
[default0]:[2024-04-23 16:19:28,436] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_24_mp_rank_01_optim_states.pt
[default0]:[2024-04-23 16:19:28,436] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default1]:[2024-04-23 16:19:28,496] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_25_mp_rank_01_optim_states.pt.
[default1]:[2024-04-23 16:19:28,496] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_25_mp_rank_01_optim_states.pt
[default1]:[2024-04-23 16:19:28,496] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default7]:(min, max) time across ranks (ms):
[default7]:    save-checkpoint ................................: (9388.51, 9388.60)
[default7]: iteration      101/  250000 | consumed samples:        51712 | consumed tokens:    105906176 | elapsed time per iteration (ms): 19552.2 | learning rate: 1.515E-05 | global batch size:   512 | lm loss: 6.167077E+00 | grad norm: 5.714 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 26.186 | TFLOPs: 35.58 |
[default7]: iteration      102/  250000 | consumed samples:        52224 | consumed tokens:    106954752 | elapsed time per iteration (ms): 8241.8 | learning rate: 1.530E-05 | global batch size:   512 | lm loss: 6.065069E+00 | grad norm: 6.081 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.122 | TFLOPs: 84.42 |
[default7]: iteration      103/  250000 | consumed samples:        52736 | consumed tokens:    108003328 | elapsed time per iteration (ms): 8387.8 | learning rate: 1.545E-05 | global batch size:   512 | lm loss: 6.143102E+00 | grad norm: 8.994 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.041 | TFLOPs: 82.95 |
[default7]: iteration      104/  250000 | consumed samples:        53248 | consumed tokens:    109051904 | elapsed time per iteration (ms): 8200.2 | learning rate: 1.560E-05 | global batch size:   512 | lm loss: 6.132038E+00 | grad norm: 7.790 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.438 | TFLOPs: 84.85 |
[default7]: iteration      105/  250000 | consumed samples:        53760 | consumed tokens:    110100480 | elapsed time per iteration (ms): 8306.5 | learning rate: 1.575E-05 | global batch size:   512 | lm loss: 6.112370E+00 | grad norm: 6.783 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.639 | TFLOPs: 83.76 |
[default7]: iteration      106/  250000 | consumed samples:        54272 | consumed tokens:    111149056 | elapsed time per iteration (ms): 8302.2 | learning rate: 1.590E-05 | global batch size:   512 | lm loss: 6.120435E+00 | grad norm: 6.509 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.670 | TFLOPs: 83.80 |
[default7]: iteration      107/  250000 | consumed samples:        54784 | consumed tokens:    112197632 | elapsed time per iteration (ms): 8388.8 | learning rate: 1.605E-05 | global batch size:   512 | lm loss: 6.000110E+00 | grad norm: 6.866 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.033 | TFLOPs: 82.94 |
[default7]: iteration      108/  250000 | consumed samples:        55296 | consumed tokens:    113246208 | elapsed time per iteration (ms): 8181.0 | learning rate: 1.620E-05 | global batch size:   512 | lm loss: 6.035397E+00 | grad norm: 4.641 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.584 | TFLOPs: 85.05 |
[default7]: iteration      109/  250000 | consumed samples:        55808 | consumed tokens:    114294784 | elapsed time per iteration (ms): 8301.0 | learning rate: 1.635E-05 | global batch size:   512 | lm loss: 6.064057E+00 | grad norm: 4.614 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.679 | TFLOPs: 83.82 |
[default7]: iteration      110/  250000 | consumed samples:        56320 | consumed tokens:    115343360 | elapsed time per iteration (ms): 8303.2 | learning rate: 1.650E-05 | global batch size:   512 | lm loss: 5.962566E+00 | grad norm: 3.724 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.663 | TFLOPs: 83.79 |
[default7]: iteration      111/  250000 | consumed samples:        56832 | consumed tokens:    116391936 | elapsed time per iteration (ms): 8196.4 | learning rate: 1.665E-05 | global batch size:   512 | lm loss: 5.908242E+00 | grad norm: 4.993 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.466 | TFLOPs: 84.89 |
[default7]: iteration      112/  250000 | consumed samples:        57344 | consumed tokens:    117440512 | elapsed time per iteration (ms): 8248.1 | learning rate: 1.680E-05 | global batch size:   512 | lm loss: 5.997045E+00 | grad norm: 4.091 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.075 | TFLOPs: 84.35 |
[default7]: iteration      113/  250000 | consumed samples:        57856 | consumed tokens:    118489088 | elapsed time per iteration (ms): 8332.9 | learning rate: 1.695E-05 | global batch size:   512 | lm loss: 5.934500E+00 | grad norm: 3.522 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.444 | TFLOPs: 83.50 |
[default7]: iteration      114/  250000 | consumed samples:        58368 | consumed tokens:    119537664 | elapsed time per iteration (ms): 8294.3 | learning rate: 1.710E-05 | global batch size:   512 | lm loss: 5.958848E+00 | grad norm: 3.542 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.729 | TFLOPs: 83.88 |
[default7]: iteration      115/  250000 | consumed samples:        58880 | consumed tokens:    120586240 | elapsed time per iteration (ms): 8224.1 | learning rate: 1.725E-05 | global batch size:   512 | lm loss: 5.967223E+00 | grad norm: 3.580 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 62.256 | TFLOPs: 84.60 |
[default7]: iteration      116/  250000 | consumed samples:        59392 | consumed tokens:    121634816 | elapsed time per iteration (ms): 8310.5 | learning rate: 1.740E-05 | global batch size:   512 | lm loss: 5.843187E+00 | grad norm: 3.712 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.608 | TFLOPs: 83.72 |
[default7]: iteration      117/  250000 | consumed samples:        59904 | consumed tokens:    122683392 | elapsed time per iteration (ms): 8363.0 | learning rate: 1.755E-05 | global batch size:   512 | lm loss: 5.900372E+00 | grad norm: 3.699 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 61.222 | TFLOPs: 83.19 |
[default0]:[2024-04-23 16:19:29,130] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2024-04-23 16:19:29,130] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default6]:[2024-04-23 16:19:29,819] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt.
[default6]:[2024-04-23 16:19:29,819] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_6_mp_rank_00_optim_states.pt
[default6]:[2024-04-23 16:19:29,819] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default7]:[2024-04-23 16:19:29,917] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt.
[default7]:[2024-04-23 16:19:29,917] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_7_mp_rank_00_optim_states.pt
[default7]:[2024-04-23 16:19:29,917] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default5]:[2024-04-23 16:19:30,449] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt.
[default5]:[2024-04-23 16:19:30,449] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_5_mp_rank_00_optim_states.pt
[default5]:[2024-04-23 16:19:30,449] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default4]:[2024-04-23 16:19:30,443] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
[default4]:[2024-04-23 16:19:30,443] [INFO] [engine.py:3431:_save_zero_checkpoint] bf16_zero checkpoint saved /gpfswork/rech/qgz/urc37ho/checkpoints10121/global_step100/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
[default4]:[2024-04-23 16:19:30,443] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:  successfully saved checkpoint at iteration     100 to /gpfswork/rech/qgz/urc37ho/checkpoints10121/
[default0]:Checkpoint Save GB: 94.338, GB/Sec: 10.05, Latency(second): 9.389
[default0]:[2024-04-23 16:19:38,896] [INFO] [logging.py:96:log_dist] [Rank 0] step=101, skipped=0, lr=[1.5149999999999999e-05, 1.5149999999999999e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 101 loss: 6.1671 iter time (s): 8.311 samples/sec: 61.605
[default0]:[2024-04-23 16:19:47,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=102, skipped=0, lr=[1.53e-05, 1.53e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 102 loss: 6.0651 iter time (s): 8.232 samples/sec: 62.196
[default0]:[2024-04-23 16:19:55,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=103, skipped=0, lr=[1.545e-05, 1.545e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 103 loss: 6.1431 iter time (s): 8.382 samples/sec: 61.082
[default0]:[2024-04-23 16:20:03,728] [INFO] [logging.py:96:log_dist] [Rank 0] step=104, skipped=0, lr=[1.56e-05, 1.56e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 104 loss: 6.1320 iter time (s): 8.179 samples/sec: 62.603
[default0]:[2024-04-23 16:20:12,040] [INFO] [logging.py:96:log_dist] [Rank 0] step=105, skipped=0, lr=[1.575e-05, 1.575e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 105 loss: 6.1124 iter time (s): 8.300 samples/sec: 61.684
[default0]:[2024-04-23 16:20:20,338] [INFO] [logging.py:96:log_dist] [Rank 0] step=106, skipped=0, lr=[1.5899999999999997e-05, 1.5899999999999997e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 106 loss: 6.1204 iter time (s): 8.298 samples/sec: 61.703
[default0]:[2024-04-23 16:20:28,711] [INFO] [logging.py:96:log_dist] [Rank 0] step=107, skipped=0, lr=[1.6049999999999997e-05, 1.6049999999999997e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 107 loss: 6.0001 iter time (s): 8.384 samples/sec: 61.066
[default0]:[2024-04-23 16:20:36,922] [INFO] [logging.py:96:log_dist] [Rank 0] step=108, skipped=0, lr=[1.62e-05, 1.62e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 108 loss: 6.0354 iter time (s): 8.174 samples/sec: 62.634
[default0]:[2024-04-23 16:20:45,220] [INFO] [logging.py:96:log_dist] [Rank 0] step=109, skipped=0, lr=[1.635e-05, 1.635e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 109 loss: 6.0641 iter time (s): 8.296 samples/sec: 61.718
[default0]:[2024-04-23 16:20:53,526] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[1.6499999999999998e-05, 1.6499999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 110 loss: 5.9626 iter time (s): 8.299 samples/sec: 61.696
[default0]:[2024-04-23 16:21:01,710] [INFO] [logging.py:96:log_dist] [Rank 0] step=111, skipped=0, lr=[1.6649999999999998e-05, 1.6649999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 111 loss: 5.9082 iter time (s): 8.191 samples/sec: 62.507
[default0]:[2024-04-23 16:21:09,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=112, skipped=0, lr=[1.68e-05, 1.68e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 112 loss: 5.9970 iter time (s): 8.244 samples/sec: 62.109
[default0]:[2024-04-23 16:21:18,289] [INFO] [logging.py:96:log_dist] [Rank 0] step=113, skipped=0, lr=[1.695e-05, 1.695e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 113 loss: 5.9345 iter time (s): 8.327 samples/sec: 61.490
[default0]:[2024-04-23 16:21:26,600] [INFO] [logging.py:96:log_dist] [Rank 0] step=114, skipped=0, lr=[1.7099999999999996e-05, 1.7099999999999996e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 114 loss: 5.9588 iter time (s): 8.289 samples/sec: 61.767
[default0]:[2024-04-23 16:21:34,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=115, skipped=0, lr=[1.725e-05, 1.725e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 115 loss: 5.9672 iter time (s): 8.218 samples/sec: 62.303
[default0]:[2024-04-23 16:21:43,136] [INFO] [logging.py:96:log_dist] [Rank 0] step=116, skipped=0, lr=[1.74e-05, 1.74e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 116 loss: 5.8432 iter time (s): 8.306 samples/sec: 61.644
[default0]:[2024-04-23 16:21:51,492] [INFO] [logging.py:96:log_dist] [Rank 0] step=117, skipped=0, lr=[1.755e-05, 1.755e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 117 loss: 5.9004 iter time (s): 8.357 samples/sec: 61.265
[default0]:[2024-04-23 16:21:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] step=118, skipped=0, lr=[1.7699999999999997e-05, 1.7699999999999997e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 118 loss: 5.8506 iter time (s): 8.375 samples/sec: 61.133
[default0]:[2024-04-23 16:22:08,131] [INFO] [logging.py:96:log_dist] [Rank 0] step=119, skipped=0, lr=[1.7849999999999997e-05, 1.7849999999999997e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 119 loss: 5.8255 iter time (s): 8.251 samples/sec: 62.050
[default0]:[2024-04-23 16:22:16,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[1.7999999999999997e-05, 1.7999999999999997e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 120 loss: 5.8110 iter time (s): 8.199 samples/sec: 62.450
[default0]:[2024-04-23 16:22:24,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=121, skipped=0, lr=[1.815e-05, 1.815e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 121 loss: 5.8113 iter time (s): 8.217 samples/sec: 62.313
[default0]:[2024-04-23 16:22:32,748] [INFO] [logging.py:96:log_dist] [Rank 0] step=122, skipped=0, lr=[1.8299999999999998e-05, 1.8299999999999998e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 122 loss: 5.8413 iter time (s): 8.189 samples/sec: 62.520
slurmstepd: error: *** JOB 1603271 ON jean-zay-iam16 CANCELLED AT 2024-04-23T16:23:02 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 1603271.0 ON jean-zay-iam16 CANCELLED AT 2024-04-23T16:23:03 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
[2024-04-23 16:23:03,055] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,055] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135643 closing signal SIGTERM
[2024-04-23 16:23:03,056] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135644 closing signal SIGTERM
[2024-04-23 16:23:03,056] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135645 closing signal SIGTERM
[2024-04-23 16:23:03,056] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,057] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646611 closing signal SIGTERM
[2024-04-23 16:23:03,057] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135646 closing signal SIGTERM
[2024-04-23 16:23:03,057] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,057] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120212 closing signal SIGTERM
[2024-04-23 16:23:03,057] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646612 closing signal SIGTERM
[2024-04-23 16:23:03,057] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135647 closing signal SIGTERM
[2024-04-23 16:23:03,057] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,057] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715186 closing signal SIGTERM
[2024-04-23 16:23:03,057] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135648 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120213 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715187 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135649 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3135650 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646613 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715188 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120214 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096009 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646614 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,058] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144710 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144711 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383750 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120215 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096010 closing signal SIGTERM
[2024-04-23 16:23:03,058] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715189 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383751 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120216 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715190 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144712 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646615 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096011 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383752 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144713 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120217 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715191 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869987 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646616 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144714 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096012 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646617 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096013 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383753 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120218 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715192 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383754 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1646618 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096014 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144715 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096015 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2120219 closing signal SIGTERM
[2024-04-23 16:23:03,059] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869988 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383755 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3715193 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383756 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1096016 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144716 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869989 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2144717 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869990 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1383757 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869991 closing signal SIGTERM
[2024-04-23 16:23:03,060] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869992 closing signal SIGTERM
[2024-04-23 16:23:03,061] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869993 closing signal SIGTERM
[2024-04-23 16:23:03,061] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1869994 closing signal SIGTERM
