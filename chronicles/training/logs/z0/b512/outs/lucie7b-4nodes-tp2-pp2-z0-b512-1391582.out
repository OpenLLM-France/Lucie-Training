+ CHECKPOINT_PATH=/gpfswork/rech/qgz/urc37ho/checkpoints/
+ LOGS_PATH=/gpfswork/rech/qgz/urc37ho/lucie-logs
+ MEGATRON_DEEPSPEED_REPO=/gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya
+ cd /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya
+ DATASET=/gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document
+ TOKENIZER_PATH=OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all
++ head -n 1
++ scontrol show hostnames 'jean-zay-iam[09,15-16,21]'
+ MASTER_ADDR=jean-zay-iam09
+ MASTER_PORT=6000
+ GPUS_PER_NODE=8
+ NNODES=4
+ PP=2
+ TP=2
+ MICRO_BATCH_SIZE=4
+ GLOBAL_BATCH_SIZE=512
+ HIDDEN_SIZE=4096
+ FFN_HIDDEN_SIZE=11008
+ NUM_LAYERS=32
+ NUM_HEADS=32
+ SEQ_LENGTH=2048
+ NUM_KV_HEADS=32
+ TRAIN_STEPS=250000
+ LR=3e-4
+ MIN_LR=3e-5
+ LR_WARMUP_STEPS=2000
+ WEIGHT_DECAY=0.1
+ GRAD_CLIP=1
+ SAVE_INTERVAL=100
+ ZERO_STAGE=0
+ DS_CONFIG=./ds_config.1391582.json
+ activation_checkpoint=false
+ cat
+ ds_args=
+ ds_args=' --deepspeed '
+ ds_args=' --deepspeed_config=./ds_config.1391582.json  --deepspeed '
+ ds_args=' --zero-stage=0  --deepspeed_config=./ds_config.1391582.json  --deepspeed '
+ '[' false = true ']'
+ export CUDA_LAUNCH_BLOCKING=1
+ CUDA_LAUNCH_BLOCKING=1
+ export TORCHELASTIC_ERROR_FILE=/tmp/torch-elastic-error.json
+ TORCHELASTIC_ERROR_FILE=/tmp/torch-elastic-error.json
+ module purge
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash purge
+ eval
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ module load cpuarch/amd
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load cpuarch/amd
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
unset' 'MODULEPATH_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd;' export 'LOADEDMODULES;
MODULEPATH=/gpfslocalsup/pub/module-rh/modulefiles:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64;' export 'MODULEPATH;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ unset MODULEPATH_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd
++ export LOADEDMODULES
++ MODULEPATH=/gpfslocalsup/pub/module-rh/modulefiles:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64
++ export MODULEPATH
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ module load anaconda-py3/2023.09
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load anaconda-py3/2023.09
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=anaconda-py3/2023.09:1:cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
MODULES_LMCONFLICT_modshare=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2:1;' export 'MODULES_LMCONFLICT_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2;' export 'MODULES_LMCONFLICT;
.' '/gpfslocalsup/pub/anaconda-py3/2023.09/etc/profile.d/conda.sh;
conda' activate 'base;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=anaconda-py3/2023.09:1:cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ MODULES_LMCONFLICT_modshare='anaconda-py3/2023.09&anaconda-py3&anaconda-py2:1'
++ export MODULES_LMCONFLICT_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='anaconda-py3/2023.09&anaconda-py3&anaconda-py2'
++ export MODULES_LMCONFLICT
++ . /gpfslocalsup/pub/anaconda-py3/2023.09/etc/profile.d/conda.sh
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
++++ dirname /gpfslocalsup/pub/anaconda-py3/2023.09/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2023.09/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
+++ export CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2023.09
+++ CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2023.09
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ conda activate lucie-torch211
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate lucie-torch211
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate lucie-torch211
++ /gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda shell.posix activate lucie-torch211
+ ask_conda='PS1='\''(lucie-torch211) '\''
export PATH='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''lucie-torch211'\''
export CONDA_PROMPT_MODIFIER='\''(lucie-torch211) '\''
export CONDA_PREFIX_1='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\''
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libblas_mkl_activate.sh"
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libxml2_activate.sh"'
+ eval 'PS1='\''(lucie-torch211) '\''
export PATH='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin'\''
export CONDA_PREFIX='\''/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''lucie-torch211'\''
export CONDA_PROMPT_MODIFIER='\''(lucie-torch211) '\''
export CONDA_PREFIX_1='\''/gpfslocalsup/pub/anaconda-py3/2023.09'\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python'\''
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libblas_mkl_activate.sh"
. "/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libxml2_activate.sh"'
++ PS1='(lucie-torch211) '
++ export PATH=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
++ PATH=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
++ export CONDA_PREFIX=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
++ CONDA_PREFIX=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=lucie-torch211
++ CONDA_DEFAULT_ENV=lucie-torch211
++ export 'CONDA_PROMPT_MODIFIER=(lucie-torch211) '
++ CONDA_PROMPT_MODIFIER='(lucie-torch211) '
++ export CONDA_PREFIX_1=/gpfslocalsup/pub/anaconda-py3/2023.09
++ CONDA_PREFIX_1=/gpfslocalsup/pub/anaconda-py3/2023.09
++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2023.09/bin/python
++ . /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libblas_mkl_activate.sh
+++ export CONDA_MKL_INTERFACE_LAYER_BACKUP=
+++ CONDA_MKL_INTERFACE_LAYER_BACKUP=
+++ export MKL_INTERFACE_LAYER=LP64,GNU
+++ MKL_INTERFACE_LAYER=LP64,GNU
++ . /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/conda/activate.d/libxml2_activate.sh
+++ test -n ''
+++ xml_catalog_files_libxml2=
+++ XML_CATALOG_FILES=
+++ conda_catalog_files=
+++ ifs_libxml2=' 	
'
+++ IFS=' '
+++ rem=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ for pre in ${rem}
+++ test '' = /linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ conda_catalog_files=/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211
+++ rem=
+++ IFS=' 	
'
+++ conda_catalog_files='file:///linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/xml/catalog file:///etc/xml/catalog'
+++ export 'XML_CATALOG_FILES=file:///linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/xml/catalog file:///etc/xml/catalog'
+++ XML_CATALOG_FILES='file:///linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/etc/xml/catalog file:///etc/xml/catalog'
+++ unset conda_catalog_files ifs_libxml2 rem
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ module load cuda/12.1.0
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load cuda/12.1.0
+ eval 'LD_LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib;' export 'LD_LIBRARY_PATH;
MANPATH=/gpfslocalsys/cuda/12.1.0/doc/man::/opt/c3/man:/opt/clmgr/man:/opt/sgi/share/man:/opt/clmgr/share/man:/opt/clmgr/lib/cm-cli/man:/gpfslocalsys/slurm/current/share/man:/usr/share/catman:/usr/share/man:/usr/catman:/usr/man;' export 'MANPATH;
LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/lib64/stubs:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib;' export 'LIBRARY_PATH;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09:cuda/12.1.0;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2:cuda/12.1.0\&cuda;' export 'MODULES_LMCONFLICT;
MANPATH_modshare=:1:/opt/sgi/share/man:1:/gpfslocalsys/slurm/current/share/man:1:/opt/c3/man:1:/opt/clmgr/lib/cm-cli/man:1:/opt/clmgr/share/man:1:/usr/man:1:/usr/catman:1:/opt/clmgr/man:1:/gpfslocalsys/cuda/12.1.0/doc/man:1:/usr/share/man:1:/usr/share/catman:1;' export 'MANPATH_modshare;
NVHPC_CUDA_HOME=/gpfslocalsys/cuda/12.1.0;' export 'NVHPC_CUDA_HOME;
LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64/stubs:1:/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1;' export 'LIBRARY_PATH_modshare;
MODULES_LMCONFLICT_modshare=anaconda-py3/2023.09\&anaconda-py3\&anaconda-py2:1:cuda/12.1.0\&cuda:1;' export 'MODULES_LMCONFLICT_modshare;
CPLUS_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include;' export 'CPLUS_INCLUDE_PATH;
CUDA_INSTALL_PATH=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_INSTALL_PATH;
CUDA_ROOT=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_ROOT;
CUDA_PATH=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_PATH;
LD_LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1;' export 'LD_LIBRARY_PATH_modshare;
C_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include;' export 'C_INCLUDE_PATH;
_LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=cuda/12.1.0:1:cpuarch/amd:1:anaconda-py3/2023.09:1;' export 'LOADEDMODULES_modshare;
PATH=/gpfslocalsys/cuda/12.1.0/samples:/gpfslocalsys/cuda/12.1.0/nvvm/bin:/gpfslocalsys/cuda/12.1.0/bin:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin;' export 'PATH;
CUDA_HOME=/gpfslocalsys/cuda/12.1.0;' export 'CUDA_HOME;
PATH_modshare=/usr/bin:1:/gpfslocalsup/bin:1:/usr/local/bin:1:/gpfslocalsys/cuda/12.1.0/bin:1:/opt/sgi/bin:1:/gpfslocalsys/slurm/current/bin:1:/opt/clmgr/bin:1:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:1:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:1:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:1:/opt/sgi/sbin:1:/gpfslocalsys/cuda/12.1.0/samples:1:/bin:1:/opt/clmgr/sbin:1:/gpfslocalsys/bin:1:/gpfslocalsys/cuda/12.1.0/nvvm/bin:1:/sbin:1:/usr/sbin:1:/usr/local/sbin:1:/usr/lpp/mmfs/bin:1:/opt/c3/bin:1;' export 'PATH_modshare;
test' '0;'
++ LD_LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
++ export LD_LIBRARY_PATH
++ MANPATH=/gpfslocalsys/cuda/12.1.0/doc/man::/opt/c3/man:/opt/clmgr/man:/opt/sgi/share/man:/opt/clmgr/share/man:/opt/clmgr/lib/cm-cli/man:/gpfslocalsys/slurm/current/share/man:/usr/share/catman:/usr/share/man:/usr/catman:/usr/man
++ export MANPATH
++ LIBRARY_PATH=/gpfslocalsys/cuda/12.1.0/lib64/stubs:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:/gpfslocalsys/cuda/12.1.0/lib64:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
++ export LIBRARY_PATH
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:anaconda-py3/2023.09:cuda/12.1.0
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='anaconda-py3/2023.09&anaconda-py3&anaconda-py2:cuda/12.1.0&cuda'
++ export MODULES_LMCONFLICT
++ MANPATH_modshare=:1:/opt/sgi/share/man:1:/gpfslocalsys/slurm/current/share/man:1:/opt/c3/man:1:/opt/clmgr/lib/cm-cli/man:1:/opt/clmgr/share/man:1:/usr/man:1:/usr/catman:1:/opt/clmgr/man:1:/gpfslocalsys/cuda/12.1.0/doc/man:1:/usr/share/man:1:/usr/share/catman:1
++ export MANPATH_modshare
++ NVHPC_CUDA_HOME=/gpfslocalsys/cuda/12.1.0
++ export NVHPC_CUDA_HOME
++ LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64/stubs:1:/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1
++ export LIBRARY_PATH_modshare
++ MODULES_LMCONFLICT_modshare='anaconda-py3/2023.09&anaconda-py3&anaconda-py2:1:cuda/12.1.0&cuda:1'
++ export MODULES_LMCONFLICT_modshare
++ CPLUS_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include
++ export CPLUS_INCLUDE_PATH
++ CUDA_INSTALL_PATH=/gpfslocalsys/cuda/12.1.0
++ export CUDA_INSTALL_PATH
++ CUDA_ROOT=/gpfslocalsys/cuda/12.1.0
++ export CUDA_ROOT
++ CUDA_PATH=/gpfslocalsys/cuda/12.1.0
++ export CUDA_PATH
++ LD_LIBRARY_PATH_modshare=/gpfslocalsys/cuda/12.1.0/lib64:1:/gpfslocalsys/slurm/current/lib/slurm:1:/gpfslocalsys/cuda/12.1.0/nvvm/lib64:1:/gpfslocalsys/cuda/12.1.0/extras/CUPTI/lib64:1:/gpfslocalsys/cuda/12.1.0/targets/x86_64-linux/lib:1:/gpfslocalsys/cuda/12.1.0/samples/common/lib/linux/x86_64:1:/gpfslocalsys/slurm/current/lib:1
++ export LD_LIBRARY_PATH_modshare
++ C_INCLUDE_PATH=/gpfslocalsys/cuda/12.1.0/include
++ export C_INCLUDE_PATH
++ _LMFILES__modshare=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1:/gpfslocalsup/pub/module-rh/modulefiles/cuda/12.1.0:1:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/anaconda-py3/2023.09:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=cuda/12.1.0:1:cpuarch/amd:1:anaconda-py3/2023.09:1
++ export LOADEDMODULES_modshare
++ PATH=/gpfslocalsys/cuda/12.1.0/samples:/gpfslocalsys/cuda/12.1.0/nvvm/bin:/gpfslocalsys/cuda/12.1.0/bin:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin
++ export PATH
++ CUDA_HOME=/gpfslocalsys/cuda/12.1.0
++ export CUDA_HOME
++ PATH_modshare=/usr/bin:1:/gpfslocalsup/bin:1:/usr/local/bin:1:/gpfslocalsys/cuda/12.1.0/bin:1:/opt/sgi/bin:1:/gpfslocalsys/slurm/current/bin:1:/opt/clmgr/bin:1:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/bin:1:/gpfslocalsup/pub/anaconda-py3/2023.09/condabin:1:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:1:/opt/sgi/sbin:1:/gpfslocalsys/cuda/12.1.0/samples:1:/bin:1:/opt/clmgr/sbin:1:/gpfslocalsys/bin:1:/gpfslocalsys/cuda/12.1.0/nvvm/bin:1:/sbin:1:/usr/sbin:1:/usr/local/sbin:1:/usr/lpp/mmfs/bin:1:/opt/c3/bin:1
++ export PATH_modshare
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ DISTRIBUTED_ARGS='--nproc_per_node 8 --nnodes 4 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam09:6000 --rdzv_backend c10d --max_restarts 0 --tee 3'
++ pwd
+ export 'RUN=torchrun --nproc_per_node 8 --nnodes 4 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam09:6000 --rdzv_backend c10d --max_restarts 0 --tee 3        /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/pretrain_gpt.py        --data-cache-path /linkhome/rech/genlor01/urc37ho/.cache        --tensor-model-parallel-size 2        --pipeline-model-parallel-size 2        --num-layers 32        --hidden-size 4096        --ffn-hidden-size 11008        --num-attention-heads 32        --micro-batch-size 4        --global-batch-size 512        --seq-length 2048        --max-position-embeddings 2048        --train-iters 250000        --save /gpfswork/rech/qgz/urc37ho/checkpoints/        --load /gpfswork/rech/qgz/urc37ho/checkpoints/        --data-path /gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document        --data-impl mmap        --tokenizer-type PretrainedFromHF         --tokenizer-name-or-path OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all        --distributed-backend nccl        --lr 3e-4        --lr-decay-style cosine        --min-lr 3e-5        --weight-decay 0.1        --clip-grad 1        --lr-warmup-iters 2000        --optimizer adam        --adam-beta1 0.9        --adam-beta2 0.95        --log-interval 1        --save-interval 1000        --eval-interval 50        --eval-iters 50        --bf16        --use-flash-attn-v2        --no-query-key-layer-scaling        --attention-dropout 0        --hidden-dropout 0        --use-rotary-position-embeddings        --untie-embeddings-and-output-weights        --swiglu        --normalization rmsnorm        --disable-bias-linear        --num-key-value-heads 32         --zero-stage=0  --deepspeed_config=./ds_config.1391582.json  --deepspeed                 '
+ RUN='torchrun --nproc_per_node 8 --nnodes 4 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam09:6000 --rdzv_backend c10d --max_restarts 0 --tee 3        /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/pretrain_gpt.py        --data-cache-path /linkhome/rech/genlor01/urc37ho/.cache        --tensor-model-parallel-size 2        --pipeline-model-parallel-size 2        --num-layers 32        --hidden-size 4096        --ffn-hidden-size 11008        --num-attention-heads 32        --micro-batch-size 4        --global-batch-size 512        --seq-length 2048        --max-position-embeddings 2048        --train-iters 250000        --save /gpfswork/rech/qgz/urc37ho/checkpoints/        --load /gpfswork/rech/qgz/urc37ho/checkpoints/        --data-path /gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document        --data-impl mmap        --tokenizer-type PretrainedFromHF         --tokenizer-name-or-path OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all        --distributed-backend nccl        --lr 3e-4        --lr-decay-style cosine        --min-lr 3e-5        --weight-decay 0.1        --clip-grad 1        --lr-warmup-iters 2000        --optimizer adam        --adam-beta1 0.9        --adam-beta2 0.95        --log-interval 1        --save-interval 1000        --eval-interval 50        --eval-iters 50        --bf16        --use-flash-attn-v2        --no-query-key-layer-scaling        --attention-dropout 0        --hidden-dropout 0        --use-rotary-position-embeddings        --untie-embeddings-and-output-weights        --swiglu        --normalization rmsnorm        --disable-bias-linear        --num-key-value-heads 32         --zero-stage=0  --deepspeed_config=./ds_config.1391582.json  --deepspeed                 '
+ srun --jobid 1391582 bash -c 'torchrun --nproc_per_node 8 --nnodes 4 --node_rank $SLURM_PROCID --rdzv_endpoint jean-zay-iam09:6000 --rdzv_backend c10d --max_restarts 0 --tee 3        /gpfswork/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/pretrain_gpt.py        --data-cache-path /linkhome/rech/genlor01/urc37ho/.cache        --tensor-model-parallel-size 2        --pipeline-model-parallel-size 2        --num-layers 32        --hidden-size 4096        --ffn-hidden-size 11008        --num-attention-heads 32        --micro-batch-size 4        --global-batch-size 512        --seq-length 2048        --max-position-embeddings 2048        --train-iters 250000        --save /gpfswork/rech/qgz/urc37ho/checkpoints/        --load /gpfswork/rech/qgz/urc37ho/checkpoints/        --data-path /gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document        --data-impl mmap        --tokenizer-type PretrainedFromHF         --tokenizer-name-or-path OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all        --distributed-backend nccl        --lr 3e-4        --lr-decay-style cosine        --min-lr 3e-5        --weight-decay 0.1        --clip-grad 1        --lr-warmup-iters 2000        --optimizer adam        --adam-beta1 0.9        --adam-beta2 0.95        --log-interval 1        --save-interval 1000        --eval-interval 50        --eval-iters 50        --bf16        --use-flash-attn-v2        --no-query-key-layer-scaling        --attention-dropout 0        --hidden-dropout 0        --use-rotary-position-embeddings        --untie-embeddings-and-output-weights        --swiglu        --normalization rmsnorm        --disable-bias-linear        --num-key-value-heads 32         --zero-stage=0  --deepspeed_config=./ds_config.1391582.json  --deepspeed                 '
+ tee -a /gpfswork/rech/qgz/urc37ho/lucie-logs/main_log.txt
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-05 19:15:08,777] torch.distributed.run: [WARNING] *****************************************
[default0]:[2024-04-05 19:15:16,420] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-05 19:15:16,460] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-05 19:15:16,518] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-05 19:15:16,524] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-05 19:15:16,530] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-05 19:15:16,521] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-05 19:15:16,513] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-05 19:15:16,525] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[2024-04-05 19:15:16,437] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-05 19:15:16,463] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-05 19:15:16,546] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-05 19:15:16,531] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-05 19:15:16,548] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-05 19:15:16,540] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-05 19:15:16,543] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-05 19:15:16,535] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[2024-04-05 19:15:16,425] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default2]:[2024-04-05 19:15:16,481] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-05 19:15:16,475] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-05 19:15:16,484] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-05 19:15:16,435] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-05 19:15:16,532] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-05 19:15:16,530] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-05 19:15:16,532] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:/bin/sh: line 0: type: git: not found
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:/bin/sh: line 0: type: git: not found
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default0]:/bin/sh: line 0: type: git: not found
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default5]:/bin/sh: line 0: type: git: not found
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [default6]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default6]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default5]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default5]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default5]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default5]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default5]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:DeepSpeed general environment info:
[default5]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:torch version .................... 2.2.1
[default5]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default5]:deepspeed info ................... 0.12.6, unknown, unknown
[default5]:torch cuda version ............... 12.1
[default5]:torch hip version ................ None
[default5]:nvcc version ..................... 12.1
[default5]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default5]:shared memory (/dev/shm) size .... 251.60 GB
[default5]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default5]:/bin/sh: line 0: type: git: not found
[default0]:/bin/sh: line 0: type: git: not found
[default7]:/bin/sh: line 0: type: git: not found
[default1]:/bin/sh: line 0: type: git: not found
[default0]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default2]:[2024-04-05 19:15:16,453] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default6]:[2024-04-05 19:15:16,447] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2024-04-05 19:15:16,551] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default3]:[2024-04-05 19:15:16,518] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:[2024-04-05 19:15:16,486] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default7]:[2024-04-05 19:15:16,494] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2024-04-05 19:15:16,550] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default5]:[2024-04-05 19:15:16,512] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default4]:--------------------------------------------------
[default4]:DeepSpeed C++/CUDA extension op report
[default4]:--------------------------------------------------
[default4]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default4]:      runtime if needed. Op compatibility means that your system
[default4]:      meet the required dependencies to JIT install the op.
[default4]:--------------------------------------------------
[default4]:JIT compiled ops requires ninja
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default6]:--------------------------------------------------
[default6]:DeepSpeed C++/CUDA extension op report
[default6]:--------------------------------------------------
[default6]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default6]:      runtime if needed. Op compatibility means that your system
[default6]:      meet the required dependencies to JIT install the op.
[default6]:--------------------------------------------------
[default6]:JIT compiled ops requires ninja
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default5]:--------------------------------------------------
[default5]:DeepSpeed C++/CUDA extension op report
[default5]:--------------------------------------------------
[default5]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default5]:      runtime if needed. Op compatibility means that your system
[default5]:      meet the required dependencies to JIT install the op.
[default5]:--------------------------------------------------
[default5]:JIT compiled ops requires ninja
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default7]:--------------------------------------------------
[default7]:DeepSpeed C++/CUDA extension op report
[default7]:--------------------------------------------------
[default7]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default7]:      runtime if needed. Op compatibility means that your system
[default7]:      meet the required dependencies to JIT install the op.
[default7]:--------------------------------------------------
[default7]:JIT compiled ops requires ninja
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default4]:ninja .................. [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:op name ................ installed .. compatible
[default4]:--------------------------------------------------
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default6]:ninja .................. [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:op name ................ installed .. compatible
[default6]:--------------------------------------------------
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default5]:ninja .................. [92m[OKAY][0m
[default5]:--------------------------------------------------
[default5]:op name ................ installed .. compatible
[default5]:--------------------------------------------------
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default7]:ninja .................. [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:op name ................ installed .. compatible
[default7]:--------------------------------------------------
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default4]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default6]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default5]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default7]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default4]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default4]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default4]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default4]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default4]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default3]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default2]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default6]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default6]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default6]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default6]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default1]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default5]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default5]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default5]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default5]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default5]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default5]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default5]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default7]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default7]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default7]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default7]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[default0]:evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:/bin/sh: line 0: type: git: not found
[default2]:/bin/sh: line 0: type: git: not found
[default0]:/bin/sh: line 0: type: git: not found
[default0]:loading file tokenizer.model from cache at None
[default0]:loading file tokenizer.json from cache at /linkhome/rech/genlor01/urc37ho/.cache/huggingface/hub/models--OpenLLM-France--Lucie-tokenizer-v2.4-space_prefix_all/snapshots/edf1b3d40698a2eec64a63aa8731c510e5810ae6/tokenizer.json
[default0]:loading file added_tokens.json from cache at None
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default1]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default1]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 2.2.1
[default0]:loading file special_tokens_map.json from cache at /linkhome/rech/genlor01/urc37ho/.cache/huggingface/hub/models--OpenLLM-France--Lucie-tokenizer-v2.4-space_prefix_all/snapshots/edf1b3d40698a2eec64a63aa8731c510e5810ae6/special_tokens_map.json
[default0]:loading file tokenizer_config.json from cache at /linkhome/rech/genlor01/urc37ho/.cache/huggingface/hub/models--OpenLLM-France--Lucie-tokenizer-v2.4-space_prefix_all/snapshots/edf1b3d40698a2eec64a63aa8731c510e5810ae6/tokenizer_config.json
[default5]:/bin/sh: line 0: type: git: not found
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:using world size: 32, data-parallel-size: 8, sequence-parallel size: 1, tensor-model-parallel size: 2, pipeline-model-parallel size: 2 
[default0]:accumulate and all-reduce gradients in fp32 for bfloat16 data type.
[default0]:using torch.bfloat16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  accumulate_allreduce_grads_in_fp32 .............. True
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  add_bias_linear ................................. False
[default0]:  add_position_embedding .......................... False
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  aml_data_download_path .......................... None
[default0]:  apply_layernorm_1p .............................. False
[default0]:  apply_query_key_layer_scaling ................... False
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  async_tensor_model_parallel_allreduce ........... False
[default0]:  attention_dropout ............................... 0.0
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  barrier_with_L1_time ............................ True
[default0]:  bert_binary_head ................................ True
[default0]:  bert_embedder_type .............................. megatron
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ True
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ False
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [default1]:/bin/sh: line 0: type: git: not found
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... False
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  classes_fraction ................................ 1.0
[default0]:  clip_grad ....................................... 1.0
[default0]:  compression_training ............................ False
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  create_moe_param_group .......................... False
[default0]:  curriculum_learning_legacy ...................... False
[default0]:  data_cache_path ................................. /linkhome/rech/genlor01/urc37ho/.cache
[default0]:  data_efficiency_curriculum_learning ............. False
[default0]:  data_impl ....................................... mmap
[default0]:  data_parallel_random_init ....................... False
[default0]:  data_parallel_size .............................. 8
[default0]:  data_path ....................................... ['/gpfsscratch/rech/qgz/commun/preprocessed_data/Lucie/lucie_tokens_2.4-space_prefix_all/Wikipedia--fr--026_text_document']
[default0]:  data_per_class_fraction ......................... 1.0
[default0]:  data_sharding ................................... True
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_num_layers .............................. None
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. False
[default0]:  deepspeed_config ................................ ./ds_config.1391582.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  dino_bottleneck_size ............................ 256
[default0]:  dino_freeze_last_layer .......................... 1
[default0]:  dino_head_hidden_size ........................... 2048
[default0]:  dino_local_crops_number ......................... 10
[default0]:  dino_local_img_size ............................. 96
[default0]:  dino_norm_last_layer ............................ False
[default0]:  dino_teacher_temp ............................... 0.07
[default0]:  dino_warmup_teacher_temp ........................ 0.04
[default0]:  dino_warmup_teacher_temp_epochs ................. 30
[default0]:  disable_mem_efficient_ln ........................ True
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distribute_saved_activations .................... False
[default0]:  distributed_backend ............................. nccl
[default0]:  distributed_timeout_minutes ..................... 10
[default0]:  ds_inference .................................... False
[default0]:  ds_pipeline_enabled ............................. True
[default0]:  ds_sequence_parallel_size ....................... 1
[default0]:  embedding_path .................................. None
[default0]:  embedding_weights_in_fp32 ....................... False
[default0]:  empty_unused_memory_level ....................... 0
[default0]:  enable_expert_tensor_parallelism ................ False
[default0]:  encoder_num_layers .............................. 32
[default0]:  encoder_seq_length .............................. 2048
[default0]:  end_weight_decay ................................ 0.1
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 50
[default0]:  eval_iters ...................................... 50
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... None
[default0]:  exit_on_missing_checkpoint ...................... False
[default0]:  exit_signal_handler ............................. False
[default0]:  expert_interval ................................. 2
[default0]:  ffn_hidden_size ................................. 11008
[default0]:  finetune ........................................ False
[default0]:  force_ds_sequence_parallel ...................... False
[default0]:  fp16 ............................................ False
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  fp8_amax_compute_algo ........................... most_recent
[default0]:  fp8_amax_history_len ............................ 1
[default0]:  fp8_e4m3 ........................................ False
[default0]:  fp8_hybrid ...................................... False
[default0]:  fp8_interval .................................... 1
[default0]:  fp8_margin ...................................... 0
[default0]:  fp8_wgrad ....................................... True
[default0]:  global_batch_size ............................... 512
[default0]:  gradient_accumulation_fusion .................... True
[default0]:  head_lr_mult .................................... 1.0
[default0]:  hidden_dropout .................................. 0.0
[default0]:  hidden_size ..................................... 4096
[default0]:  hidden_size_teacher ............................. None
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_h ........................................... 224
[default0]:  img_w ........................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  inference_batch_times_seqlen_threshold .......... 512
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  iter_per_epoch .................................. 1250
[default0]:  kd .............................................. False
[default0]:  kd_alpha_ce ..................................... 1
[default0]:  kd_beta_ce ...................................... 1
[default0]:  kd_temp ......................................... 1.0
[default0]:  kv_channels ..................................... 128
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ /gpfswork/rech/qgz/urc37ho/checkpoints/
[default0]:  load_iteration .................................. None
[default0]:  load_teacher .................................... None
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... False
[default0]:  log_interval .................................... 1
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_memory_to_tensorboard ....................... False
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_optimizer_states_to_tensorboard ............. False
[default0]:  log_params_norm ................................. False
[default0]:  log_timers_to_tensorboard ....................... False
[default0]:  log_validation_ppl_to_tensorboard ............... False
[default0]:  log_world_size_to_tensorboard ................... False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0003
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 2000
[default0]:  lr_warmup_samples ............................... 0
[default0]:  lr_warmup_tokens ................................ None
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_factor ..................................... 1.0
[default0]:  mask_prob ....................................... 0.15
[default0]:  mask_type ....................................... random
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 2048
[default0]:  max_tokens_to_oom ............................... 12000
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... None
[default0]:  micro_batch_size ................................ 4
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 3e-05
[default0]:  mlp_type ........................................ standard
[default0]:  mmap_warmup ..................................... False
[default0]:  moe_eval_capacity_factor ........................ 1.0
[default0]:  moe_expert_parallel_size ........................ 1
[default0]:  moe_loss_coeff .................................. 0.1
[default0]:  moe_min_capacity ................................ 4
[default0]:  moe_token_dropping .............................. True
[default0]:  moe_train_capacity_factor ....................... 1.0
[default0]:  mos ............................................. False
[default0]:  multiple_valid_sets ............................. False
[default0]:  no_load_lr_state ................................ False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_persist_layer_norm ........................... False
[default0]:  no_pipeline_parallel ............................ False
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  normalization ................................... rmsnorm
[default0]:  num_attention_heads ............................. 32
[default0]:  num_attention_heads_teacher ..................... None
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_experts ..................................... [1]
[default0]:  num_experts_switch .............................. None
[default0]:  num_experts_teacher ............................. [1]
[default0]:  num_key_value_heads ............................. 32
[default0]:  num_layers ...................................... 32
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_layers_teacher .............................. None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  output_bert_embeddings .......................... False
[default0]:  overlap_p2p_comm ................................ False
[default0]:  override_opt_param_scheduler .................... False
[default0]:  params_dtype .................................... torch.bfloat16
[default0]:  partition_activations ........................... False
[default0]:  patch_dim ....................................... 16
[default0]:  perform_initialization .......................... True
[default0]:  pipeline_model_parallel_size .................... 2
[default0]:  pipeline_model_parallel_split_rank .............. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  random_ltd ...................................... False
[default0]:  rank ............................................ 0
[default0]:  recompute_granularity ........................... None
[default0]:  recompute_method ................................ None
[default0]:  recompute_num_layers ............................ 1
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_iteration ................................. False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  retro_add_retriever ............................. False
[default0]:  retro_cyclic_train_iters ........................ None
[default0]:  retro_encoder_attention_dropout ................. 0.1
[default0]:  retro_encoder_hidden_dropout .................... 0.1
[default0]:  retro_encoder_layers ............................ 2
[default0]:  retro_num_neighbors ............................. 2
[default0]:  retro_num_retrieved_chunks ...................... 2
[default0]:  retro_return_doc_ids ............................ False
[default0]:  retro_workdir ................................... None
[default0]:  return_data_index ............................... False
[default0]:  rotary_percent .................................. 1.0
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ /gpfswork/rech/qgz/urc37ho/checkpoints/
[default0]:  save_interval ................................... 1000
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 1234
[default0]:  seq_length ...................................... 2048
[default0]:  sequence_parallel ............................... False
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train ...................................... False
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  squared_relu .................................... False
[default0]:  standalone_embedding_stage ...................... False
[default0]:  start_weight_decay .............................. 0.1
[default0]:  swiglu .......................................... True
[default0]:  swin_backbone_type .............................. tiny
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 2
[default0]:  tensorboard_dir ................................. None
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 1000
[default0]:  test_data_path .................................. None
[default7]:/bin/sh: line 0: type: git: not found
[default3]:/bin/sh: line 0: type: git: not found
[default4]:/bin/sh: line 0: type: git: not found
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:Loading extension module scaled_softmax_cuda...
[default1]:[rank25]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank28]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank27]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank11]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank13]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank9]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank8]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank10]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank12]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank14]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank7]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank6]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank30]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default6]:[rank22]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank15]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank23]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank21]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank4]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default7]:[rank31]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank29]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default5]:[rank5]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:[rank19]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank24]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default4]:[rank20]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank18]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default1]:[rank17]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default0]:[rank16]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default2]:[rank26]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default3]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default3]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default5]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default5]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default1]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default1]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default0]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default2]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default2]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default4]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default4]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default6]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default6]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default7]:/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/training.py:135: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/tensor/python_tensor.cpp:83.)
[default7]:  start_time_tensor = get_accelerator().DoubleTensor([_TRAIN_START_TIME])
[default0]:  tile_factor ..................................... 1
[default0]:  timing_log_level ................................ 0
[default0]:  timing_log_option ............................... minmax
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_model ................................. None
[default0]:  tokenizer_name_or_path .......................... OpenLLM-France/Lucie-tokenizer-v2.4-space_prefix_all
[default0]:  tokenizer_type .................................. PretrainedFromHF
[default0]:  topk ............................................ 1
[default0]:  train_data_exact_num_epochs ..................... None
[default0]:  train_data_path ................................. None
[default0]:  train_desc_path ................................. None
[default0]:  train_doc_idx_path .............................. None
[default0]:  train_idx_path .................................. None
[default0]:  train_iters ..................................... 250000
[default0]:  train_sample_idx_path ........................... None
[default0]:  train_samples ................................... None
[default0]:  train_shuffle_idx_path .......................... None
[default0]:  train_tokens .................................... None
[default0]:  transformer_impl ................................ local
[default0]:  transformer_pipeline_model_parallel_size ........ 2
[default0]:  universal_checkpoint ............................ False
[default0]:  untie_embeddings_and_output_weights ............. True
[default0]:  use_checkpoint_args ............................. False
[default0]:  use_checkpoint_opt_param_scheduler .............. False
[default0]:  use_contiguous_buffers_in_local_ddp ............. True
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_dataset_only ................................ False
[default0]:  use_distributed_optimizer ....................... False
[default0]:  use_flash_attn .................................. True
[default0]:  use_flash_attn_triton ........................... False
[default0]:  use_flash_attn_v1 ............................... False
[default0]:  use_flash_attn_v2 ............................... True
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  use_ring_exchange_p2p ........................... False
[default0]:  use_rotary_position_embeddings .................. True
[default0]:  use_tutel ....................................... False
[default0]:  valid_data_path ................................. None
[default0]:  variable_seq_lengths ............................ False
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vision_backbone_type ............................ vit
[default0]:  vision_pretraining .............................. False
[default0]:  vision_pretraining_type ......................... classify
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... None
[default0]:  vocab_size ...................................... None
[default0]:  wandb_api_key ................................... None
[default0]:  wandb_entity .................................... None
[default0]:  wandb_id ........................................ None
[default0]:  wandb_logger .................................... False
[default0]:  wandb_project ................................... megatron-ds-training
[default0]:  wandb_resume .................................... None
[default0]:  wandb_run_name .................................. None
[default0]:  weight_decay .................................... 0.1
[default0]:  weight_decay_incr_style ......................... constant
[default0]:  world_size ...................................... 32
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 0
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 16
[default0]:> building PretrainedFromHF tokenizer ...
[default0]: vocab file is un-used. loading tokenizer from pre-trained model
[default0]: > padded vocab (size: 32000) with 0 dummy tokens (new size: 32000)
[default0]:> initializing torch distributed ...
[default0]:[2024-04-05 19:15:48,156] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]:[2024-04-05 19:15:48,156] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default4]:[2024-04-05 19:15:49,066] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-05 19:15:49,054] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-05 19:15:49,058] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-05 19:15:49,048] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-05 19:15:49,054] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-05 19:15:49,054] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-05 19:15:49,040] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]:> initialized tensor model parallel with size 2
[default0]:> initialized pipeline model parallel with size 2
[default0]:> setting random seeds to 1234 ...
[default0]:> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
[default0]:> compiling dataset index builder ...
[default0]:make: Entering directory '/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/gpfsdswork/projects/rech/qgz/urc37ho/Megatron-DeepSpeed-yaya/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 0.147 seconds
[default0]:> compiling and loading fused kernels ...
[default0]:ninja: no work to do.
[default0]:ninja: no work to do.
[default0]:ninja: no work to do.
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 65.427 seconds
[default0]:time to initialize megatron (seconds): 86.609
[default0]:[after megatron is initialized] datetime: 2024-04-05 19:17:00 
[default0]:building GPT model ...
[default0]:[2024-04-05 19:17:00,112] [INFO] [utils.py:791:see_memory_usage] Before Building Model
[default0]:[2024-04-05 19:17:00,113] [INFO] [utils.py:792:see_memory_usage] MA 0.0 GB         Max_MA 1.43 GB         CA 0.0 GB         Max_CA 1 GB 
[default0]:[2024-04-05 19:17:00,113] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 28.71 GB, percent = 5.7%
[default0]:SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default0]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 2.2.1
[default0]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.12.6, unknown, unknown
[default0]:torch cuda version ............... 12.1
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 12.1
[default0]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default0]:shared memory (/dev/shm) size .... 251.60 GB
[default0]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-05 19:15:47,921] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-05 19:15:48,207] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-05 19:15:48,208] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-05 19:15:53,476] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-05 19:15:53,449] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-05 19:15:53,476] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-05 19:15:53,474] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-05 19:15:53,476] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]: > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 1684672512
[default1]: > total number of parameters in model: 1684672512
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 1684672512
[default0]: > total number of parameters in model: 1684672512
[default4]:[2024-04-05 19:17:01,874] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default1]:[2024-04-05 19:17:01,880] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default6]:[2024-04-05 19:17:01,873] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default2]:[2024-04-05 19:17:01,873] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default5]:[2024-04-05 19:17:01,883] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default7]:[2024-04-05 19:17:01,883] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default3]:[2024-04-05 19:17:01,884] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default0]:Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=1, model=0): 2, ProcessCoord(pipe=0, data=1, model=1): 3, ProcessCoord(pipe=0, data=2, model=0): 4, ProcessCoord(pipe=0, data=2, model=1): 5, ProcessCoord(pipe=0, data=3, model=0): 6, ProcessCoord(pipe=0, data=3, model=1): 7, ProcessCoord(pipe=0, data=4, model=0): 8, ProcessCoord(pipe=0, data=4, model=1): 9, ProcessCoord(pipe=0, data=5, model=0): 10, ProcessCoord(pipe=0, data=5, model=1): 11, ProcessCoord(pipe=0, data=6, model=0): 12, ProcessCoord(pipe=0, data=6, model=1): 13, ProcessCoord(pipe=0, data=7, model=0): 14, ProcessCoord(pipe=0, data=7, model=1): 15, ProcessCoord(pipe=1, data=0, model=0): 16, ProcessCoord(pipe=1, data=0, model=1): 17, ProcessCoord(pipe=1, data=1, model=0): 18, ProcessCoord(pipe=1, data=1, model=1): 19, ProcessCoord(pipe=1, data=2, model=0): 20, ProcessCoord(pipe=1, data=2, model=1): 21, ProcessCoord(pipe=1, data=3, model=0): 22, ProcessCoord(pipe=1, data=3, model=1): 23, ProcessCoord(pipe=1, data=4, model=0): 24, ProcessCoord(pipe=1, data=4, model=1): 25, ProcessCoord(pipe=1, data=5, model=0): 26, ProcessCoord(pipe=1, data=5, model=1): 27, ProcessCoord(pipe=1, data=6, model=0): 28, ProcessCoord(pipe=1, data=6, model=1): 29, ProcessCoord(pipe=1, data=7, model=0): 30, ProcessCoord(pipe=1, data=7, model=1): 31}
[default0]:[2024-04-05 19:17:00,116] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer
[default0]:stage=0 layers=18
[default0]:     0: _to_float16
[default0]:     1: EmbeddingPipe
[default0]:     2: ParallelTransformerLayerPipe
[default0]:     3: ParallelTransformerLayerPipe
[default0]:     4: ParallelTransformerLayerPipe
[default0]:     5: ParallelTransformerLayerPipe
[default0]:     6: ParallelTransformerLayerPipe
[default0]:     7: ParallelTransformerLayerPipe
[default0]:     8: ParallelTransformerLayerPipe
[default0]:     9: ParallelTransformerLayerPipe
[default0]:    10: ParallelTransformerLayerPipe
[default0]:    11: ParallelTransformerLayerPipe
[default0]:    12: ParallelTransformerLayerPipe
[default0]:    13: ParallelTransformerLayerPipe
[default0]:    14: ParallelTransformerLayerPipe
[default0]:    15: ParallelTransformerLayerPipe
[default0]:    16: ParallelTransformerLayerPipe
[default0]:    17: ParallelTransformerLayerPipe
[default0]:stage=1 layers=19
[default0]:    18: ParallelTransformerLayerPipe
[default0]:    19: ParallelTransformerLayerPipe
[default0]:    20: ParallelTransformerLayerPipe
[default0]:    21: ParallelTransformerLayerPipe
[default0]:    22: ParallelTransformerLayerPipe
[default0]:    23: ParallelTransformerLayerPipe
[default0]:    24: ParallelTransformerLayerPipe
[default0]:    25: ParallelTransformerLayerPipe
[default0]:    26: ParallelTransformerLayerPipe
[default0]:    27: ParallelTransformerLayerPipe
[default0]:    28: ParallelTransformerLayerPipe
[default0]:    29: ParallelTransformerLayerPipe
[default0]:    30: ParallelTransformerLayerPipe
[default0]:    31: ParallelTransformerLayerPipe
[default0]:    32: ParallelTransformerLayerPipe
[default0]:    33: ParallelTransformerLayerPipe
[default0]:    34: MixedFusedRMSNorm
[default0]:    35: LMHeadPipe
[default0]:    36: float16_to_fp32
[default0]:  loss: CrossEntropy
[default1]: > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 1684668416
[default1]: > total number of parameters in model: 1684668416
[default0]:[2024-04-05 19:17:00,350] [INFO] [utils.py:791:see_memory_usage] After Building Model
[default0]:[2024-04-05 19:17:00,350] [INFO] [utils.py:792:see_memory_usage] MA 3.17 GB         Max_MA 3.19 GB         CA 3.19 GB         Max_CA 3 GB 
[default0]:[2024-04-05 19:17:00,351] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 28.98 GB, percent = 5.8%
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1684668416
[default0]: > total number of parameters in model: 1684668416
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2024-04-05 19:17:00,352] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown
[default3]:[2024-04-05 19:17:01,995] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default6]:[2024-04-05 19:17:01,996] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default4]:[2024-04-05 19:17:01,993] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default5]:[2024-04-05 19:17:01,997] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default2]:[2024-04-05 19:17:01,996] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default1]:[2024-04-05 19:17:01,995] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default7]:[2024-04-05 19:17:01,996] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default0]:[2024-04-05 19:17:01,928] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2024-04-05 19:17:01,928] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2024-04-05 19:17:01,928] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[default0]:[2024-04-05 19:17:01,929] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2024-04-05 19:17:01,929] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[default0]:[2024-04-05 19:17:01,987] [INFO] [utils.py:791:see_memory_usage] begin bf16_optimizer
[default0]:[2024-04-05 19:17:01,988] [INFO] [utils.py:792:see_memory_usage] MA 3.16 GB         Max_MA 3.17 GB         CA 3.19 GB         Max_CA 3 GB 
[default0]:[2024-04-05 19:17:01,988] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.6 GB, percent = 5.9%
[default0]:[2024-04-05 19:17:02,041] [INFO] [utils.py:791:see_memory_usage] before initializing group 0
[default0]:[2024-04-05 19:17:02,042] [INFO] [utils.py:792:see_memory_usage] MA 3.16 GB         Max_MA 3.16 GB         CA 3.19 GB         Max_CA 3 GB 
[default0]:[2024-04-05 19:17:02,042] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.6 GB, percent = 5.9%
[default0]:[2024-04-05 19:17:02,184] [INFO] [utils.py:791:see_memory_usage] after initializing group 0
[default0]:[2024-04-05 19:17:02,185] [INFO] [utils.py:792:see_memory_usage] MA 10.2 GB         Max_MA 10.2 GB         CA 13.78 GB         Max_CA 14 GB 
[default0]:[2024-04-05 19:17:02,185] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.61 GB, percent = 5.9%
[default0]:[2024-04-05 19:17:02,237] [INFO] [utils.py:791:see_memory_usage] before initializing group 1
[default0]:[2024-04-05 19:17:02,238] [INFO] [utils.py:792:see_memory_usage] MA 10.2 GB         Max_MA 10.2 GB         CA 13.78 GB         Max_CA 14 GB 
[default0]:[2024-04-05 19:17:02,238] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.61 GB, percent = 5.9%
[default0]:[2024-04-05 19:17:02,302] [INFO] [utils.py:791:see_memory_usage] after initializing group 1
[default0]:[2024-04-05 19:17:02,302] [INFO] [utils.py:792:see_memory_usage] MA 10.2 GB         Max_MA 10.2 GB         CA 13.78 GB         Max_CA 14 GB 
[default0]:[2024-04-05 19:17:02,302] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.61 GB, percent = 5.9%
[default0]:[2024-04-05 19:17:02,356] [INFO] [utils.py:791:see_memory_usage] before initialize_optimizer
[default0]:[2024-04-05 19:17:02,356] [INFO] [utils.py:792:see_memory_usage] MA 10.2 GB         Max_MA 10.2 GB         CA 13.78 GB         Max_CA 14 GB 
[default0]:[2024-04-05 19:17:02,357] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.71 GB, percent = 5.9%
[default0]:[2024-04-05 19:17:02,423] [INFO] [utils.py:791:see_memory_usage] end initialize_optimizer
[default0]:[2024-04-05 19:17:02,424] [INFO] [utils.py:792:see_memory_usage] MA 11.78 GB         Max_MA 11.78 GB         CA 15.35 GB         Max_CA 15 GB 
[default0]:[2024-04-05 19:17:02,424] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.86 GB, percent = 5.9%
[default0]:[2024-04-05 19:17:02,478] [INFO] [utils.py:791:see_memory_usage] end bf16_optimizer
[default0]:[2024-04-05 19:17:02,478] [INFO] [utils.py:792:see_memory_usage] MA 11.78 GB         Max_MA 11.78 GB         CA 15.35 GB         Max_CA 15 GB 
[default0]:[2024-04-05 19:17:02,479] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 29.98 GB, percent = 6.0%
[default0]:[2024-04-05 19:17:02,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2024-04-05 19:17:02,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2024-04-05 19:17:02,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x14d0634348e0>
[default0]:[2024-04-05 19:17:02,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2024-04-05 19:17:02,479] [INFO] [config.py:984:print] DeepSpeedEngine configuration:
[default0]:[2024-04-05 19:17:02,479] [INFO] [config.py:988:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2024-04-05 19:17:02,479] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2024-04-05 19:17:02,479] [INFO] [config.py:988:print]   amp_enabled .................. False
[default0]:[2024-04-05 19:17:02,479] [INFO] [config.py:988:print]   amp_params ................... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   bfloat16_enabled ............. True
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x14d063435960>
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   communication_data_type ...... None
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   dataloader_drop_last ......... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   disable_allgather ............ False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   dump_state ................... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   elasticity_enabled ........... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "recompute_fwd_factor": 0.0, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   fp16_auto_cast ............... None
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   fp16_enabled ................. False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   global_rank .................. 0
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 16
[default1]:torch version .................... 2.2.1
[default1]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.12.6, unknown, unknown
[default1]:torch cuda version ............... 12.1
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 12.1
[default1]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default1]:shared memory (/dev/shm) size .... 251.60 GB
[default1]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default7]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default7]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default7]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default7]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default7]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default7]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default7]:--------------------------------------------------
[default7]:DeepSpeed general environment info:
[default7]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default7]:torch version .................... 2.2.1
[default7]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default7]:deepspeed info ................... 0.12.6, unknown, unknown
[default7]:torch cuda version ............... 12.1
[default7]:torch hip version ................ None
[default7]:nvcc version ..................... 12.1
[default7]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default7]:shared memory (/dev/shm) size .... 251.60 GB
[default7]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default6]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default6]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default6]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default6]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default6]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default6]:--------------------------------------------------
[default6]:DeepSpeed general environment info:
[default6]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default0]:[2024-04-05 19:15:52,851] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-05 19:15:53,853] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-05 19:15:53,868] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-05 19:15:53,880] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-05 19:15:53,853] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-05 19:15:53,871] [INFO] [comm.py:637:init_distributed] cdb=None
[default6]:[2024-04-05 19:15:53,880] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-05 19:15:53,882] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]:[2024-04-05 19:17:01,874] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default4]:[2024-04-05 19:17:01,874] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default2]:[2024-04-05 19:17:01,874] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default7]:[2024-04-05 19:17:01,886] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default1]:[2024-04-05 19:17:01,883] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default3]:[2024-04-05 19:17:01,883] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default6]:[2024-04-05 19:17:01,873] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default5]:[2024-04-05 19:17:01,885] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default6]:torch version .................... 2.2.1
[default6]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default6]:deepspeed info ................... 0.12.6, unknown, unknown
[default6]:torch cuda version ............... 12.1
[default6]:torch hip version ................ None
[default6]:nvcc version ..................... 12.1
[default6]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default6]:shared memory (/dev/shm) size .... 251.60 GB
[default6]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default2]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default2]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 2.2.1
[default2]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.12.6, unknown, unknown
[default2]:torch cuda version ............... 12.1
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 12.1
[default2]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default2]:shared memory (/dev/shm) size .... 251.60 GB
[default2]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default4]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default4]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default4]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default4]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default4]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default4]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default4]:--------------------------------------------------
[default4]:DeepSpeed general environment info:
[default4]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default4]:torch version .................... 2.2.1
[default4]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default4]:deepspeed info ................... 0.12.6, unknown, unknown
[default4]:torch cuda version ............... 12.1
[default4]:torch hip version ................ None
[default4]:nvcc version ..................... 12.1
[default4]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default4]:shared memory (/dev/shm) size .... 251.60 GB
[default4]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default3]:inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[default3]:[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 2.2.1
[default3]:deepspeed install path ........... ['/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.12.6, unknown, unknown
[default3]:torch cuda version ............... 12.1
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 12.1
[default3]:deepspeed wheel compiled w. ...... torch 2.2, cuda 12.1
[default3]:shared memory (/dev/shm) size .... 251.60 GB
[default3]:**** Git info for Megatron: git_hash=unknown git_branch=unknown ****
[default6]:[2024-04-05 19:15:48,332] [INFO] [comm.py:637:init_distributed] cdb=None
[default2]:[2024-04-05 19:15:48,332] [INFO] [comm.py:637:init_distributed] cdb=None
[default4]:[2024-04-05 19:15:48,332] [INFO] [comm.py:637:init_distributed] cdb=None
[default0]:[2024-04-05 19:15:52,811] [INFO] [comm.py:637:init_distributed] cdb=None
[default1]:[2024-04-05 19:15:53,466] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-05 19:15:53,462] [INFO] [comm.py:637:init_distributed] cdb=None
[default5]:[2024-04-05 19:15:53,466] [INFO] [comm.py:637:init_distributed] cdb=None
[default3]:[2024-04-05 19:15:53,466] [INFO] [comm.py:637:init_distributed] cdb=None
[default7]:[2024-04-05 19:17:01,995] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default0]:[2024-04-05 19:17:02,000] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default5]:[2024-04-05 19:17:02,000] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default2]:[2024-04-05 19:17:01,999] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default3]:[2024-04-05 19:17:02,001] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default4]:[2024-04-05 19:17:02,001] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default1]:[2024-04-05 19:17:02,000] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default6]:[2024-04-05 19:17:02,001] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   gradient_clipping ............ 0.0
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   graph_harvesting ............. False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 1
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   load_universal_checkpoint .... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   loss_scale ................... 1.0
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   memory_breakdown ............. False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   mics_shard_size .............. -1
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   optimizer_name ............... None
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   optimizer_params ............. None
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[default0]:[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   pld_enabled .................. False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   pld_params ................... False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   prescale_gradients ........... False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   scheduler_name ............... None
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   scheduler_params ............. None
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   sparse_attention ............. None
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   steps_per_print .............. 1
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   train_batch_size ............. 512
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  4
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   use_node_local_storage ....... False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   weight_quantization_config ... None
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   world_size ................... 8
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   zero_enabled ................. False
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:988:print]   zero_optimization_stage ...... 0
[default0]:[2024-04-05 19:17:02,481] [INFO] [config.py:974:print_user_config]   json = {
[default0]:    "train_batch_size": 512, 
[default0]:    "train_micro_batch_size_per_gpu": 4, 
[default0]:    "steps_per_print": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 0
[default0]:    }, 
[default0]:    "bf16": {
[default0]:        "enabled": true
[default0]:    }
[default0]:}
[default0]:[2024-04-05 19:17:02,481] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=16 micro_batch_size=4
[default0]:[2024-04-05 19:17:02,481] [INFO] [engine.py:139:__init__] is_pipe_partitioned= True is_grad_partitioned= True
[default1]:[2024-04-05 19:17:02,830] [INFO] [engine.py:158:__init__] RANK=1 STAGE=0 LAYERS=18 [0, 18) STAGE_PARAMS=1684668416 (1684.668M) TOTAL_PARAMS=6738681856 (6738.682M) UNIQUE_PARAMS=6738681856 (6738.682M)
[default0]:[2024-04-05 19:17:02,830] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=18 [0, 18) STAGE_PARAMS=1684668416 (1684.668M) TOTAL_PARAMS=6738681856 (6738.682M) UNIQUE_PARAMS=6738681856 (6738.682M)
[default6]:[2024-04-05 19:17:02,984] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-05 19:17:02,984] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-05 19:17:02,984] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-05 19:17:02,984] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2024-04-05 19:17:02,984] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default1]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default1]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default0]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default3]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default3]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default5]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default5]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default4]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default4]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default7]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default7]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default2]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default2]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default6]:/linkhome/rech/genlor01/urc37ho/.conda/envs/lucie-torch211/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
[default6]:  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[default0]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default4]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default6]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default5]:[2024-04-05 19:17:02,985] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default7]:(min, max) time across ranks (ms):
[default7]:    load-checkpoint ................................: (28.59, 28.84)
[default7]:(min, max) time across ranks (ms):
[default7]:    model-and-optimizer-setup ......................: (2958.91, 3212.98)
[default7]:    train/valid/test-data-iterators-setup ..........: (2281.47, 3247.31)
[default7]: iteration        1/  250000 | consumed samples:          512 | consumed tokens:      1048576 | elapsed time per iteration (ms): 15598.6 | learning rate: 1.500E-07 | global batch size:   512 | lm loss: 1.121062E+01 | grad norm: 16.110 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 32.823 | TFLOPs: 89.21 |
[default7]: iteration        2/  250000 | consumed samples:         1024 | consumed tokens:      2097152 | elapsed time per iteration (ms): 11569.6 | learning rate: 3.000E-07 | global batch size:   512 | lm loss: 1.120294E+01 | grad norm: 14.291 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.254 | TFLOPs: 120.27 |
[default7]: iteration        3/  250000 | consumed samples:         1536 | consumed tokens:      3145728 | elapsed time per iteration (ms): 11614.4 | learning rate: 4.500E-07 | global batch size:   512 | lm loss: 1.120694E+01 | grad norm: 17.631 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.083 | TFLOPs: 119.81 |
[default7]: iteration        4/  250000 | consumed samples:         2048 | consumed tokens:      4194304 | elapsed time per iteration (ms): 11610.5 | learning rate: 6.000E-07 | global batch size:   512 | lm loss: 1.120638E+01 | grad norm: 17.640 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.098 | TFLOPs: 119.85 |
[default7]: iteration        5/  250000 | consumed samples:         2560 | consumed tokens:      5242880 | elapsed time per iteration (ms): 11610.1 | learning rate: 7.500E-07 | global batch size:   512 | lm loss: 1.118815E+01 | grad norm: 19.033 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.100 | TFLOPs: 119.85 |
[default7]: iteration        6/  250000 | consumed samples:         3072 | consumed tokens:      6291456 | elapsed time per iteration (ms): 11614.3 | learning rate: 9.000E-07 | global batch size:   512 | lm loss: 1.114213E+01 | grad norm: 17.738 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.084 | TFLOPs: 119.81 |
[default7]: iteration        7/  250000 | consumed samples:         3584 | consumed tokens:      7340032 | elapsed time per iteration (ms): 11607.2 | learning rate: 1.050E-06 | global batch size:   512 | lm loss: 1.098079E+01 | grad norm: 17.577 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.110 | TFLOPs: 119.88 |
[default7]: iteration        8/  250000 | consumed samples:         4096 | consumed tokens:      8388608 | elapsed time per iteration (ms): 11578.5 | learning rate: 1.200E-06 | global batch size:   512 | lm loss: 1.092031E+01 | grad norm: 17.128 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.220 | TFLOPs: 120.18 |
[default7]: iteration        9/  250000 | consumed samples:         4608 | consumed tokens:      9437184 | elapsed time per iteration (ms): 11604.2 | learning rate: 1.350E-06 | global batch size:   512 | lm loss: 1.049876E+01 | grad norm: 15.966 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.122 | TFLOPs: 119.91 |
[default7]: iteration       10/  250000 | consumed samples:         5120 | consumed tokens:     10485760 | elapsed time per iteration (ms): 11602.2 | learning rate: 1.500E-06 | global batch size:   512 | lm loss: 1.036658E+01 | grad norm: 18.967 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.130 | TFLOPs: 119.94 |
[default7]: iteration       11/  250000 | consumed samples:         5632 | consumed tokens:     11534336 | elapsed time per iteration (ms): 13294.8 | learning rate: 1.650E-06 | global batch size:   512 | lm loss: 1.025263E+01 | grad norm: 17.679 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 38.511 | TFLOPs: 104.67 |
[default7]: iteration       12/  250000 | consumed samples:         6144 | consumed tokens:     12582912 | elapsed time per iteration (ms): 11603.0 | learning rate: 1.800E-06 | global batch size:   512 | lm loss: 9.973583E+00 | grad norm: 43.484 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.127 | TFLOPs: 119.93 |
[default7]: iteration       13/  250000 | consumed samples:         6656 | consumed tokens:     13631488 | elapsed time per iteration (ms): 11625.7 | learning rate: 1.950E-06 | global batch size:   512 | lm loss: 9.577026E+00 | grad norm: 28.019 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.040 | TFLOPs: 119.69 |
[default7]:[2024-04-05 19:17:02,984] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2024-04-05 19:17:02,984] [WARNING] [engine.py:2714:load_checkpoint] Unable to find latest file at /gpfswork/rech/qgz/urc37ho/checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file /gpfswork/rech/qgz/urc37ho/checkpoints/ 
[default0]:    will not load any checkpoints and will start from random
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2024-04-05 19:17:03 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      128000000
[default0]:    validation: 128025600
[default0]:    test:       25600
[default0]:> building train, validation, and test datasets for GPT ...
[default0]:Single data path provided for train, valid & test
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.011892 seconds
[default0]:    number of documents: 32615
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 31604) total of 31604 documents
[default0]:    validation:
[default0]:     document indices in [31604, 32582) total of 978 documents
[default0]:    test:
[default0]:     document indices in [32582, 32615) total of 33 documents
[default0]: > loading doc-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/bbbf4e74e1791ddd0220158bd599e480_doc_idx.npy
[default0]: > loading sample-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/bbbf4e74e1791ddd0220158bd599e480_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/bbbf4e74e1791ddd0220158bd599e480_shuffle_idx.npy
[default0]:    loaded indexed file in 0.153 seconds
[default0]:    total number of samples: 128006360
[default0]:    total number of epochs: 14270
[default0]: > loading doc-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/5b71433b2cf6bdb9c6a97388444a926f_doc_idx.npy
[default0]: > loading sample-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/5b71433b2cf6bdb9c6a97388444a926f_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/5b71433b2cf6bdb9c6a97388444a926f_shuffle_idx.npy
[default0]:    loaded indexed file in 0.290 seconds
[default0]:    total number of samples: 128025754
[default0]:    total number of epochs: 487379
[default0]: > loading doc-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/60c0412e0d26067d531346d71e3a6f6e_doc_idx.npy
[default0]: > loading sample-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/60c0412e0d26067d531346d71e3a6f6e_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /linkhome/rech/genlor01/urc37ho/.cache/60c0412e0d26067d531346d71e3a6f6e_shuffle_idx.npy
[default0]:    loaded indexed file in 0.056 seconds
[default0]:    total number of samples: 25602
[default0]:    total number of epochs: 3569
[default0]:> finished creating GPT datasets ...
[default0]:[after dataloaders are built] datetime: 2024-04-05 19:17:06 
[default0]:done with setup ...
[default0]:training ...
[default0]:[before the start of training step] datetime: 2024-04-05 19:17:06 
[default0]:[2024-04-05 19:17:21,828] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[1.5e-07, 1.5e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 1 loss: 11.2106 iter time (s): 15.597 samples/sec: 32.827
[default0]:[Rank 0] (after 1 iterations) memory (MB) | allocated: 15331.69189453125 | max allocated: 42135.86376953125 | reserved: 47036.0 | max reserved: 47036.0
[default1]:[Rank 1] (after 1 iterations) memory (MB) | allocated: 15331.69189453125 | max allocated: 42135.86376953125 | reserved: 47036.0 | max reserved: 47036.0
[default0]:[2024-04-05 19:17:33,684] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[3e-07, 3e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 2 loss: 11.2029 iter time (s): 11.565 samples/sec: 44.273
[default0]:[2024-04-05 19:17:45,299] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=0, lr=[4.5e-07, 4.5e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 3 loss: 11.2069 iter time (s): 11.610 samples/sec: 44.100
[default0]:[2024-04-05 19:17:56,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=0, lr=[6e-07, 6e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 4 loss: 11.2064 iter time (s): 11.606 samples/sec: 44.115
[default0]:[2024-04-05 19:18:08,520] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[7.499999999999999e-07, 7.499999999999999e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 5 loss: 11.1882 iter time (s): 11.606 samples/sec: 44.117
[default0]:[2024-04-05 19:18:20,134] [INFO] [logging.py:96:log_dist] [Rank 0] step=6, skipped=0, lr=[9e-07, 9e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 6 loss: 11.1421 iter time (s): 11.610 samples/sec: 44.101
[default0]:[2024-04-05 19:18:31,742] [INFO] [logging.py:96:log_dist] [Rank 0] step=7, skipped=0, lr=[1.05e-06, 1.05e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 7 loss: 10.9808 iter time (s): 11.603 samples/sec: 44.128
[default0]:[2024-04-05 19:18:43,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=8, skipped=0, lr=[1.2e-06, 1.2e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 8 loss: 10.9203 iter time (s): 11.574 samples/sec: 44.237
[default0]:[2024-04-05 19:18:54,925] [INFO] [logging.py:96:log_dist] [Rank 0] step=9, skipped=0, lr=[1.3499999999999998e-06, 1.3499999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 9 loss: 10.4988 iter time (s): 11.600 samples/sec: 44.138
[default0]:[2024-04-05 19:19:06,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.4999999999999998e-06, 1.4999999999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 10 loss: 10.3666 iter time (s): 11.598 samples/sec: 44.146
[default0]:[2024-04-05 19:19:19,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=11, skipped=0, lr=[1.6499999999999999e-06, 1.6499999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 11 loss: 10.2526 iter time (s): 13.290 samples/sec: 38.524
[default0]:[2024-04-05 19:19:31,426] [INFO] [logging.py:96:log_dist] [Rank 0] step=12, skipped=0, lr=[1.8e-06, 1.8e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 12 loss: 9.9736 iter time (s): 11.599 samples/sec: 44.143
[default0]:[2024-04-05 19:19:43,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=13, skipped=0, lr=[1.95e-06, 1.95e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 13 loss: 9.5770 iter time (s): 11.621 samples/sec: 44.057
[default0]:[2024-04-05 19:19:54,725] [INFO] [logging.py:96:log_dist] [Rank 0] step=14, skipped=0, lr=[2.1e-06, 2.1e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 14 loss: 9.3686 iter time (s): 11.669 samples/sec: 43.879
[default0]:[2024-04-05 19:20:06,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=15, skipped=0, lr=[2.2499999999999996e-06, 2.2499999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 15 loss: 9.1422 iter time (s): 11.644 samples/sec: 43.971
[default0]:[2024-04-05 19:20:17,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=16, skipped=0, lr=[2.4e-06, 2.4e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 16 loss: 9.0442 iter time (s): 11.618 samples/sec: 44.070
2,480] [INFO  [confiO     :print]   global rank ..O     ........ 0
[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[2024-04-05 19:17:02,480] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 16
[default7]: iteration       14/  250000 | consumed samples:         7168 | consumed tokens:     14680064 | elapsed time per iteration (ms): 11673.5 | learning rate: 2.100E-06 | global batch size:   512 | lm loss: 9.368626E+00 | grad norm: 21.871 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.860 | TFLOPs: 119.20 |
[default7]: iteration       15/  250000 | consumed samples:         7680 | consumed tokens:     15728640 | elapsed time per iteration (ms): 11648.4 | learning rate: 2.250E-06 | global batch size:   512 | lm loss: 9.142216E+00 | grad norm: 21.460 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.955 | TFLOPs: 119.46 |
[default7]: iteration       16/  250000 | consumed samples:         8192 | consumed tokens:     16777216 | elapsed time per iteration (ms): 11622.3 | learning rate: 2.400E-06 | global batch size:   512 | lm loss: 9.044230E+00 | grad norm: 19.952 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.053 | TFLOPs: 119.73 |
[default7]: iteration       17/  250000 | consumed samples:         8704 | consumed tokens:     17825792 | elapsed time per iteration (ms): 11657.9 | learning rate: 2.550E-06 | global batch size:   512 | lm loss: 8.720350E+00 | grad norm: 18.192 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.919 | TFLOPs: 119.36 |
[default7]: iteration       18/  250000 | consumed samples:         9216 | consumed tokens:     18874368 | elapsed time per iteration (ms): 11633.4 | learning rate: 2.700E-06 | global batch size:   512 | lm loss: 8.716166E+00 | grad norm: 15.011 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.011 | TFLOPs: 119.61 |
[default7]: iteration       19/  250000 | consumed samples:         9728 | consumed tokens:     19922944 | elapsed time per iteration (ms): 11632.1 | learning rate: 2.850E-06 | global batch size:   512 | lm loss: 8.545902E+00 | grad norm: 17.434 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.016 | TFLOPs: 119.63 |
[default7]: iteration       20/  250000 | consumed samples:        10240 | consumed tokens:     20971520 | elapsed time per iteration (ms): 11613.9 | learning rate: 3.000E-06 | global batch size:   512 | lm loss: 8.478180E+00 | grad norm: 16.718 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.085 | TFLOPs: 119.82 |
[default7]: iteration       21/  250000 | consumed samples:        10752 | consumed tokens:     22020096 | elapsed time per iteration (ms): 11631.4 | learning rate: 3.150E-06 | global batch size:   512 | lm loss: 8.318501E+00 | grad norm: 17.734 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.019 | TFLOPs: 119.63 |
[default7]: iteration       22/  250000 | consumed samples:        11264 | consumed tokens:     23068672 | elapsed time per iteration (ms): 11622.0 | learning rate: 3.300E-06 | global batch size:   512 | lm loss: 8.160726E+00 | grad norm: 14.081 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.054 | TFLOPs: 119.73 |
[default7]: iteration       23/  250000 | consumed samples:        11776 | consumed tokens:     24117248 | elapsed time per iteration (ms): 11643.0 | learning rate: 3.450E-06 | global batch size:   512 | lm loss: 8.103281E+00 | grad norm: 26.981 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.975 | TFLOPs: 119.52 |
[default7]: iteration       24/  250000 | consumed samples:        12288 | consumed tokens:     25165824 | elapsed time per iteration (ms): 11606.4 | learning rate: 3.600E-06 | global batch size:   512 | lm loss: 8.090141E+00 | grad norm: 15.220 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.113 | TFLOPs: 119.89 |
[default7]: iteration       25/  250000 | consumed samples:        12800 | consumed tokens:     26214400 | elapsed time per iteration (ms): 11622.7 | learning rate: 3.750E-06 | global batch size:   512 | lm loss: 7.982036E+00 | grad norm: 13.153 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.052 | TFLOPs: 119.72 |
[default7]: iteration       26/  250000 | consumed samples:        13312 | consumed tokens:     27262976 | elapsed time per iteration (ms): 11615.3 | learning rate: 3.900E-06 | global batch size:   512 | lm loss: 7.907323E+00 | grad norm: 12.290 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.080 | TFLOPs: 119.80 |
[default7]: iteration       27/  250000 | consumed samples:        13824 | consumed tokens:     28311552 | elapsed time per iteration (ms): 11618.9 | learning rate: 4.050E-06 | global batch size:   512 | lm loss: 7.947085E+00 | grad norm: 11.537 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.066 | TFLOPs: 119.76 |
[default7]: iteration       28/  250000 | consumed samples:        14336 | consumed tokens:     29360128 | elapsed time per iteration (ms): 11612.4 | learning rate: 4.200E-06 | global batch size:   512 | lm loss: 7.780764E+00 | grad norm: 9.123 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.091 | TFLOPs: 119.83 |
[default7]: iteration       29/  250000 | consumed samples:        14848 | consumed tokens:     30408704 | elapsed time per iteration (ms): 11614.5 | learning rate: 4.350E-06 | global batch size:   512 | lm loss: 7.709858E+00 | grad norm: 14.815 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.083 | TFLOPs: 119.81 |
[default7]: iteration       30/  250000 | consumed samples:        15360 | consumed tokens:     31457280 | elapsed time per iteration (ms): 11707.1 | learning rate: 4.500E-06 | global batch size:   512 | lm loss: 7.614200E+00 | grad norm: 8.999 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.734 | TFLOPs: 118.86 |
[default7]: iteration       31/  250000 | consumed samples:        15872 | consumed tokens:     32505856 | elapsed time per iteration (ms): 11687.5 | learning rate: 4.650E-06 | global batch size:   512 | lm loss: 7.634847E+00 | grad norm: 10.472 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.808 | TFLOPs: 119.06 |
[default7]: iteration       32/  250000 | consumed samples:        16384 | consumed tokens:     33554432 | elapsed time per iteration (ms): 11623.7 | learning rate: 4.800E-06 | global batch size:   512 | lm loss: 7.544942E+00 | grad norm: 8.367 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.048 | TFLOPs: 119.71 |
[default7]: iteration       33/  250000 | consumed samples:        16896 | consumed tokens:     34603008 | elapsed time per iteration (ms): 11743.4 | learning rate: 4.950E-06 | global batch size:   512 | lm loss: 7.439875E+00 | grad norm: 6.935 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.599 | TFLOPs: 118.49 |
[2024-04-05 19:17:02,480] [INFO[default0]:[2024-04-05 19:20:29,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=17, skipped=0, lr=[2.5499999999999997e-06, 2.5499999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 17 loss: 8.7204 iter time (s): 11.646 samples/sec: 43.964
[default0]:[2024-04-05 19:20:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=18, skipped=0, lr=[2.6999999999999996e-06, 2.6999999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 18 loss: 8.7162 iter time (s): 11.629 samples/sec: 44.028
[default0]:[2024-04-05 19:20:52,921] [INFO] [logging.py:96:log_dist] [Rank 0] step=19, skipped=0, lr=[2.85e-06, 2.85e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 19 loss: 8.5459 iter time (s): 11.627 samples/sec: 44.034
[default0]:[2024-04-05 19:21:04,534] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[2.9999999999999997e-06, 2.9999999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 20 loss: 8.4782 iter time (s): 11.609 samples/sec: 44.103
[default0]:[2024-04-05 19:21:16,167] [INFO] [logging.py:96:log_dist] [Rank 0] step=21, skipped=0, lr=[3.1499999999999995e-06, 3.1499999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 21 loss: 8.3185 iter time (s): 11.627 samples/sec: 44.036
[default0]:[2024-04-05 19:21:27,789] [INFO] [logging.py:96:log_dist] [Rank 0] step=22, skipped=0, lr=[3.2999999999999997e-06, 3.2999999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 22 loss: 8.1607 iter time (s): 11.617 samples/sec: 44.072
[default0]:[2024-04-05 19:21:39,432] [INFO] [logging.py:96:log_dist] [Rank 0] step=23, skipped=0, lr=[3.4499999999999996e-06, 3.4499999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 23 loss: 8.1033 iter time (s): 11.638 samples/sec: 43.992
[default0]:[2024-04-05 19:21:51,038] [INFO] [logging.py:96:log_dist] [Rank 0] step=24, skipped=0, lr=[3.6e-06, 3.6e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 24 loss: 8.0901 iter time (s): 11.602 samples/sec: 44.131
[default0]:[2024-04-05 19:22:02,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=25, skipped=0, lr=[3.7499999999999997e-06, 3.7499999999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 25 loss: 7.9820 iter time (s): 11.618 samples/sec: 44.069
[default0]:[2024-04-05 19:22:14,277] [INFO] [logging.py:96:log_dist] [Rank 0] step=26, skipped=0, lr=[3.9e-06, 3.9e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 26 loss: 7.9073 iter time (s): 11.611 samples/sec: 44.098
[default0]:[2024-04-05 19:22:25,896] [INFO] [logging.py:96:log_dist] [Rank 0] step=27, skipped=0, lr=[4.05e-06, 4.05e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 27 loss: 7.9471 iter time (s): 11.614 samples/sec: 44.084
[default0]:[2024-04-05 19:22:37,509] [INFO] [logging.py:96:log_dist] [Rank 0] step=28, skipped=0, lr=[4.2e-06, 4.2e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 28 loss: 7.7808 iter time (s): 11.608 samples/sec: 44.108
[default0]:[2024-04-05 19:22:49,123] [INFO] [logging.py:96:log_dist] [Rank 0] step=29, skipped=0, lr=[4.35e-06, 4.35e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 29 loss: 7.7099 iter time (s): 11.610 samples/sec: 44.100
[default0]:[2024-04-05 19:23:00,831] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[4.499999999999999e-06, 4.499999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 30 loss: 7.6142 iter time (s): 11.703 samples/sec: 43.751
[default0]:[2024-04-05 19:23:12,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=31, skipped=0, lr=[4.6499999999999995e-06, 4.6499999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 31 loss: 7.6348 iter time (s): 11.683 samples/sec: 43.825
[default0]:[2024-04-05 19:23:24,142] [INFO] [logging.py:96:log_dist] [Rank 0] step=32, skipped=0, lr=[4.8e-06, 4.8e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 32 loss: 7.5449 iter time (s): 11.619 samples/sec: 44.065
[default0]:[2024-04-05 19:23:35,886] [INFO] [logging.py:96:log_dist] [Rank 0] step=33, skipped=0, lr=[4.949999999999999e-06, 4.949999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 33 loss: 7.4399 iter time (s): 11.739 samples/sec: 43.615
[default0]:[2024-04-05 19:23:47,505] [INFO] [logging.py:96:log_dist] [Rank 0] step=34, skipped=0, lr=[5.0999999999999995e-06, 5.0999999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 34 loss: 7.4224 iter time (s): 11.615 samples/sec: 44.081
[default0]:[2024-04-05 19:23:59,193] [INFO] [logging.py:96:log_dist] [Rank 0] step=35, skipped=0, lr=[5.25e-06, 5.25e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 35 loss: 7.5123 iter time (s): 11.682 samples/sec: 43.827
[default0]:[2024-04-05 19:24:10,958] [INFO] [logging.py:96:log_dist] [Rank 0] step=36, skipped=0, lr=[5.399999999999999e-06, 5.399999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 36 loss: 7.4035 iter time (s): 11.761 samples/sec: 43.534
[default0]:[2024-04-05 19:24:22,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=37, skipped=0, lr=[5.549999999999999e-06, 5.549999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 37 loss: 7.3699 iter time (s): 11.623 samples/sec: 44.049
[default0]:[2024-04-05 19:24:34,304] [INFO] [logging.py:96:log_dist] [Rank 0] step=38, skipped=0, lr=[5.7e-06, 5.7e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 38 loss: 7.2354 iter time (s): 11.713 samples/sec: 43.713
[default0]:[2024-04-05 19:24:45,941] [INFO] [logging.py:96:log_dist] [Rank 0] step=39, skipped=0, lr=[5.849999999999999e-06, 5.849999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 39 loss: 7.2540 iter time (s): 11.632 samples/sec: 44.015
[default0]:[2024-04-05 19:24:57,577] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[5.999999999999999e-06, 5.999999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 40 loss: 7.1405 iter time (s): 11.631 samples/sec: 44.021
[default0]:[2024-04-05 19:25:09,205] [INFO] [logging.py:96:log_dist] [Rank 0] step=41, skipped=0, lr=[6.1499999999999996e-06, 6.1499999999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 41 loss: 7.2249 iter time (s): 11.624 samples/sec: 44.048
[default0]:[2024-04-05 19:25:20,830] [INFO] [logging.py:96:log_dist] [Rank 0] step=42, skipped=0, lr=[6.299999999999999e-06, 6.299999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 42 loss: 7.1565 iter time (s): 11.620 samples/sec: 44.062
[default0]:[2024-04-05 19:25:32,473] [INFO] [logging.py:96:log_dist] [Rank 0] step=43, skipped=0, lr=[6.449999999999999e-06, 6.449999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 43 loss: 7.2046 iter time (s): 11.639 samples/sec: 43.992
[default0]:[2024-04-05 19:25:44,087] [INFO] [logging.py:96:log_dist] [Rank 0] step=44, skipped=0, lr=[6.5999999999999995e-06, 6.5999999999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 44 loss: 7.1090 iter time (s): 11.609 samples/sec: 44.103
[default0]:[2024-04-05 19:25:55,716] [INFO] [logging.py:96:log_dist] [Rank 0] step=45, skipped=0, lr=[6.749999999999999e-06, 6.749999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 45 loss: 6.9995 iter time (s): 11.624 samples/sec: 44.047
[default0]:[2024-04-05 19:26:07,337] [INFO] [logging.py:96:log_dist] [Rank 0] step=46, skipped=0, lr=[6.899999999999999e-06, 6.899999999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 46 loss: 7.0026 iter time (s): 11.617 samples/sec: 44.074
[default0]:[2024-04-05 19:26:18,940] [INFO] [logging.py:96:log_dist] [Rank 0] step=47, skipped=0, lr=[7.0499999999999986e-06, 7.0499999999999986e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 47 loss: 6.9869 iter time (s): 11.598 samples/sec: 44.144
[default0]:[2024-04-05 19:26:30,549] [INFO] [logging.py:96:log_dist] [Rank 0] step=48, skipped=0, lr=[7.2e-06, 7.2e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 48 loss: 6.9199 iter time (s): 11.603 samples/sec: 44.125
[default0]:[2024-04-05 19:26:42,165] [INFO] [logging.py:96:log_dist] [Rank 0] step=49, skipped=0, lr=[7.35e-06, 7.35e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:steps: 49 loss: 6.9654 iter time (s): 11.612 samples/sec: 44.092
[default7]: iteration       34/  250000 | consumed samples:        17408 | consumed tokens:     35651584 | elapsed time per iteration (ms): 11619.6 | learning rate: 5.100E-06 | global batch size:   512 | lm loss: 7.422379E+00 | grad norm: 9.670 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.063 | TFLOPs: 119.76 |
[default7]: iteration       35/  250000 | consumed samples:        17920 | consumed tokens:     36700160 | elapsed time per iteration (ms): 11686.7 | learning rate: 5.250E-06 | global batch size:   512 | lm loss: 7.512257E+00 | grad norm: 7.242 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.811 | TFLOPs: 119.07 |
[default7]: iteration       36/  250000 | consumed samples:        18432 | consumed tokens:     37748736 | elapsed time per iteration (ms): 11765.4 | learning rate: 5.400E-06 | global batch size:   512 | lm loss: 7.403522E+00 | grad norm: 6.643 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.517 | TFLOPs: 118.27 |
[default7]: iteration       37/  250000 | consumed samples:        18944 | consumed tokens:     38797312 | elapsed time per iteration (ms): 11628.1 | learning rate: 5.550E-06 | global batch size:   512 | lm loss: 7.369922E+00 | grad norm: 6.623 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.031 | TFLOPs: 119.67 |
[default7]: iteration       38/  250000 | consumed samples:        19456 | consumed tokens:     39845888 | elapsed time per iteration (ms): 11717.3 | learning rate: 5.700E-06 | global batch size:   512 | lm loss: 7.235367E+00 | grad norm: 5.347 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.696 | TFLOPs: 118.76 |
[default7]: iteration       39/  250000 | consumed samples:        19968 | consumed tokens:     40894464 | elapsed time per iteration (ms): 11636.9 | learning rate: 5.850E-06 | global batch size:   512 | lm loss: 7.254013E+00 | grad norm: 6.604 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.998 | TFLOPs: 119.58 |
[default7]: iteration       40/  250000 | consumed samples:        20480 | consumed tokens:     41943040 | elapsed time per iteration (ms): 11635.4 | learning rate: 6.000E-06 | global batch size:   512 | lm loss: 7.140486E+00 | grad norm: 5.734 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.004 | TFLOPs: 119.59 |
[default7]: iteration       41/  250000 | consumed samples:        20992 | consumed tokens:     42991616 | elapsed time per iteration (ms): 11628.5 | learning rate: 6.150E-06 | global batch size:   512 | lm loss: 7.224939E+00 | grad norm: 5.182 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.030 | TFLOPs: 119.66 |
[default7]: iteration       42/  250000 | consumed samples:        21504 | consumed tokens:     44040192 | elapsed time per iteration (ms): 11624.6 | learning rate: 6.300E-06 | global batch size:   512 | lm loss: 7.156538E+00 | grad norm: 4.207 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.045 | TFLOPs: 119.70 |
[default7]: iteration       43/  250000 | consumed samples:        22016 | consumed tokens:     45088768 | elapsed time per iteration (ms): 11643.2 | learning rate: 6.450E-06 | global batch size:   512 | lm loss: 7.204596E+00 | grad norm: 5.658 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.974 | TFLOPs: 119.51 |
[default7]: iteration       44/  250000 | consumed samples:        22528 | consumed tokens:     46137344 | elapsed time per iteration (ms): 11613.8 | learning rate: 6.600E-06 | global batch size:   512 | lm loss: 7.108979E+00 | grad norm: 3.810 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.086 | TFLOPs: 119.82 |
[default7]: iteration       45/  250000 | consumed samples:        23040 | consumed tokens:     47185920 | elapsed time per iteration (ms): 11628.5 | learning rate: 6.750E-06 | global batch size:   512 | lm loss: 6.999483E+00 | grad norm: 4.919 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.030 | TFLOPs: 119.66 |
[default7]: iteration       46/  250000 | consumed samples:        23552 | consumed tokens:     48234496 | elapsed time per iteration (ms): 11621.4 | learning rate: 6.900E-06 | global batch size:   512 | lm loss: 7.002564E+00 | grad norm: 3.445 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.056 | TFLOPs: 119.74 |
[default7]: iteration       47/  250000 | consumed samples:        24064 | consumed tokens:     49283072 | elapsed time per iteration (ms): 11602.8 | learning rate: 7.050E-06 | global batch size:   512 | lm loss: 6.986934E+00 | grad norm: 4.307 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.127 | TFLOPs: 119.93 |
[default7]: iteration       48/  250000 | consumed samples:        24576 | consumed tokens:     50331648 | elapsed time per iteration (ms): 11608.0 | learning rate: 7.200E-06 | global batch size:   512 | lm loss: 6.919935E+00 | grad norm: 3.746 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.107 | TFLOPs: 119.88 |
[default7]: iteration       49/  250000 | consumed samples:        25088 | consumed tokens:     51380224 | elapsed time per iteration (ms): 11616.5 | learning rate: 7.350E-06 | global batch size:   512 | lm loss: 6.965363E+00 | grad norm: 3.906 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.075 | TFLOPs: 119.79 |
[default7]: iteration       50/  250000 | consumed samples:        25600 | consumed tokens:     52428800 | elapsed time per iteration (ms): 11613.5 | learning rate: 7.500E-06 | global batch size:   512 | lm loss: 6.924201E+00 | grad norm: 3.800 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.087 | TFLOPs: 119.82 |
[default7]:----------------------------------------------------------------------------------------------
[default7]: validation loss at iteration 50 | lm loss value: 6.923852E+00 | lm loss PPL: 1.016227E+03 | 
[default7]:----------------------------------------------------------------------------------------------
[default7]: iteration       51/  250000 | consumed samples:        26112 | consumed tokens:     53477376 | elapsed time per iteration (ms): 193122.3 | learning rate: 7.650E-06 | global batch size:   512 | lm loss: 6.903137E+00 | grad norm: 5.489 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.651 | TFLOPs: 7.21 |
[default7]: iteration       52/  250000 | consumed samples:        26624 | consumed tokens:     54525952 | elapsed time per iteration (ms): 11633.2 | learning rate: 7.800E-06 | global batch size:   512 | lm loss: 6.818805E+00 | grad norm: 8.453 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.012 | TFLOPs: 119.62 |
[default7]: iteration       53/  250000 | consumed samples:        27136 | consumed tokens:     55574528 | elapsed time per iteration (ms): 11610.6 | learning rate: 7.950E-06 | global batch size:   512 | lm loss: 6.872390E+00 | grad norm: 10.160 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.098 | TFLOPs: 119.85 |
[default7]: iteration       54/  250000 | consumed samples:        27648 | consumed tokens:     56623104 | elapsed time per iteration (ms): 11649.2 | learning rate: 8.100E-06 | global batch size:   512 | lm loss: 6.821166E+00 | grad norm: 7.929 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.952 | TFLOPs: 119.45 |
[default7]: iteration       55/  250000 | consumed samples:        28160 | consumed tokens:     57671680 | elapsed time per iteration (ms): 11649.3 | learning rate: 8.250E-06 | global batch size:   512 | lm loss: 6.780715E+00 | grad norm: 5.196 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.951 | TFLOPs: 119.45 |
[default7]: iteration       56/  250000 | consumed samples:        28672 | consumed tokens:     58720256 | elapsed time per iteration (ms): 11626.3 | learning rate: 8.400E-06 | global batch size:   512 | lm loss: 6.792825E+00 | grad norm: 16.549 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.038 | TFLOPs: 119.69 |
[default7]: iteration       57/  250000 | consumed samples:        29184 | consumed tokens:     59768832 | elapsed time per iteration (ms): 11634.1 | learning rate: 8.550E-06 | global batch size:   512 | lm loss: 6.850250E+00 | grad norm: 10.868 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.009 | TFLOPs: 119.61 |
[default7]: iteration       58/  250000 | consumed samples:        29696 | consumed tokens:     60817408 | elapsed time per iteration (ms): 11646.8 | learning rate: 8.700E-06 | global batch size:   512 | lm loss: 6.900882E+00 | grad norm: 16.757 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.961 | TFLOPs: 119.48 |
[default7]: iteration       59/  250000 | consumed samples:        30208 | consumed tokens:     61865984 | elapsed time per iteration (ms): 11658.8 | learning rate: 8.850E-06 | global batch size:   512 | lm loss: 6.834041E+00 | grad norm: 10.180 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.915 | TFLOPs: 119.35 |
[default7]: iteration       60/  250000 | consumed samples:        30720 | consumed tokens:     62914560 | elapsed time per iteration (ms): 11649.5 | learning rate: 9.000E-06 | global batch size:   512 | lm loss: 7.049283E+00 | grad norm: 41.411 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.950 | TFLOPs: 119.45 |
[default7]: iteration       61/  250000 | consumed samples:        31232 | consumed tokens:     63963136 | elapsed time per iteration (ms): 11634.5 | learning rate: 9.150E-06 | global batch size:   512 | lm loss: 6.895134E+00 | grad norm: 11.469 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.007 | TFLOPs: 119.60 |
[default7]: iteration       62/  250000 | consumed samples:        31744 | consumed tokens:     65011712 | elapsed time per iteration (ms): 11630.4 | learning rate: 9.300E-06 | global batch size:   512 | lm loss: 7.078115E+00 | grad norm: 14.544 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.022 | TFLOPs: 119.64 |
[default7]: iteration       63/  250000 | consumed samples:        32256 | consumed tokens:     66060288 | elapsed time per iteration (ms): 11625.3 | learning rate: 9.450E-06 | global batch size:   512 | lm loss: 7.105683E+00 | grad norm: 9.331 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 44.042 | TFLOPs: 119.70 |
[default7]: iteration       64/  250000 | consumed samples:        32768 | consumed tokens:     67108864 | elapsed time per iteration (ms): 11656.1 | learning rate: 9.600E-06 | global batch size:   512 | lm loss: 7.032716E+00 | grad norm: 9.245 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.926 | TFLOPs: 119.38 |
[default7]: iteration       65/  250000 | consumed samples:        33280 | consumed tokens:     68157440 | elapsed time per iteration (ms): 11649.9 | learning rate: 9.750E-06 | global batch size:   512 | lm loss: 7.027358E+00 | grad norm: 6.033 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.949 | TFLOPs: 119.44 |
[default7]: iteration       66/  250000 | consumed samples:        33792 | consumed tokens:     69206016 | elapsed time per iteration (ms): 11643.7 | learning rate: 9.900E-06 | global batch size:   512 | lm loss: 6.812833E+00 | grad norm: 6.115 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.972 | TFLOPs: 119.51 |
[default7]: iteration       67/  250000 | consumed samples:        34304 | consumed tokens:     70254592 | elapsed time per iteration (ms): 11647.7 | learning rate: 1.005E-05 | global batch size:   512 | lm loss: 6.717587E+00 | grad norm: 6.643 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.957 | TFLOPs: 119.47 |
[default7]: iteration       68/  250000 | consumed samples:        34816 | consumed tokens:     71303168 | elapsed time per iteration (ms): 11640.2 | learning rate: 1.020E-05 | global batch size:   512 | lm loss: 6.637843E+00 | grad norm: 4.631 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.985 | TFLOPs: 119.54 |
[default7]: iteration       69/  250000 | consumed samples:        35328 | consumed tokens:     72351744 | elapsed time per iteration (ms): 11656.2 | learning rate: 1.035E-05 | global batch size:   512 | lm loss: 6.681751E+00 | grad norm: 6.419 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.925 | TFLOPs: 119.38 |
[default7]: iteration       70/  250000 | consumed samples:        35840 | consumed tokens:     73400320 | elapsed time per iteration (ms): 11643.7 | learning rate: 1.050E-05 | global batch size:   512 | lm loss: 6.617918E+00 | grad norm: 4.810 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.972 | TFLOPs: 119.51 |
[default7]: iteration       71/  250000 | consumed samples:        36352 | consumed tokens:     74448896 | elapsed time per iteration (ms): 11644.9 | learning rate: 1.065E-05 | global batch size:   512 | lm loss: 6.573709E+00 | grad norm: 3.563 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.968 | TFLOPs: 119.50 |
[default7]: iteration       72/  250000 | consumed samples:        36864 | consumed tokens:     75497472 | elapsed time per iteration (ms): 11653.6 | learning rate: 1.080E-05 | global batch size:   512 | lm loss: 6.605297E+00 | grad norm: 3.811 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 43.935 | TFLOPs: 119.41 |
slurmstepd: error: *** JOB 1391582 ON jean-zay-iam09 CANCELLED AT 2024-04-05T19:34:50 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 1391582.0 ON jean-zay-iam09 CANCELLED AT 2024-04-05T19:34:50 DUE TO TIME LIMIT ***
[2024-04-05 19:34:50,521] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-05 19:34:50,521] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323634 closing signal SIGTERM
[2024-04-05 19:34:50,521] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-05 19:34:50,521] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362481 closing signal SIGTERM
[2024-04-05 19:34:50,522] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323635 closing signal SIGTERM
[2024-04-05 19:34:50,522] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362482 closing signal SIGTERM
[2024-04-05 19:34:50,522] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323636 closing signal SIGTERM
[2024-04-05 19:34:50,523] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323637 closing signal SIGTERM
[2024-04-05 19:34:50,523] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362483 closing signal SIGTERM
[2024-04-05 19:34:50,523] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323638 closing signal SIGTERM
[2024-04-05 19:34:50,524] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323639 closing signal SIGTERM
[2024-04-05 19:34:50,525] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323640 closing signal SIGTERM
[2024-04-05 19:34:50,525] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323641 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323634 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323635 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323636 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323637 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323638 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323639 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323640 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 323641 closing signal SIGTERM
[2024-04-05 19:34:50,523] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362484 closing signal SIGTERM
[2024-04-05 19:34:50,523] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362485 closing signal SIGTERM
[2024-04-05 19:34:50,524] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362486 closing signal SIGTERM
[2024-04-05 19:34:50,525] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362487 closing signal SIGTERM
[2024-04-05 19:34:50,525] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362488 closing signal SIGTERM
[2024-04-05 19:34:50,526] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362481 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362482 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362483 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362484 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362485 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362486 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362487 closing signal SIGTERM
[2024-04-05 19:34:50,527] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 362488 closing signal SIGTERM
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
[2024-04-05 19:34:50,562] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-05 19:34:50,562] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352546 closing signal SIGTERM
[2024-04-05 19:34:50,562] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-05 19:34:50,562] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352547 closing signal SIGTERM
[2024-04-05 19:34:50,562] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438135 closing signal SIGTERM
[2024-04-05 19:34:50,563] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352548 closing signal SIGTERM
[2024-04-05 19:34:50,563] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438136 closing signal SIGTERM
[2024-04-05 19:34:50,564] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352549 closing signal SIGTERM
[2024-04-05 19:34:50,564] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438137 closing signal SIGTERM
[2024-04-05 19:34:50,564] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438138 closing signal SIGTERM
[2024-04-05 19:34:50,565] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352550 closing signal SIGTERM
[2024-04-05 19:34:50,565] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352551 closing signal SIGTERM
[2024-04-05 19:34:50,565] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438139 closing signal SIGTERM
[2024-04-05 19:34:50,566] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352552 closing signal SIGTERM
[2024-04-05 19:34:50,566] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 352553 closing signal SIGTERM
[2024-04-05 19:34:50,566] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438140 closing signal SIGTERM
[2024-04-05 19:34:50,566] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438141 closing signal SIGTERM
[2024-04-05 19:34:50,567] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 438142 closing signal SIGTERM
