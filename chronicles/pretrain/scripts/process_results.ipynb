{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_paths = [\n",
    "    '/data-server/datasets/evaluation/evaluation_output/benchmarks',\n",
    "    #'/home/lriviere/EVAL_INSTRUCT/benchmarks',\n",
    "    #'/lustre/fsn1/projects/rech/qgz/commun/evaluation_output/benchmarks',\n",
    "    #'~/Lucie-Training/evaluation/out',\n",
    "    ]\n",
    "\n",
    "file_paths = []\n",
    "for input_file_path in input_file_paths:\n",
    "    file_paths += glob.glob(os.path.join(os.path.expanduser(input_file_path),'**/*.json'), recursive=True)\n",
    "\n",
    "folder_output_table = \"../\"\n",
    "output_file_eval_lucie = os.path.join(folder_output_table, \"evaluation_learning_curve_lucie.csv\")\n",
    "output_file_eval_baselines = os.path.join(folder_output_table, \"evaluation_baselines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERF_NAMES = [\n",
    "    \"acc_norm,none\", \"acc,none\",\n",
    "    \"rouge1_acc,none\", \"rouge1,none\",\n",
    "    \"exact_match,flexible-extract\", \"exact_match,none\",\n",
    "    \"prompt_level_loose_acc,none\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucie_training_step_total(training_steps, training_phase=None):\n",
    "    if not training_phase:\n",
    "        return training_steps\n",
    "\n",
    "    if training_phase == \"extension\":\n",
    "        return 753851 + training_steps\n",
    "    \n",
    "    if training_phase == \"annealing\":\n",
    "        return lucie_training_step_total(1220, \"extension\") + training_steps\n",
    "\n",
    "    if training_phase.startswith(\"instruct\"):\n",
    "        # TODO after annealing is completed\n",
    "        return lucie_training_step_total(10, \"annealing\") + training_steps\n",
    "\n",
    "    raise ValueError(f\"Unknown training phase {training_phase}\")\n",
    "\n",
    "def lucie_training_step_to_tokens(training_steps, training_phase=None, cumulate=True):\n",
    "    if not training_phase: # 1. main pretrained\n",
    "        # Batch size ramp-up\n",
    "        training_tokens = {\n",
    "            0: 0,\n",
    "            5000: 5700059136,\n",
    "            10000: 13884194816,\n",
    "            15000: 26008354816,\n",
    "            22818: 55567450112,\n",
    "        }.get(training_steps)\n",
    "\n",
    "        if training_tokens is None:\n",
    "            assert training_steps >= 20000, f\"Cannot infer number of tokens for {training_steps=}\"\n",
    "            training_tokens = round(43747901440 + ((training_steps - 20000) / 5000) * 20971520000)\n",
    "\n",
    "    else:\n",
    "        training_phase_meta = {\n",
    "            \"extension\": {\n",
    "                \"previous_phase\": None,\n",
    "                \"tokens_by_batch\": 4096000,\n",
    "            },\n",
    "            \"annealing\": {\n",
    "                \"previous_phase\": \"extension\",\n",
    "                \"tokens_by_batch\": 4096 * 128,\n",
    "            },\n",
    "            \"instruct\": {\n",
    "                \"previous_phase\": \"annealing\",\n",
    "                \"tokens_by_batch\": 4096 * 128,\n",
    "            },\n",
    "        }.get(training_phase.split(\"-\")[0])\n",
    "        if not training_phase_meta: raise ValueError(f\"Unknown training phase {training_phase}\")\n",
    "\n",
    "        previous_training_phase = training_phase_meta[\"previous_phase\"]\n",
    "        tokens_by_batch = training_phase_meta[\"tokens_by_batch\"]\n",
    "\n",
    "        num_steps_before = lucie_training_step_total(0, training_phase)\n",
    "        num_tokens_before = lucie_training_step_to_tokens(num_steps_before, previous_training_phase) if cumulate else 0\n",
    "        training_tokens = training_steps * tokens_by_batch + num_tokens_before\n",
    "\n",
    "    return training_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def process_results(json_data):\n",
    "    results = json_data.pop(\"results\")\n",
    "    config = json_data.pop(\"config\")\n",
    "    configs = json_data.pop(\"configs\")\n",
    "\n",
    "    out = []\n",
    "    for benchmark, result_dict in results.items():\n",
    "        score_name = None\n",
    "        for n in PERF_NAMES:\n",
    "            if n in result_dict:\n",
    "                score_name = n\n",
    "                break\n",
    "        \n",
    "        if benchmark in configs:\n",
    "            num_fewshot = configs[benchmark].get('num_fewshot', None)\n",
    "            doc_to_target = configs[benchmark].get('doc_to_target', None)\n",
    "        else: \n",
    "            num_fewshot = None\n",
    "            doc_to_target = None\n",
    "\n",
    "        if score_name is not None:\n",
    "            stderr_name = score_name.split(\",\")[0] + \"_stderr,\" + \",\".join(score_name.split(\",\")[1:])\n",
    "            result_dict.pop(\"alias\", None)\n",
    "            out.append(\n",
    "                {\n",
    "                    \"dataset\": benchmark, \n",
    "                    \"score_name\": score_name, \n",
    "                    \"score\": result_dict[score_name], \n",
    "                    \"stderr\": result_dict[stderr_name], \n",
    "                    \"num_fewshot\": num_fewshot,\n",
    "                    # \"doc_to_target\": doc_to_target,\n",
    "                    **result_dict,\n",
    "                }\n",
    "            )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(json_data):\n",
    "    model_name = json_data['model_name']\n",
    "    if 'Lucie' in model_name: # Lucie model\n",
    "        name = 'Lucie-7B'\n",
    "        intermediate_checkpoint = False\n",
    "        #training_steps_in_phase = int(re.search(r'global_step(\\d+)', model_name).group(1))\n",
    "        match_step = re.search(r'global_step(\\d+)', model_name)\n",
    "        training_steps_in_phase = int(match_step.group(1)) if match_step else 0\n",
    "        if 'extension' in model_name:\n",
    "            phase_type = 'extension'\n",
    "            phase_str = '2_extension'\n",
    "            if 'extension_rope20M' in model_name:\n",
    "                expe_name = 'rope20M'\n",
    "            else:\n",
    "                expe_name = 'rope500k'\n",
    "        elif ('annealing' in model_name) or ('stage2' in model_name):\n",
    "            phase_type = 'annealing'\n",
    "            if 'stage2' in model_name:\n",
    "                size = '5B_tokens'\n",
    "            else:\n",
    "                size = '40M_tokens'\n",
    "            match = re.search(r'mix_(\\d+)', model_name)\n",
    "            if match:\n",
    "                mix = int(match.group(1))\n",
    "            else:\n",
    "                mix = 1\n",
    "            phase_str = f\"3_{phase_type}\" \n",
    "            expe_name = f\"{size}-mix{mix}\"\n",
    "        elif 'instruction_lora' in model_name:\n",
    "            phase_type = 'instruct'\n",
    "            match1 = re.search(r'instruction_lora/Lucie/human/(.*)_global_step', model_name)\n",
    "            match2 = re.search(r'instruction_lora/Lucie/(.*)/merged', model_name)\n",
    "            if match1:\n",
    "                expe_name = match1.group(1)\n",
    "            elif match2:\n",
    "                expe_name = match2.group(1)\n",
    "            else:\n",
    "                expe_name = '????'\n",
    "            phase_str = f\"4_{phase_type}_lora\"\n",
    "        elif 'instruction_assistant_only' in model_name:\n",
    "            phase_type = 'instruct'\n",
    "            match = re.search(r'mix_(\\d+)', model_name)\n",
    "            if match:\n",
    "                mix = int(match.group(1))\n",
    "            else:\n",
    "                mix = 1\n",
    "            phase_str = f\"4_{phase_type}_full\"\n",
    "            expe_name = f\"mix{mix}\"\n",
    "        elif 'instruction' in model_name:\n",
    "            phase_type = 'instruct'\n",
    "            match = re.search(r'mix_(\\d+)', model_name)\n",
    "            if match:\n",
    "                mix = int(match.group(1))\n",
    "            else:\n",
    "                mix = 1\n",
    "            phase_str = f\"4_{phase_type}_full_deprecated\"\n",
    "            expe_name = f\"mix{mix}\"\n",
    "        elif 'pretrained' in model_name:\n",
    "            phase_type = None\n",
    "            phase_str = f\"1_main\"\n",
    "            expe_name = 'pretraining'\n",
    "        else:\n",
    "            print(model_name)\n",
    "            raise NotImplementedError\n",
    "\n",
    "        training_steps = lucie_training_step_total(training_steps_in_phase, phase_type)\n",
    "        training_tokens = lucie_training_step_to_tokens(training_steps_in_phase, phase_type)\n",
    "        training_tokens_in_phase = lucie_training_step_to_tokens(training_steps_in_phase, phase_type, cumulate=False)\n",
    "\n",
    "        return {\n",
    "            \"training_phase\": phase_str,\n",
    "            \"model_name\": name,\n",
    "            \"expe_name\": expe_name,\n",
    "            \"intermediate_checkpoint\": intermediate_checkpoint,\n",
    "            \"training_steps\": training_steps,\n",
    "            \"training_tokens\": training_tokens,\n",
    "            \"training_steps_in_phase\": training_steps_in_phase,\n",
    "            \"training_tokens_in_phase\": training_tokens_in_phase,\n",
    "        }\n",
    "    else:\n",
    "        name = model_name.split('/')[-1]\n",
    "        if 'Meta-Llama-3.1-8B' in name:\n",
    "            training_tokens = 15*10**12    \n",
    "        elif 'Mistral-7B' in name:\n",
    "            training_tokens = 7*10**12\n",
    "        elif 'bloom-7b1' in name:\n",
    "            training_tokens = 0.35*10**12\n",
    "        elif 'CroissantLLM' in name:\n",
    "            training_tokens = 3*10**12 \n",
    "        elif 'falcon-7b' in name:\n",
    "            training_tokens = 3*10**12 \n",
    "        elif 'pythia-6.9b' in name:\n",
    "            training_tokens = 299892736000\n",
    "        else:\n",
    "            print(model_name)\n",
    "        if ('Instruct' in name) or ('Chat' in name):\n",
    "            phase_str = 'instruction'\n",
    "        else:\n",
    "            phase_str = 'main'\n",
    "        return {\n",
    "            \"training_phase\": phase_str,\n",
    "            \"model_name\": name,\n",
    "            \"training_tokens\": training_tokens,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    json_data = read_json(file_path)\n",
    "    match = re.search(r'/(fr_leaderboard|french_bench|french_bench_gen|leaderboard|okapi|multilingual|openllm)/', file_path)\n",
    "    benchmark = match.group(1) if match else '???'\n",
    "    out.append({\n",
    "        'file_path': file_path,\n",
    "        'benchmark': benchmark,\n",
    "        **process_name(json_data),\n",
    "        'chat_template': json_data['chat_template'] is not None,\n",
    "        'fewshot_as_multiturn': json_data['fewshot_as_multiturn'],\n",
    "        'add_bos_token': 'add_bos_token=True' in json_data['config']['model_args'],\n",
    "        'results': process_results(json_data)\n",
    "        })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(out)\n",
    "df = df.explode('results')\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df.drop(columns=['results']).reset_index(drop=True),\n",
    "        pd.json_normalize(df['results']).reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = df[df.duplicated(subset=[\n",
    "    'benchmark', 'training_phase', 'model_name', \"expe_name\",\n",
    "       'intermediate_checkpoint', 'training_steps', 'training_tokens',\n",
    "       'training_steps_in_phase', 'training_tokens_in_phase', 'chat_template',\n",
    "       'fewshot_as_multiturn', 'add_bos_token', 'dataset', 'score_name',\n",
    "       'num_fewshot', \n",
    "    #    'doc_to_target'\n",
    "       ], keep=False)]\n",
    "\n",
    "files_to_check = list(duplicated_rows['file_path'].unique())\n",
    "\n",
    "if len(files_to_check) > 0:\n",
    "    print(f'Please clean your duplicated files...\\n')\n",
    "    for x in files_to_check:\n",
    "        print(x)\n",
    "else:\n",
    "    print('No duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(files_to_check) == 0\n",
    "\n",
    "df = df[['model_name', 'expe_name', 'training_phase', 'intermediate_checkpoint',\n",
    " 'add_bos_token', 'fewshot_as_multiturn', 'chat_template',\n",
    " 'training_steps','training_tokens','training_steps_in_phase','training_tokens_in_phase',\n",
    " 'benchmark','dataset','score','stderr','score_name',\n",
    " 'num_fewshot',\n",
    "#  'doc_to_target',\n",
    " \"acc,none\",\"acc_stderr,none\",\"acc_norm,none\",\"acc_norm_stderr,none\",\n",
    " \"exact_match,strict-match\",\"exact_match_stderr,strict-match\",\"exact_match,flexible-extract\",\"exact_match_stderr,flexible-extract\",\n",
    " \"bleu_max,none\",\"bleu_max_stderr,none\",\"bleu_acc,none\",\"bleu_acc_stderr,none\",\"bleu_diff,none\",\"bleu_diff_stderr,none\",\n",
    " \"rouge1_max,none\",\"rouge1_max_stderr,none\",\"rouge1_acc,none\",\"rouge1_acc_stderr,none\",\"rouge1_diff,none\",\"rouge1_diff_stderr,none\",\n",
    " \"rouge2_max,none\",\"rouge2_max_stderr,none\",\"rouge2_acc,none\",\"rouge2_acc_stderr,none\",\"rouge2_diff,none\",\"rouge2_diff_stderr,none\",\n",
    " \"rougeL_max,none\",\"rougeL_max_stderr,none\",\"rougeL_acc,none\",\"rougeL_acc_stderr,none\",\"rougeL_diff,none\",\"rougeL_diff_stderr,none\",\n",
    " \"rouge1,none\",\"rouge1_stderr,none\",\"f1,none\",\"f1_stderr,none\",\n",
    " \"exact,none\",\"exact_stderr,none\",\n",
    " \"is_included,none\",\"is_included_stderr,none\",\n",
    " \"inst_level_loose_acc,none\",\"inst_level_loose_acc_stderr,none\",\"inst_level_strict_acc,none\",\"inst_level_strict_acc_stderr,none\",\n",
    " \"prompt_level_loose_acc,none\",\"prompt_level_loose_acc_stderr,none\",\n",
    " \"exact_match,none\",\"exact_match_stderr,none\",\n",
    " \"prompt_level_strict_acc,none\",\"prompt_level_strict_acc_stderr,none\"\n",
    "]]\n",
    "\n",
    "lucie_df = df[df['model_name'].apply(lambda x: 'Lucie' in x)]\n",
    "baseline_df = df[df['model_name'].apply(lambda x: 'Lucie' not in x)]\n",
    "\n",
    "pd.DataFrame(lucie_df) \\\n",
    "    .sort_values(by=[\"model_name\", \"training_tokens\", \"training_phase\", \"benchmark\"], ascending=True) \\\n",
    "    .to_csv(output_file_eval_lucie, index=False)\n",
    "\n",
    "pd.DataFrame(baseline_df) \\\n",
    "    .sort_values(by=[\"model_name\", \"training_tokens\", \"benchmark\"], ascending=True) \\\n",
    "    .to_csv(output_file_eval_baselines, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
